{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://github.com/jfpuget/DSB_2018/blob/master/keras_unet_67_final_save.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "c332549b-8d23-4bb5-8497-e7a8eb8b21d2",
    "_uuid": "5c38504af3a84bee68c66d3cde74443c58df422f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label, binary_erosion, binary_dilation, disk\n",
    "from skimage.morphology import square, watershed, closing, binary_closing\n",
    "from skimage.morphology import remove_small_holes, remove_small_objects\n",
    "from skimage.filters.rank import gradient\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.segmentation import random_walker\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pickle as pkl\n",
    "import gc\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = 'stage1_train/'\n",
    "TEST_PATH = 'stage2_test/'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith open('X_train.pkl', 'wb') as file:\\n    pkl.dump(X_train, file, protocol=pkl.HIGHEST_PROTOCOL)\\n\\nwith open('Z_train.pkl', 'wb') as file:\\n    pkl.dump(Z_train, file, protocol=pkl.HIGHEST_PROTOCOL)\\n\\nwith open('X_test.pkl', 'wb') as file:\\n    pkl.dump(X_test, file, protocol=pkl.HIGHEST_PROTOCOL)\\n\\n    \\nwith open('X_train.pkl', 'rb') as file:\\n    X_train= pkl.load(file)\\n\\nwith open('Z_train.pkl', 'rb') as file:\\n    Z_train = pkl.load(file)\\n\\nwith open('X_test.pkl', 'rb') as file:\\n    X_test = pkl.load(file)\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open('X_train.pkl', 'wb') as file:\n",
    "    pkl.dump(X_train, file, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('Z_train.pkl', 'wb') as file:\n",
    "    pkl.dump(Z_train, file, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('X_test.pkl', 'wb') as file:\n",
    "    pkl.dump(X_test, file, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "with open('X_train.pkl', 'rb') as file:\n",
    "    X_train= pkl.load(file)\n",
    "\n",
    "with open('Z_train.pkl', 'rb') as file:\n",
    "    Z_train = pkl.load(file)\n",
    "\n",
    "with open('X_test.pkl', 'rb') as file:\n",
    "    X_test = pkl.load(file)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rn\n",
    "def init_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "    # The below is necessary for starting Numpy generated random numbers\n",
    "    # in a well-defined initial state.\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # The below is necessary for starting core Python generated random numbers\n",
    "    # in a well-defined state.\n",
    "\n",
    "    rn.seed(seed)\n",
    "\n",
    "    # Force TensorFlow to use single thread.\n",
    "    # Multiple threads are a potential source of\n",
    "    # non-reproducible results.\n",
    "    # For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "    from keras import backend as K\n",
    "\n",
    "    # The below tf.set_random_seed() will make random number generation\n",
    "    # in the TensorFlow backend have a well-defined initial state.\n",
    "    # For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "    tf.set_random_seed(seed)\n",
    "\n",
    "    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    K.set_session(sess)\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n",
    "\n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(len(train_ids))\n",
    "train_ids = [train_ids[i] for i in perm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "59c4a25d-645f-4b74-9c53-145ac78cc481",
    "_uuid": "875af74f980236825de3a650825b46e25632422c"
   },
   "source": [
    "# Get the data\n",
    "Let's first import all the images and associated masks. I downsample both the training and test images to keep things light and manageable, but we need to keep a record of the original sizes of the test images to upsample our predicted masks and create correct run-length encodings later on. There are definitely better ways to handle this, but it works fine for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 664/664 [00:42<00:00, 15.75it/s]\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "train_mask = []\n",
    "\n",
    "\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    file = \"stage1_train/{}/images/{}.png\".format(id_,id_)\n",
    "    mfile = \"stage1_train/{}/masks/*.png\".format(id_)\n",
    "    image = cv2.imread(file)\n",
    "    image = rescale_intensity(image, out_range=np.uint8)\n",
    "    masks = imread_collection(mfile).concatenate()\n",
    "    train.append(image)\n",
    "    train_mask.append(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3019/3019 [00:25<00:00, 116.42it/s]\n"
     ]
    }
   ],
   "source": [
    "test = [] \n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    file = \"stage2_test/{}/images/{}.png\".format(id_,id_)\n",
    "    image = cv2.imread(file)\n",
    "    image = rescale_intensity(image, out_range=np.uint8)\n",
    "    test.append((image))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otsu thresholding\n",
    "\n",
    "def to_flip(img_rgb):\n",
    "    # do not flip colored images\n",
    "    if (img_rgb[:,:,0] != img_rgb[:,:,1]).any():\n",
    "        return img_rgb\n",
    "    #green channel happens to produce slightly better results\n",
    "    #than the grayscale image and other channels\n",
    "    img_gray=img_rgb[:,:,1]#cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    #morphological opening (size tuned on training data)\n",
    "    circle7=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7))\n",
    "    img_open=cv2.morphologyEx(img_gray, cv2.MORPH_OPEN, circle7)\n",
    "    #Otsu thresholding\n",
    "    img_th=cv2.threshold(img_open,0,255,cv2.THRESH_OTSU)[1]\n",
    "    #Invert the image in case the objects of interest are in the dark side\n",
    "    if (np.sum(img_th==255)>np.sum(img_th==0)):\n",
    "        return img_rgb\n",
    "    else:\n",
    "        return 255 - img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [to_flip(img_rgb) for img_rgb in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [to_flip(img_rgb) for img_rgb in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_aux(img):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    if height > 2*width:\n",
    "        half = int(height//2)\n",
    "        return [img[:half, :, :], img[half:, :, :]]\n",
    "    elif height > width:\n",
    "        return [img[:width, :, :], img[height-width:, :, :]]\n",
    "    elif width > 2*height:\n",
    "        half = int(width//2)\n",
    "        return [img[:, :half, :], img[:, half:, :]]\n",
    "    else:\n",
    "        return [img[:, :height, :], img[:, width-height:, :]]\n",
    "\n",
    "def split(img):\n",
    "    s = split_aux(img)\n",
    "    return s\n",
    "        \n",
    "def split_mask_aux(img):\n",
    "    height = img.shape[1]\n",
    "    width = img.shape[2]\n",
    "    if height > 2*width:\n",
    "        half = int(height//2)\n",
    "        return [img[:, :half, :], img[:, half:, :]]\n",
    "    elif height > width:\n",
    "        return [img[:, :width, :], img[:, height-width:, :]]\n",
    "    elif width > 2*height:\n",
    "        half = int(width//2)\n",
    "        return [img[:, :, :half], img[:, :, half:]]\n",
    "    else:\n",
    "        return [img[:, :, :height], img[:, :, width-height:]]\n",
    "\n",
    "def split_mask(img):\n",
    "    s = split_mask_aux(img)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = [split(img) for img in train]\n",
    "train_split = [t_split[i] for t_split in train_split for i in [0, 1] ]\n",
    "\n",
    "train_mask_split = [split_mask(img) for img in train_mask]\n",
    "train_mask_split = [t_split[i] for t_split in train_mask_split for i in [0, 1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = [split(img) for img in test]\n",
    "test_split = [t_split[i] for t_split in test_split for i in [0, 1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1328/1328 [09:10<00:00,  2.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_split) * 4, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), np.uint8)\n",
    "Y_train = np.zeros((len(train_split) * 4, IMG_HEIGHT, IMG_WIDTH, 1), np.uint8)\n",
    "Z_train = np.zeros((len(train_split) * 4, IMG_HEIGHT, IMG_WIDTH, 3), np.uint8)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, (img, masks) in enumerate(zip(tqdm(train_split), train_mask_split)):\n",
    "    img = img[:, :, :IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    img_mean = np.mean(img, axis=2).astype(np.uint8)\n",
    "    for c in range(IMG_CHANNELS):\n",
    "        img[:,:,c] = img_mean\n",
    "    X_train[n * 4 + 0] = img\n",
    "    X_train[n * 4 + 1] = np.fliplr(img)\n",
    "    X_train[n * 4 + 2] = np.flipud(img)\n",
    "    X_train[n * 4 + 3] = np.flipud(np.fliplr(img))\n",
    "\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH), np.uint8)\n",
    "    mask_lr = np.zeros((IMG_HEIGHT, IMG_WIDTH), np.uint8)\n",
    "    mask_ud = np.zeros((IMG_HEIGHT, IMG_WIDTH), np.uint8)\n",
    "    mask_lr_ud = np.zeros((IMG_HEIGHT, IMG_WIDTH), np.uint8)\n",
    "    for mask_id in range(masks.shape[0]):\n",
    "        mask_ = masks[mask_id, :, :]\n",
    "        mask_ = mask_ // 255\n",
    "        mask_ = resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                       preserve_range=True).astype(np.uint8)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "        mask_lr = np.maximum(mask_lr, np.fliplr(mask_))\n",
    "        mask_ud = np.maximum(mask_ud, np.flipud(mask_))\n",
    "        mask_lr_ud = np.maximum(mask_lr_ud, np.flipud(np.fliplr(mask_)))\n",
    "        \n",
    "    Y_train[4*n + 0, :, :, 0] = mask\n",
    "    Y_train[4*n + 1, :, :, 0] = mask_lr\n",
    "    Y_train[4*n + 2, :, :, 0] = mask_ud\n",
    "    Y_train[4*n + 3, :, :, 0] = mask_lr_ud\n",
    "  \n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH), np.uint8)\n",
    "    mask_lr = np.zeros((IMG_HEIGHT, IMG_WIDTH), np.uint8)\n",
    "    mask_ud = np.zeros((IMG_HEIGHT, IMG_WIDTH), np.uint8)\n",
    "    mask_lr_ud = np.zeros((IMG_HEIGHT, IMG_WIDTH), np.uint8)\n",
    "    for mask_id in range(masks.shape[0]):\n",
    "        mask_ = masks[mask_id, :, :]\n",
    "        mask_ = mask_ // 255\n",
    "        mask_ = resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                       preserve_range=True).astype(np.uint8)\n",
    "        mask_ = binary_dilation(mask_, selem=square(3))\n",
    "        mask += mask_\n",
    "        mask_lr += np.fliplr(mask_)\n",
    "        mask_ud += np.flipud(mask_)\n",
    "        mask_lr_ud += np.flipud(np.fliplr(mask_))\n",
    "        \n",
    "    Z_train[4*n + 0, :, :, 0] = (mask > 1)\n",
    "    Z_train[4*n + 1, :, :, 0] = (mask_lr > 1)\n",
    "    Z_train[4*n + 2, :, :, 0] = (mask_ud > 1)\n",
    "    Z_train[4*n + 3, :, :, 0] = (mask_lr_ud > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5312/5312 [00:01<00:00, 4504.44it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_split) * 4)):\n",
    "    Z_train[i, :, :, 1] = Y_train[i, :, :, 0]\n",
    "    Z_train[i, :, :, 2] = np.where(Z_train[i, :, :, 0] == 1, 0, 1 - Y_train[i, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6038/6038 [01:06<00:00, 90.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get and resize test images and masks\n",
    "X_test = np.zeros((len(test_split) * 4, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), np.uint8)\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, img in enumerate(tqdm(test_split)):\n",
    "    img = img[:, :, :IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    img_mean = np.mean(img, axis=2).astype(np.uint8)\n",
    "    for c in range(IMG_CHANNELS):\n",
    "        img[:,:,c] = img_mean\n",
    "    X_test[n * 4 + 0] = img\n",
    "    X_test[n * 4 + 1] = np.fliplr(img)\n",
    "    X_test[n * 4 + 2] = np.flipud(img)\n",
    "    X_test[n * 4 + 3] = np.flipud(np.fliplr(img))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c0523b03-1fc5-4505-a1b8-eb35ee617c8a",
    "_uuid": "d4f8327802a1ec6139ce0585953986272ba62ce1"
   },
   "source": [
    "Let's see if things look all right by drawing some random images and their associated masks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c3b9f148-1dba-4b6a-981b-6cdbf394fc3c",
    "_uuid": "986488a4c5223576be370e224426a30431911eb2"
   },
   "source": [
    "# Build and train our neural network\n",
    "Next we build our U-Net model, loosely based on [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf) and very similar to [this repo](https://github.com/jocicmarko/ultrasound-nerve-segmentation) from the Kaggle Ultrasound Nerve Segmentation competition.\n",
    "\n",
    "![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def pixelwise_crossentropy(target, output):\n",
    "    _epsilon = 10e-8\n",
    "    output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)\n",
    "    weight = 30 * target[:,:,:,0:1] + 3 * target[:,:,:,1:2] + 1 * target[:,:,:,2:3]\n",
    "    return - tf.reduce_sum(target * weight *  tf.log(output) +\n",
    "                           (1 - target)  *  tf.log(1 - output),\n",
    "                           len(output.get_shape()) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "class SpeckleNoise(Layer):\n",
    "    \"\"\"Apply multiplicative one-centered Gaussian noise.\n",
    "    This is useful to mitigate overfitting\n",
    "    (you could see it as a form of random data augmentation).\n",
    "    Speckle Noise (GS) is a natural choice as corruption process\n",
    "    for real valued inputs.\n",
    "    As it is a regularization layer, it is only active at training time.\n",
    "    # Arguments\n",
    "        stddev: float, standard deviation of the noise distribution.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    \"\"\"\n",
    "\n",
    "#    @interfaces.legacy_specklenoise_support\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super(SpeckleNoise, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        def noised():\n",
    "            return K.clip(inputs * K.random_normal(shape=K.shape(inputs),\n",
    "                                            mean=1.,\n",
    "                                            stddev=self.stddev), 0.0, 1.0)\n",
    "        return K.in_train_phase(noised, inputs, training=training)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'stddev': self.stddev}\n",
    "        base_config = super(SpeckleNoise, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "def perspective_transform(images, sequence):\n",
    "    if len(images[0].shape) > 2 and images[0].shape[2] == 2:\n",
    "        images = [img.astype(dtype=np.uint8) for img in images]\n",
    "        images = sequence.augment_images(images)\n",
    "        images = [img.astype(dtype=np.bool) for img in images]\n",
    "    else:\n",
    "        images = sequence.augment_images(images)\n",
    "    return images\n",
    "\n",
    "def additive_Gaussian_noise(images, scale):\n",
    "    transformer = iaa.AdditiveGaussianNoise(scale=(0,scale*255), deterministic=True)\n",
    "    return augment_on_df(images, transformer)\n",
    "    \n",
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "#from https://www.kaggle.com/bguberfain/elastic-transform-for-data-augmentation/code\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "def elastic_transform(image, alpha, sigma, alpha_affine, random_state=None):\n",
    "    \"\"\"Elastic deformation of images as described in [Simard2003]_ (with modifications).\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "         Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "         Proc. of the International Conference on Document Analysis and\n",
    "         Recognition, 2003.\n",
    "\n",
    "     Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5\n",
    "    \"\"\"\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "\n",
    "    shape = image.shape\n",
    "    shape_size = shape[:2]\n",
    "    \n",
    "    # Random affine\n",
    "    center_square = np.float32(shape_size) // 2\n",
    "    square_size = min(shape_size) // 3\n",
    "    pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size], center_square - square_size])\n",
    "    pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "    image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dz = np.zeros_like(dx)\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
    "\n",
    "    return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_cell_guid": "c1dbc57c-b497-4ccb-b077-2053203ab7ed",
    "_uuid": "0aa97d66c29f45dfac9b0f45fcf74ba0e778ba5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras import layers\\n\\ninputs = Input((IMG_HEIGHT, IMG_WIDTH, 3))\\n\\ns = Lambda(lambda x: x/255)(inputs)\\nx = SpeckleNoise(0.01)(s)\\n\\nconv_a0 = layers.Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\\nconv_a0 = Dropout(0.1)(conv_a0)\\nconv_a0 = layers.Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv_a0)\\npool_a0 = layers.MaxPooling2D((2, 2)) (conv_a0)\\n\\nconv_a = layers.Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool_a0)\\nconv_a = Dropout(0.1)(conv_a)\\nconv_a = layers.Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv_a)\\npool0 = layers.MaxPooling2D((2, 2)) (conv_a)\\n\\nconv1 = layers.Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(pool0)\\nconv1 = Dropout(0.1)(conv1)\\nconv1 = layers.Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv1)\\npool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\\n\\nconv2 = layers.Conv2D(64, (3, 3), activation='elu', kernel_initializer ='he_normal', padding='same')(pool1)\\nconv2 = Dropout(0.2)(conv2)\\nconv2 = layers.Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv2)\\npool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\\n\\nconv3 = layers.Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(pool2)\\nconv3 = Dropout(0.2)(conv3)\\nconv3 = layers.Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv3)\\npool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\\n\\nconv4 = layers.Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(pool3)\\nconv4 = Dropout(0.3)(conv4)\\nconv4 = layers.Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv4)\\npool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\\n\\nconv5 = layers.Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(pool4)\\nconv5 = Dropout(0.3)(conv5)\\nconv5 = layers.Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv5)\\n\\nup6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5)\\nup6 = concatenate([up6, conv4])\\nconv6 = layers.Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up6)\\nconv6 = Dropout(0.3)(conv6)\\nconv6 = layers.Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv6)\\n\\nup7 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(conv6)\\nup7 = concatenate([up7, conv3]) \\nconv7 = layers.Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up7)\\nconv7 = Dropout(0.2)(conv7)\\nconv7 = layers.Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv7)\\n\\nup8 = Conv2DTranspose(64, (2,2), strides = (2,2), padding='same')(conv7)\\nup8 = concatenate([up8, conv2])\\nconv8 = layers.Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up8)\\nconv8 = Dropout(0.2)(conv8)\\nconv8 = layers.Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv8)\\n\\nup9 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(conv8)\\nup9 = layers.concatenate([up9, conv1])\\nconv9 = layers.Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up9)\\nconv9 = Dropout(0.1)(conv9)\\nconv9 = layers.Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv9)\\n\\nup10 = Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(conv9)\\nup10 = layers.concatenate([up10, conv_a])\\nconv10 = layers.Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up10)\\nconv10 = Dropout(0.1)(conv10)\\nconv10 = layers.Conv2D(16, (3, 3), activation='elu', kernel_initializer = 'he_normal', padding='same')(conv10)\\n\\nconv_a0 = Conv2DTranspose(8, (2, 2), strides=(2,2), padding='same') (conv10)\\nconv_a0 = layers.Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv_a0)\\nconv_a0 = Dropout(0.1)(conv_a0)\\nconv_a0 = layers.Conv2D(8, (3, 3), activation='elu', kernel_initializer = 'he_normal', padding='same')(conv_a0)\\n\\nconv_last = layers.Conv2D(3, (1, 1), activation='sigmoid')(conv_a0)\\n\\nmodel = Model(inputs=[inputs], outputs=[conv_last])\\nmodel.compile(optimizer=Adam(clipvalue=5), loss=pixelwise_crossentropy)\\nmodel.summary()\\n\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from https://github.com/zizhaozhang/unet-tensorflow-keras/blob/master/model.py\n",
    "\"\"\"\n",
    "from keras import layers\n",
    "\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "s = Lambda(lambda x: x/255)(inputs)\n",
    "x = SpeckleNoise(0.01)(s)\n",
    "\n",
    "conv_a0 = layers.Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "conv_a0 = Dropout(0.1)(conv_a0)\n",
    "conv_a0 = layers.Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv_a0)\n",
    "pool_a0 = layers.MaxPooling2D((2, 2)) (conv_a0)\n",
    "\n",
    "conv_a = layers.Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool_a0)\n",
    "conv_a = Dropout(0.1)(conv_a)\n",
    "conv_a = layers.Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv_a)\n",
    "pool0 = layers.MaxPooling2D((2, 2)) (conv_a)\n",
    "\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(pool0)\n",
    "conv1 = Dropout(0.1)(conv1)\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv1)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='elu', kernel_initializer ='he_normal', padding='same')(pool1)\n",
    "conv2 = Dropout(0.2)(conv2)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv2)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(pool2)\n",
    "conv3 = Dropout(0.2)(conv3)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv3)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(pool3)\n",
    "conv4 = Dropout(0.3)(conv4)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv4)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = layers.Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(pool4)\n",
    "conv5 = Dropout(0.3)(conv5)\n",
    "conv5 = layers.Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv5)\n",
    "\n",
    "up6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "up6 = concatenate([up6, conv4])\n",
    "conv6 = layers.Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up6)\n",
    "conv6 = Dropout(0.3)(conv6)\n",
    "conv6 = layers.Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    "\n",
    "up7 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(conv6)\n",
    "up7 = concatenate([up7, conv3]) \n",
    "conv7 = layers.Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up7)\n",
    "conv7 = Dropout(0.2)(conv7)\n",
    "conv7 = layers.Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    "\n",
    "up8 = Conv2DTranspose(64, (2,2), strides = (2,2), padding='same')(conv7)\n",
    "up8 = concatenate([up8, conv2])\n",
    "conv8 = layers.Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up8)\n",
    "conv8 = Dropout(0.2)(conv8)\n",
    "conv8 = layers.Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv8)\n",
    "\n",
    "up9 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(conv8)\n",
    "up9 = layers.concatenate([up9, conv1])\n",
    "conv9 = layers.Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up9)\n",
    "conv9 = Dropout(0.1)(conv9)\n",
    "conv9 = layers.Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv9)\n",
    "\n",
    "up10 = Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(conv9)\n",
    "up10 = layers.concatenate([up10, conv_a])\n",
    "conv10 = layers.Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up10)\n",
    "conv10 = Dropout(0.1)(conv10)\n",
    "conv10 = layers.Conv2D(16, (3, 3), activation='elu', kernel_initializer = 'he_normal', padding='same')(conv10)\n",
    "\n",
    "conv_a0 = Conv2DTranspose(8, (2, 2), strides=(2,2), padding='same') (conv10)\n",
    "conv_a0 = layers.Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv_a0)\n",
    "conv_a0 = Dropout(0.1)(conv_a0)\n",
    "conv_a0 = layers.Conv2D(8, (3, 3), activation='elu', kernel_initializer = 'he_normal', padding='same')(conv_a0)\n",
    "\n",
    "conv_last = layers.Conv2D(3, (1, 1), activation='sigmoid')(conv_a0)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[conv_last])\n",
    "model.compile(optimizer=Adam(clipvalue=5), loss=pixelwise_crossentropy)\n",
    "model.summary()\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "72330944-6ce7-4070-b276-c3c4b20c4fe5",
    "_uuid": "92350b6e18cc50f3fa7b6e9a02d39fcbff8238f7"
   },
   "source": [
    "*Update: Changed to ELU units, added dropout.*\n",
    "\n",
    "Next we fit the model on the training data, using a validation split of 0.1. We use a small batch size because we have so little data. I recommend using checkpointing and early stopping when training your model. I won't do it here to make things a bit more reproducible (although it's very likely that your results will be different anyway). I'll just train for 10 epochs, which takes around 10 minutes in the Kaggle kernel with the current parameters. \n",
    "\n",
    "*Update: Added early stopping and checkpointing and increased to 30 epochs.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Layer\n",
    "from keras.engine import InputSpec\n",
    "from keras import backend as K\n",
    "try:\n",
    "    from keras import initializations\n",
    "except ImportError:\n",
    "    from keras import initializers as initializations\n",
    "\n",
    "class Scale(Layer):\n",
    "    '''Learns a set of weights and biases used for scaling the input data.\n",
    "    the output consists simply in an element-wise multiplication of the input\n",
    "    and a sum of a set of constants:\n",
    "        out = in * gamma + beta,\n",
    "    where 'gamma' and 'beta' are the weights and biases larned.\n",
    "    # Arguments\n",
    "        axis: integer, axis along which to normalize in mode 0. For instance,\n",
    "        \n",
    "            if your input tensor has shape (samples, channels, rows, cols),\n",
    "            set axis to 1 to normalize per feature map (channels axis).\n",
    "        momentum: momentum in the computation of the\n",
    "            exponential average of the mean and standard deviation\n",
    "            of the data, for feature-wise normalization.\n",
    "        weights: Initialization weights.\n",
    "            List of 2 Numpy arrays, with shapes:\n",
    "            `[(input_shape,), (input_shape,)]`\n",
    "        beta_init: name of initialization function for shift parameter\n",
    "            (see [initializations](../initializations.md)), or alternatively,\n",
    "            Theano/TensorFlow function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "        gamma_init: name of initialization function for scale parameter (see\n",
    "            [initializations](../initializations.md)), or alternatively,\n",
    "            Theano/TensorFlow function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "    '''\n",
    "    def __init__(self, weights=None, axis=-1, momentum = 0.9, beta_init='zero', gamma_init='one', **kwargs):\n",
    "        self.momentum = momentum\n",
    "        self.axis = axis\n",
    "        self.beta_init = initializations.get(beta_init)\n",
    "        self.gamma_init = initializations.get(gamma_init)\n",
    "        self.initial_weights = weights\n",
    "        super(Scale, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        shape = (int(input_shape[self.axis]),)\n",
    "\n",
    "        # Compatibility with TensorFlow >= 1.0.0\n",
    "        self.gamma = K.variable(self.gamma_init(shape), name='{}_gamma'.format(self.name))\n",
    "        self.beta = K.variable(self.beta_init(shape), name='{}_beta'.format(self.name))\n",
    "        #self.gamma = self.gamma_init(shape, name='{}_gamma'.format(self.name))\n",
    "        #self.beta = self.beta_init(shape, name='{}_beta'.format(self.name))\n",
    "        self.trainable_weights = [self.gamma, self.beta]\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        input_shape = self.input_spec[0].shape\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "\n",
    "        out = K.reshape(self.gamma, broadcast_shape) * x + K.reshape(self.beta, broadcast_shape)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"momentum\": self.momentum, \"axis\": self.axis}\n",
    "        base_config = super(Scale, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "bn_axis = 3\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(3000)\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    '''The identity_block is the block that has no conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(nb_filter1, (1, 1), name=conv_name_base + '2a', bias=False)(input_tensor)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
    "    x = layers.Conv2D(nb_filter2, kernel_size, kernel_size,\n",
    "                      name=conv_name_base + '2b', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
    "\n",
    "    x = merge([x, input_tensor], mode='sum', name='res' + str(stage) + block)\n",
    "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    '''conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(nb_filter1, (1, 1), subsample=strides,\n",
    "                      name=conv_name_base + '2a', bias=False)(input_tensor)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
    "    x = layers.Conv2D(nb_filter2, kernel_size, kernel_size,\n",
    "                      name=conv_name_base + '2b', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Convolution2D(nb_filter3, (1, 1), subsample=strides,\n",
    "                             name=conv_name_base + '1', bias=False)(input_tensor)\n",
    "    shortcut = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "    shortcut = Scale(axis=bn_axis, name=scale_name_base + '1')(shortcut)\n",
    "\n",
    "    x = merge([x, shortcut], mode='sum', name='res' + str(stage) + block)\n",
    "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
    "    return x\n",
    "\n",
    "def resnet152_model(img_rows, img_cols, color_type=1, num_classes=None):\n",
    "    \"\"\"\n",
    "    Resnet 152 Model for Keras\n",
    "    Model Schema and layer naming follow that of the original Caffe implementation\n",
    "    https://github.com/KaimingHe/deep-residual-networks\n",
    "    ImageNet Pretrained Weights \n",
    "    Theano: https://drive.google.com/file/d/0Byy2AcGyEVxfZHhUT3lWVWxRN28/view?usp=sharing\n",
    "    TensorFlow: https://drive.google.com/file/d/0Byy2AcGyEVxfeXExMzNNOHpEODg/view?usp=sharing\n",
    "    Parameters:\n",
    "      img_rows, img_cols - resolution of inputs\n",
    "      channel - 1 for grayscale, 3 for color \n",
    "      num_classes - number of class labels for our classification task\n",
    "    \"\"\"\n",
    "    eps = 1.1e-5\n",
    "\n",
    "    global bn_axis\n",
    "    img_input = Input(shape=(img_rows, img_cols, color_type), name='data')\n",
    "\n",
    "    x = SpeckleNoise(0.01)(img_input)\n",
    "    x = Lambda(lambda x:x/255)(img_input)\n",
    "    \n",
    "    x_a = layers.Conv2D(16,(1,1), activation='elu', kernel_initializer='he_normal', padding='same')(x)\n",
    "    \n",
    "    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(x)\n",
    "    x0 = Convolution2D(64, (7, 7), subsample=(2, 2), name='conv1', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name='bn_conv1')(x0)\n",
    "    x = Scale(axis=bn_axis, name='scale_conv1')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x1 = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x1, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x2 = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    for i in range(1,8):\n",
    "        x = identity_block(x2, 3, [128, 128, 512], stage=3, block='b'+str(i))\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x3 = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    for i in range(1,36):\n",
    "        x = identity_block(x3, 3, [256, 256, 1024], stage=4, block='b'+str(i))\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    up6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    up6 = concatenate([up6, x3])\n",
    "    conv6 = layers.Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up6)\n",
    "    conv6 = Dropout(0.3)(conv6)\n",
    "    conv6 = layers.Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    "    conv6 = Dropout(0.3)(conv6)\n",
    "    conv6 = layers.Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(conv6)\n",
    "    up7 = concatenate([up7, x2]) \n",
    "    conv7 = layers.Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up7)\n",
    "    conv7 = Dropout(0.2)(conv7)\n",
    "    conv7 = layers.Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    "    conv7 = Dropout(0.2)(conv7)\n",
    "    conv7 = layers.Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(64, (2,2), strides = (2,2), padding='same')(conv7)\n",
    "    up8 = concatenate([up8, x1])\n",
    "    conv8 = layers.Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up8)\n",
    "    conv8 = Dropout(0.2)(conv8)\n",
    "    conv8 = layers.Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv8)\n",
    "    conv8 = Dropout(0.2)(conv8)\n",
    "    conv8 = layers.Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv8)\n",
    "\n",
    "    up9 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(conv8)\n",
    "    up9 = layers.concatenate([up9, x0])\n",
    "    conv9 = layers.Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up9)\n",
    "    conv9 = Dropout(0.1)(conv9)\n",
    "    conv9 = layers.Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv9)\n",
    "    conv9 = Dropout(0.1)(conv9)\n",
    "    conv9 = layers.Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv9)\n",
    "\n",
    "    up10 = Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(conv9)\n",
    "    up10 = layers.concatenate([up10, x_a])\n",
    "    conv10 = layers.Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up10)\n",
    "    conv10 = Dropout(0.1)(conv10)\n",
    "    conv10 = layers.Conv2D(16, (3, 3), activation='elu', kernel_initializer = 'he_normal', padding='same')(conv10)\n",
    "    \n",
    "    x_new = layers.Conv2D(3, (1, 1), activation='sigmoid')(conv10)\n",
    "    \n",
    "    model = Model(img_input, x_new)\n",
    "    \n",
    "    weights_path = 'resnet152_weights_tf.h5'\n",
    "\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    model.compile(optimizer=Adam(clipvalue=5), loss=pixelwise_crossentropy)\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "bn_axis = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#x_train, x_valid, z_train, z_valid = train_test_split(X_train, Z_train, test_size=0.1, random_state=8011)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:188: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (7, 7), name=\"conv1\", strides=(2, 2), use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:139: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), name=\"res2a_branch2a\", strides=(1, 1), use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:146: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"res2a_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:151: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res2a_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:156: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res2a_branch1\", strides=(1, 1), use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:160: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), name=\"res2b_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"res2b_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res2b_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:117: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), name=\"res2c_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"res2c_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res2c_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:139: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), name=\"res3a_branch2a\", strides=(2, 2), use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:146: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"res3a_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:151: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3a_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:156: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3a_branch1\", strides=(2, 2), use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), name=\"res3b1_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"res3b1_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3b1_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), name=\"res3b2_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"res3b2_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3b2_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), name=\"res3b3_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"res3b3_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3b3_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), name=\"res3b4_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"res3b4_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3b4_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), name=\"res3b5_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"res3b5_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3b5_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), name=\"res3b6_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"res3b6_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3b6_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), name=\"res3b7_branch2a\", use_bias=False)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"res3b7_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3b7_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:139: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4a_branch2a\", strides=(2, 2), use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:146: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4a_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:151: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4a_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:156: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4a_branch1\", strides=(2, 2), use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b1_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b1_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b1_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b2_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b2_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b2_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b3_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b3_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b3_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b4_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b4_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b4_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b5_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b5_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b5_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b6_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b6_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b6_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b7_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b7_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b7_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b8_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b8_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b8_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b9_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b9_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b9_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b10_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b10_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b10_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b11_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b11_branch2b\", use_bias=False)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b11_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b12_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b12_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b12_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b13_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b13_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b13_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b14_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b14_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b14_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b15_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b15_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b15_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b16_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b16_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b16_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b17_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b17_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b17_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b18_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b18_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b18_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b19_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b19_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b19_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b20_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b20_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b20_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b21_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b21_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b21_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b22_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b22_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b22_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b23_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b23_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b23_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b24_branch2a\", use_bias=False)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b24_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b24_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b25_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b25_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b25_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b26_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b26_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b26_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b27_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b27_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b27_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b28_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b28_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b28_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b29_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b29_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b29_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b30_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b30_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b30_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b31_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b31_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b31_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b32_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b32_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b32_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b33_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b33_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b33_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b34_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b34_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b34_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b35_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b35_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b35_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:139: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res5a_branch2a\", strides=(2, 2), use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:146: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"res5a_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:151: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (1, 1), name=\"res5a_branch2c\", use_bias=False)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:156: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (1, 1), name=\"res5a_branch1\", strides=(2, 2), use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res5b_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"res5b_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (1, 1), name=\"res5b_branch2c\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res5c_branch2a\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"res5c_branch2b\", use_bias=False)`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (1, 1), name=\"res5c_branch2c\", use_bias=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 256, 256, 3)  0           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1_zeropadding (ZeroPadding2 (None, 262, 262, 3)  0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 128, 64) 9408        conv1_zeropadding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_conv1 (Scale)             (None, 128, 128, 64) 128         bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           scale_conv1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 128, 128, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 64, 64, 64)   0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4096        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2a (Scale)        (None, 64, 64, 64)   128         bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2b (Scale)        (None, 64, 64, 64)   128         bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16384       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2c (Scale)        (None, 64, 64, 256)  512         bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch1 (Scale)         (None, 64, 64, 256)  512         bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a (Merge)                   (None, 64, 64, 256)  0           scale2a_branch2c[0][0]           \n",
      "                                                                 scale2a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2a_relu (Activation)         (None, 64, 64, 256)  0           res2a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16384       res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2a (Scale)        (None, 64, 64, 64)   128         bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2b (Scale)        (None, 64, 64, 64)   128         bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2c (Scale)        (None, 64, 64, 256)  512         bn2b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b (Merge)                   (None, 64, 64, 256)  0           scale2b_branch2c[0][0]           \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2b_relu (Activation)         (None, 64, 64, 256)  0           res2b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16384       res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2a (Scale)        (None, 64, 64, 64)   128         bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2b (Scale)        (None, 64, 64, 64)   128         bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2c (Scale)        (None, 64, 64, 256)  512         bn2c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c (Merge)                   (None, 64, 64, 256)  0           scale2c_branch2c[0][0]           \n",
      "                                                                 res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2c_relu (Activation)         (None, 64, 64, 256)  0           res2c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 64, 64, 256)  0           res2c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32768       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2a (Scale)        (None, 32, 32, 128)  256         bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a_relu (Activation (None, 32, 32, 128)  0           scale3a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_zeropadding (Zer (None, 34, 34, 128)  0           res3a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147456      res3a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2b (Scale)        (None, 32, 32, 128)  256         bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_relu (Activation (None, 32, 32, 128)  0           scale3a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 512)  65536       res3a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131072      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2c (Scale)        (None, 32, 32, 512)  1024        bn3a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch1 (Scale)         (None, 32, 32, 512)  1024        bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a (Merge)                   (None, 32, 32, 512)  0           scale3a_branch2c[0][0]           \n",
      "                                                                 scale3a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3a_relu (Activation)         (None, 32, 32, 512)  0           res3a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a (Conv2D)        (None, 32, 32, 128)  65536       res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2a (BatchNormalizat (None, 32, 32, 128)  512         res3b7_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2a (Scale)       (None, 32, 32, 128)  256         bn3b7_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a_relu (Activatio (None, 32, 32, 128)  0           scale3b7_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_zeropadding (Ze (None, 34, 34, 128)  0           res3b7_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b (Conv2D)        (None, 32, 32, 128)  147456      res3b7_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2b (BatchNormalizat (None, 32, 32, 128)  512         res3b7_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2b (Scale)       (None, 32, 32, 128)  256         bn3b7_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_relu (Activatio (None, 32, 32, 128)  0           scale3b7_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2c (Conv2D)        (None, 32, 32, 512)  65536       res3b7_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2c (BatchNormalizat (None, 32, 32, 512)  2048        res3b7_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2c (Scale)       (None, 32, 32, 512)  1024        bn3b7_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7 (Merge)                  (None, 32, 32, 512)  0           scale3b7_branch2c[0][0]          \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_relu (Activation)        (None, 32, 32, 512)  0           res3b7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 512)  0           res3b7_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131072      dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2a (Scale)        (None, 16, 16, 256)  512         bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a_relu (Activation (None, 16, 16, 256)  0           scale4a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_zeropadding (Zer (None, 18, 18, 256)  0           res4a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 16, 16, 256)  589824      res4a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2b (Scale)        (None, 16, 16, 256)  512         bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_relu (Activation (None, 16, 16, 256)  0           scale4a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 262144      res4a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 524288      dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2c (Scale)        (None, 16, 16, 1024) 2048        bn4a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch1 (Scale)         (None, 16, 16, 1024) 2048        bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4a (Merge)                   (None, 16, 16, 1024) 0           scale4a_branch2c[0][0]           \n",
      "                                                                 scale4a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4a_relu (Activation)         (None, 16, 16, 1024) 0           res4a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a (Conv2D)       (None, 16, 16, 256)  262144      res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2a (BatchNormaliza (None, 16, 16, 256)  1024        res4b35_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2a (Scale)      (None, 16, 16, 256)  512         bn4b35_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a_relu (Activati (None, 16, 16, 256)  0           scale4b35_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_zeropadding (Z (None, 18, 18, 256)  0           res4b35_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b (Conv2D)       (None, 16, 16, 256)  589824      res4b35_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2b (BatchNormaliza (None, 16, 16, 256)  1024        res4b35_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2b (Scale)      (None, 16, 16, 256)  512         bn4b35_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_relu (Activati (None, 16, 16, 256)  0           scale4b35_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2c (Conv2D)       (None, 16, 16, 1024) 262144      res4b35_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2c (BatchNormaliza (None, 16, 16, 1024) 4096        res4b35_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2c (Scale)      (None, 16, 16, 1024) 2048        bn4b35_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35 (Merge)                 (None, 16, 16, 1024) 0           scale4b35_branch2c[0][0]         \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_relu (Activation)       (None, 16, 16, 1024) 0           res4b35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 1024) 0           res4b35_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524288      dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2097152     dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch1 (Scale)         (None, 8, 8, 2048)   4096        bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a (Merge)                   (None, 8, 8, 2048)   0           scale5a_branch2c[0][0]           \n",
      "                                                                 scale5a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res5a_relu (Activation)         (None, 8, 8, 2048)   0           res5a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1048576     res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b (Merge)                   (None, 8, 8, 2048)   0           scale5b_branch2c[0][0]           \n",
      "                                                                 res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5b_relu (Activation)         (None, 8, 8, 2048)   0           res5b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1048576     res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c (Merge)                   (None, 8, 8, 2048)   0           scale5c_branch2c[0][0]           \n",
      "                                                                 res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5c_relu (Activation)         (None, 8, 8, 2048)   0           res5c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 8, 8, 2048)   0           res5c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 16, 16, 256)  2097408     dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16, 16, 1280) 0           conv2d_transpose_6[0][0]         \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 256)  2949376     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 256)  0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 256)  590080      dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 256)  0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 256)  590080      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 32, 32, 128)  131200      conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 640)  0           conv2d_transpose_7[0][0]         \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 128)  737408      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 32, 32, 128)  0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 128)  147584      dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 32, 32, 128)  0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 128)  147584      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 64, 64, 64)   32832       conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 64, 64, 320)  0           conv2d_transpose_8[0][0]         \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 64)   184384      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 64, 64, 64)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 64)   36928       dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 64, 64, 64)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 64)   36928       dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 128, 128, 32) 8224        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 128, 128, 96) 0           conv2d_transpose_9[0][0]         \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 128, 128, 32) 27680       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 128, 128, 32) 0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 128, 128, 32) 9248        dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 128, 128, 32) 0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 128, 128, 32) 9248        dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 256, 256, 16) 2064        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 16) 64          lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 256, 256, 32) 0           conv2d_transpose_10[0][0]        \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 256, 256, 16) 0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 256, 256, 16) 2320        dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 256, 256, 3)  51          conv2d_30[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,300,003\n",
      "Trainable params: 26,262,243\n",
      "Non-trainable params: 37,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "738/737 [==============================] - 308s 417ms/step - loss: 0.4315 - val_loss: 0.5297\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52975, saving model to Resnet152_UNet.h5\n",
      "Epoch 2/30\n",
      "738/737 [==============================] - 286s 387ms/step - loss: 0.3437 - val_loss: 0.4168\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52975 to 0.41684, saving model to Resnet152_UNet.h5\n",
      "Epoch 3/30\n",
      "738/737 [==============================] - 286s 387ms/step - loss: 0.3215 - val_loss: 0.3521\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.41684 to 0.35213, saving model to Resnet152_UNet.h5\n",
      "Epoch 4/30\n",
      "738/737 [==============================] - 286s 387ms/step - loss: 0.3002 - val_loss: 0.4916\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35213\n",
      "Epoch 5/30\n",
      "738/737 [==============================] - 286s 387ms/step - loss: 0.2887 - val_loss: 0.9229\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35213\n",
      "Epoch 6/30\n",
      "738/737 [==============================] - 286s 387ms/step - loss: 0.2897 - val_loss: 0.3263\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35213 to 0.32627, saving model to Resnet152_UNet.h5\n",
      "Epoch 7/30\n",
      "738/737 [==============================] - 285s 387ms/step - loss: 0.2759 - val_loss: 0.3426\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32627\n",
      "Epoch 8/30\n",
      "738/737 [==============================] - 285s 387ms/step - loss: 0.2669 - val_loss: 0.3209\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.32627 to 0.32087, saving model to Resnet152_UNet.h5\n",
      "Epoch 9/30\n",
      "738/737 [==============================] - 286s 387ms/step - loss: 0.2684 - val_loss: 1.0497\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32087\n",
      "Epoch 10/30\n",
      "738/737 [==============================] - 285s 387ms/step - loss: 0.2655 - val_loss: 0.9917\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32087\n",
      "Epoch 11/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2607 - val_loss: 0.2387\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.32087 to 0.23867, saving model to Resnet152_UNet.h5\n",
      "Epoch 12/30\n",
      "738/737 [==============================] - 286s 387ms/step - loss: 0.2574 - val_loss: 0.3991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.23867\n",
      "Epoch 13/30\n",
      "738/737 [==============================] - 285s 387ms/step - loss: 0.2569 - val_loss: 1.0043\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.23867\n",
      "Epoch 14/30\n",
      "738/737 [==============================] - 285s 387ms/step - loss: 0.2554 - val_loss: 0.3612\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.23867\n",
      "Epoch 15/30\n",
      "738/737 [==============================] - 285s 386ms/step - loss: 0.2505 - val_loss: 0.5685\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.23867\n",
      "Epoch 16/30\n",
      "738/737 [==============================] - 285s 386ms/step - loss: 0.2494 - val_loss: 1.7092\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.23867\n",
      "Epoch 17/30\n",
      "738/737 [==============================] - 285s 386ms/step - loss: 0.2510 - val_loss: 1.0126\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.23867\n",
      "Epoch 18/30\n",
      "738/737 [==============================] - 285s 387ms/step - loss: 0.2460 - val_loss: 0.9050\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.23867\n",
      "Epoch 19/30\n",
      "738/737 [==============================] - 286s 387ms/step - loss: 0.2455 - val_loss: 0.6821\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.23867\n",
      "Epoch 00019: early stopping\n",
      "****************************************\n",
      "Fold: 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 256, 256, 3)  0           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1_zeropadding (ZeroPadding2 (None, 262, 262, 3)  0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 128, 64) 9408        conv1_zeropadding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_conv1 (Scale)             (None, 128, 128, 64) 128         bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           scale_conv1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 128, 128, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 64, 64, 64)   0           dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4096        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2a (Scale)        (None, 64, 64, 64)   128         bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2b (Scale)        (None, 64, 64, 64)   128         bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16384       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2c (Scale)        (None, 64, 64, 256)  512         bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch1 (Scale)         (None, 64, 64, 256)  512         bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a (Merge)                   (None, 64, 64, 256)  0           scale2a_branch2c[0][0]           \n",
      "                                                                 scale2a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2a_relu (Activation)         (None, 64, 64, 256)  0           res2a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16384       res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2a (Scale)        (None, 64, 64, 64)   128         bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2b (Scale)        (None, 64, 64, 64)   128         bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2c (Scale)        (None, 64, 64, 256)  512         bn2b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b (Merge)                   (None, 64, 64, 256)  0           scale2b_branch2c[0][0]           \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2b_relu (Activation)         (None, 64, 64, 256)  0           res2b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16384       res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2a (Scale)        (None, 64, 64, 64)   128         bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2b (Scale)        (None, 64, 64, 64)   128         bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2c (Scale)        (None, 64, 64, 256)  512         bn2c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c (Merge)                   (None, 64, 64, 256)  0           scale2c_branch2c[0][0]           \n",
      "                                                                 res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2c_relu (Activation)         (None, 64, 64, 256)  0           res2c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 64, 64, 256)  0           res2c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32768       dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2a (Scale)        (None, 32, 32, 128)  256         bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a_relu (Activation (None, 32, 32, 128)  0           scale3a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_zeropadding (Zer (None, 34, 34, 128)  0           res3a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147456      res3a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2b (Scale)        (None, 32, 32, 128)  256         bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_relu (Activation (None, 32, 32, 128)  0           scale3a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 512)  65536       res3a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131072      dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2c (Scale)        (None, 32, 32, 512)  1024        bn3a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch1 (Scale)         (None, 32, 32, 512)  1024        bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a (Merge)                   (None, 32, 32, 512)  0           scale3a_branch2c[0][0]           \n",
      "                                                                 scale3a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3a_relu (Activation)         (None, 32, 32, 512)  0           res3a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a (Conv2D)        (None, 32, 32, 128)  65536       res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2a (BatchNormalizat (None, 32, 32, 128)  512         res3b7_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2a (Scale)       (None, 32, 32, 128)  256         bn3b7_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a_relu (Activatio (None, 32, 32, 128)  0           scale3b7_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_zeropadding (Ze (None, 34, 34, 128)  0           res3b7_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b (Conv2D)        (None, 32, 32, 128)  147456      res3b7_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2b (BatchNormalizat (None, 32, 32, 128)  512         res3b7_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2b (Scale)       (None, 32, 32, 128)  256         bn3b7_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_relu (Activatio (None, 32, 32, 128)  0           scale3b7_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2c (Conv2D)        (None, 32, 32, 512)  65536       res3b7_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2c (BatchNormalizat (None, 32, 32, 512)  2048        res3b7_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2c (Scale)       (None, 32, 32, 512)  1024        bn3b7_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7 (Merge)                  (None, 32, 32, 512)  0           scale3b7_branch2c[0][0]          \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_relu (Activation)        (None, 32, 32, 512)  0           res3b7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 32, 32, 512)  0           res3b7_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131072      dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2a (Scale)        (None, 16, 16, 256)  512         bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a_relu (Activation (None, 16, 16, 256)  0           scale4a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_zeropadding (Zer (None, 18, 18, 256)  0           res4a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 16, 16, 256)  589824      res4a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2b (Scale)        (None, 16, 16, 256)  512         bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_relu (Activation (None, 16, 16, 256)  0           scale4a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 262144      res4a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 524288      dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2c (Scale)        (None, 16, 16, 1024) 2048        bn4a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch1 (Scale)         (None, 16, 16, 1024) 2048        bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4a (Merge)                   (None, 16, 16, 1024) 0           scale4a_branch2c[0][0]           \n",
      "                                                                 scale4a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4a_relu (Activation)         (None, 16, 16, 1024) 0           res4a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a (Conv2D)       (None, 16, 16, 256)  262144      res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2a (BatchNormaliza (None, 16, 16, 256)  1024        res4b35_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2a (Scale)      (None, 16, 16, 256)  512         bn4b35_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a_relu (Activati (None, 16, 16, 256)  0           scale4b35_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_zeropadding (Z (None, 18, 18, 256)  0           res4b35_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b (Conv2D)       (None, 16, 16, 256)  589824      res4b35_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2b (BatchNormaliza (None, 16, 16, 256)  1024        res4b35_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2b (Scale)      (None, 16, 16, 256)  512         bn4b35_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_relu (Activati (None, 16, 16, 256)  0           scale4b35_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2c (Conv2D)       (None, 16, 16, 1024) 262144      res4b35_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2c (BatchNormaliza (None, 16, 16, 1024) 4096        res4b35_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2c (Scale)      (None, 16, 16, 1024) 2048        bn4b35_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35 (Merge)                 (None, 16, 16, 1024) 0           scale4b35_branch2c[0][0]         \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_relu (Activation)       (None, 16, 16, 1024) 0           res4b35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 16, 16, 1024) 0           res4b35_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524288      dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2097152     dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch1 (Scale)         (None, 8, 8, 2048)   4096        bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a (Merge)                   (None, 8, 8, 2048)   0           scale5a_branch2c[0][0]           \n",
      "                                                                 scale5a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res5a_relu (Activation)         (None, 8, 8, 2048)   0           res5a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1048576     res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b (Merge)                   (None, 8, 8, 2048)   0           scale5b_branch2c[0][0]           \n",
      "                                                                 res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5b_relu (Activation)         (None, 8, 8, 2048)   0           res5b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1048576     res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c (Merge)                   (None, 8, 8, 2048)   0           scale5c_branch2c[0][0]           \n",
      "                                                                 res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5c_relu (Activation)         (None, 8, 8, 2048)   0           res5c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 8, 8, 2048)   0           res5c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 16, 16, 256)  2097408     dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 16, 16, 1280) 0           conv2d_transpose_11[0][0]        \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 256)  2949376     concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 16, 16, 256)  0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 256)  590080      dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 16, 16, 256)  0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 256)  590080      dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 32, 32, 128)  131200      conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 32, 640)  0           conv2d_transpose_12[0][0]        \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 128)  737408      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 32, 32, 128)  0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 128)  147584      dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 32, 32, 128)  0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 128)  147584      dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 64, 64, 64)   32832       conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64, 64, 320)  0           conv2d_transpose_13[0][0]        \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 64, 64, 64)   184384      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 64, 64, 64)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 64, 64, 64)   36928       dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 64, 64, 64)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 64, 64, 64)   36928       dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 128, 128, 32) 8224        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 128, 128, 96) 0           conv2d_transpose_14[0][0]        \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 128, 128, 32) 27680       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 128, 128, 32) 0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 128, 128, 32) 9248        dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 128, 128, 32) 0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 128, 128, 32) 9248        dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 256, 256, 16) 2064        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 256, 256, 16) 64          lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 256, 256, 32) 0           conv2d_transpose_15[0][0]        \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 256, 256, 16) 0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 256, 256, 16) 2320        dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 256, 256, 3)  51          conv2d_46[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,300,003\n",
      "Trainable params: 26,262,243\n",
      "Non-trainable params: 37,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "738/737 [==============================] - 309s 419ms/step - loss: 0.4209 - val_loss: 8.8905\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 8.89054, saving model to Resnet152_UNet.h5\n",
      "Epoch 2/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.3364 - val_loss: 0.3731\n",
      "\n",
      "Epoch 00002: val_loss improved from 8.89054 to 0.37307, saving model to Resnet152_UNet.h5\n",
      "Epoch 3/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.3089 - val_loss: 0.4009\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.37307\n",
      "Epoch 4/30\n",
      "738/737 [==============================] - 287s 388ms/step - loss: 0.2958 - val_loss: 0.4227\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.37307\n",
      "Epoch 5/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2808 - val_loss: 0.3668\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.37307 to 0.36684, saving model to Resnet152_UNet.h5\n",
      "Epoch 6/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2765 - val_loss: 0.5028\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36684\n",
      "Epoch 7/30\n",
      "738/737 [==============================] - 287s 388ms/step - loss: 0.2644 - val_loss: 1.0375\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36684\n",
      "Epoch 8/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2648 - val_loss: 0.4603\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36684\n",
      "Epoch 9/30\n",
      "738/737 [==============================] - 287s 388ms/step - loss: 0.2613 - val_loss: 0.5577\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.36684\n",
      "Epoch 10/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2582 - val_loss: 0.4655\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.36684\n",
      "Epoch 11/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2526 - val_loss: 0.5925\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.36684\n",
      "Epoch 12/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2509 - val_loss: 0.3077\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36684 to 0.30768, saving model to Resnet152_UNet.h5\n",
      "Epoch 13/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2482 - val_loss: 1.0192\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.30768\n",
      "Epoch 14/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2504 - val_loss: 0.6021\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.30768\n",
      "Epoch 15/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2455 - val_loss: 0.6300\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.30768\n",
      "Epoch 16/30\n",
      "738/737 [==============================] - 287s 388ms/step - loss: 0.2423 - val_loss: 0.4165\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.30768\n",
      "Epoch 17/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2433 - val_loss: 0.7171\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.30768\n",
      "Epoch 18/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2395 - val_loss: 0.3220\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.30768\n",
      "Epoch 19/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2389 - val_loss: 1.5396\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.30768\n",
      "Epoch 20/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2398 - val_loss: 0.2934\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.30768 to 0.29341, saving model to Resnet152_UNet.h5\n",
      "Epoch 21/30\n",
      "738/737 [==============================] - 287s 388ms/step - loss: 0.2364 - val_loss: 0.5404\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.29341\n",
      "Epoch 22/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2353 - val_loss: 1.1765\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.29341\n",
      "Epoch 23/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2338 - val_loss: 0.3631\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.29341\n",
      "Epoch 24/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2357 - val_loss: 0.2798\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.29341 to 0.27979, saving model to Resnet152_UNet.h5\n",
      "Epoch 25/30\n",
      "738/737 [==============================] - 287s 388ms/step - loss: 0.2310 - val_loss: 0.3480\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.27979\n",
      "Epoch 26/30\n",
      "738/737 [==============================] - 287s 388ms/step - loss: 0.2353 - val_loss: 0.3868\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.27979\n",
      "Epoch 27/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2308 - val_loss: 0.5199\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.27979\n",
      "Epoch 28/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2305 - val_loss: 0.3457\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.27979\n",
      "Epoch 29/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2340 - val_loss: 0.2846\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.27979\n",
      "Epoch 30/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2309 - val_loss: 0.3072\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.27979\n",
      "****************************************\n",
      "Fold: 2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 256, 256, 3)  0           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1_zeropadding (ZeroPadding2 (None, 262, 262, 3)  0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 128, 64) 9408        conv1_zeropadding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_conv1 (Scale)             (None, 128, 128, 64) 128         bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           scale_conv1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 128, 128, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 64, 64, 64)   0           dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4096        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2a (Scale)        (None, 64, 64, 64)   128         bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2b (Scale)        (None, 64, 64, 64)   128         bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16384       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2c (Scale)        (None, 64, 64, 256)  512         bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch1 (Scale)         (None, 64, 64, 256)  512         bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a (Merge)                   (None, 64, 64, 256)  0           scale2a_branch2c[0][0]           \n",
      "                                                                 scale2a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2a_relu (Activation)         (None, 64, 64, 256)  0           res2a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16384       res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2a (Scale)        (None, 64, 64, 64)   128         bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2b (Scale)        (None, 64, 64, 64)   128         bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2c (Scale)        (None, 64, 64, 256)  512         bn2b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b (Merge)                   (None, 64, 64, 256)  0           scale2b_branch2c[0][0]           \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2b_relu (Activation)         (None, 64, 64, 256)  0           res2b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16384       res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2a (Scale)        (None, 64, 64, 64)   128         bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2b (Scale)        (None, 64, 64, 64)   128         bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2c (Scale)        (None, 64, 64, 256)  512         bn2c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c (Merge)                   (None, 64, 64, 256)  0           scale2c_branch2c[0][0]           \n",
      "                                                                 res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2c_relu (Activation)         (None, 64, 64, 256)  0           res2c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 64, 64, 256)  0           res2c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32768       dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2a (Scale)        (None, 32, 32, 128)  256         bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a_relu (Activation (None, 32, 32, 128)  0           scale3a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_zeropadding (Zer (None, 34, 34, 128)  0           res3a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147456      res3a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2b (Scale)        (None, 32, 32, 128)  256         bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_relu (Activation (None, 32, 32, 128)  0           scale3a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 512)  65536       res3a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131072      dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2c (Scale)        (None, 32, 32, 512)  1024        bn3a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch1 (Scale)         (None, 32, 32, 512)  1024        bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a (Merge)                   (None, 32, 32, 512)  0           scale3a_branch2c[0][0]           \n",
      "                                                                 scale3a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3a_relu (Activation)         (None, 32, 32, 512)  0           res3a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a (Conv2D)        (None, 32, 32, 128)  65536       res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2a (BatchNormalizat (None, 32, 32, 128)  512         res3b7_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2a (Scale)       (None, 32, 32, 128)  256         bn3b7_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a_relu (Activatio (None, 32, 32, 128)  0           scale3b7_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_zeropadding (Ze (None, 34, 34, 128)  0           res3b7_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b (Conv2D)        (None, 32, 32, 128)  147456      res3b7_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2b (BatchNormalizat (None, 32, 32, 128)  512         res3b7_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2b (Scale)       (None, 32, 32, 128)  256         bn3b7_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_relu (Activatio (None, 32, 32, 128)  0           scale3b7_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2c (Conv2D)        (None, 32, 32, 512)  65536       res3b7_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2c (BatchNormalizat (None, 32, 32, 512)  2048        res3b7_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2c (Scale)       (None, 32, 32, 512)  1024        bn3b7_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7 (Merge)                  (None, 32, 32, 512)  0           scale3b7_branch2c[0][0]          \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_relu (Activation)        (None, 32, 32, 512)  0           res3b7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 32, 32, 512)  0           res3b7_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131072      dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2a (Scale)        (None, 16, 16, 256)  512         bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a_relu (Activation (None, 16, 16, 256)  0           scale4a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_zeropadding (Zer (None, 18, 18, 256)  0           res4a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 16, 16, 256)  589824      res4a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2b (Scale)        (None, 16, 16, 256)  512         bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_relu (Activation (None, 16, 16, 256)  0           scale4a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 262144      res4a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 524288      dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2c (Scale)        (None, 16, 16, 1024) 2048        bn4a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch1 (Scale)         (None, 16, 16, 1024) 2048        bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4a (Merge)                   (None, 16, 16, 1024) 0           scale4a_branch2c[0][0]           \n",
      "                                                                 scale4a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4a_relu (Activation)         (None, 16, 16, 1024) 0           res4a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a (Conv2D)       (None, 16, 16, 256)  262144      res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2a (BatchNormaliza (None, 16, 16, 256)  1024        res4b35_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2a (Scale)      (None, 16, 16, 256)  512         bn4b35_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a_relu (Activati (None, 16, 16, 256)  0           scale4b35_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_zeropadding (Z (None, 18, 18, 256)  0           res4b35_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b (Conv2D)       (None, 16, 16, 256)  589824      res4b35_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2b (BatchNormaliza (None, 16, 16, 256)  1024        res4b35_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2b (Scale)      (None, 16, 16, 256)  512         bn4b35_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_relu (Activati (None, 16, 16, 256)  0           scale4b35_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2c (Conv2D)       (None, 16, 16, 1024) 262144      res4b35_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2c (BatchNormaliza (None, 16, 16, 1024) 4096        res4b35_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2c (Scale)      (None, 16, 16, 1024) 2048        bn4b35_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35 (Merge)                 (None, 16, 16, 1024) 0           scale4b35_branch2c[0][0]         \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_relu (Activation)       (None, 16, 16, 1024) 0           res4b35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 16, 16, 1024) 0           res4b35_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524288      dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2097152     dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch1 (Scale)         (None, 8, 8, 2048)   4096        bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a (Merge)                   (None, 8, 8, 2048)   0           scale5a_branch2c[0][0]           \n",
      "                                                                 scale5a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res5a_relu (Activation)         (None, 8, 8, 2048)   0           res5a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1048576     res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b (Merge)                   (None, 8, 8, 2048)   0           scale5b_branch2c[0][0]           \n",
      "                                                                 res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5b_relu (Activation)         (None, 8, 8, 2048)   0           res5b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1048576     res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c (Merge)                   (None, 8, 8, 2048)   0           scale5c_branch2c[0][0]           \n",
      "                                                                 res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5c_relu (Activation)         (None, 8, 8, 2048)   0           res5c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 8, 8, 2048)   0           res5c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DTran (None, 16, 16, 256)  2097408     dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 1280) 0           conv2d_transpose_16[0][0]        \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 256)  2949376     concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 16, 16, 256)  0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 256)  590080      dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 16, 16, 256)  0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 256)  590080      dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DTran (None, 32, 32, 128)  131200      conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 32, 32, 640)  0           conv2d_transpose_17[0][0]        \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 32, 128)  737408      concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 32, 32, 128)  0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 32, 32, 128)  147584      dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 32, 32, 128)  0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 32, 32, 128)  147584      dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DTran (None, 64, 64, 64)   32832       conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 64, 64, 320)  0           conv2d_transpose_18[0][0]        \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 64, 64, 64)   184384      concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 64, 64, 64)   0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 64, 64, 64)   36928       dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 64, 64, 64)   0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 64, 64, 64)   36928       dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_19 (Conv2DTran (None, 128, 128, 32) 8224        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 128, 128, 96) 0           conv2d_transpose_19[0][0]        \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 128, 128, 32) 27680       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 128, 128, 32) 0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 128, 128, 32) 9248        dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 128, 128, 32) 0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 128, 128, 32) 9248        dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DTran (None, 256, 256, 16) 2064        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 256, 256, 16) 64          lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 256, 256, 32) 0           conv2d_transpose_20[0][0]        \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 256, 256, 16) 0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 256, 256, 16) 2320        dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 256, 256, 3)  51          conv2d_62[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,300,003\n",
      "Trainable params: 26,262,243\n",
      "Non-trainable params: 37,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "738/737 [==============================] - 317s 430ms/step - loss: 0.4277 - val_loss: 1.7450\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.74502, saving model to Resnet152_UNet.h5\n",
      "Epoch 2/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.3259 - val_loss: 0.6149\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.74502 to 0.61490, saving model to Resnet152_UNet.h5\n",
      "Epoch 3/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.3073 - val_loss: 0.5259\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.61490 to 0.52589, saving model to Resnet152_UNet.h5\n",
      "Epoch 4/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2872 - val_loss: 0.6787\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.52589\n",
      "Epoch 5/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2798 - val_loss: 0.7403\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.52589\n",
      "Epoch 6/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2746 - val_loss: 0.5663\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.52589\n",
      "Epoch 7/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2623 - val_loss: 0.4514\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.52589 to 0.45141, saving model to Resnet152_UNet.h5\n",
      "Epoch 8/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2571 - val_loss: 0.5272\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45141\n",
      "Epoch 9/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2603 - val_loss: 0.5785\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45141\n",
      "Epoch 10/30\n",
      "738/737 [==============================] - 287s 388ms/step - loss: 0.2564 - val_loss: 0.4104\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.45141 to 0.41045, saving model to Resnet152_UNet.h5\n",
      "Epoch 11/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2517 - val_loss: 0.5857\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.41045\n",
      "Epoch 12/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2500 - val_loss: 0.5234\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.41045\n",
      "Epoch 13/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2517 - val_loss: 1.2956\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.41045\n",
      "Epoch 14/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2486 - val_loss: 0.7291\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.41045\n",
      "Epoch 15/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2446 - val_loss: 0.4056\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.41045 to 0.40561, saving model to Resnet152_UNet.h5\n",
      "Epoch 16/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2476 - val_loss: 0.3581\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.40561 to 0.35814, saving model to Resnet152_UNet.h5\n",
      "Epoch 17/30\n",
      "738/737 [==============================] - 287s 388ms/step - loss: 0.2407 - val_loss: 0.3630\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.35814\n",
      "Epoch 18/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2381 - val_loss: 1.0474\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.35814\n",
      "Epoch 19/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2380 - val_loss: 0.4712\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.35814\n",
      "Epoch 20/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2404 - val_loss: 0.4165\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.35814\n",
      "Epoch 21/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2360 - val_loss: 0.5560\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.35814\n",
      "Epoch 22/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2371 - val_loss: 0.3725\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.35814\n",
      "Epoch 23/30\n",
      "738/737 [==============================] - 286s 388ms/step - loss: 0.2353 - val_loss: 0.3732\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.35814\n",
      "Epoch 24/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2375 - val_loss: 0.3474\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.35814 to 0.34744, saving model to Resnet152_UNet.h5\n",
      "Epoch 25/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2332 - val_loss: 0.8951\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34744\n",
      "Epoch 26/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2317 - val_loss: 0.3184\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.34744 to 0.31835, saving model to Resnet152_UNet.h5\n",
      "Epoch 27/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2314 - val_loss: 0.6261\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.31835\n",
      "Epoch 28/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2314 - val_loss: 0.3528\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.31835\n",
      "Epoch 29/30\n",
      "738/737 [==============================] - 287s 388ms/step - loss: 0.2287 - val_loss: 0.5462\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.31835\n",
      "Epoch 30/30\n",
      "738/737 [==============================] - 287s 388ms/step - loss: 0.2326 - val_loss: 0.7662\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.31835\n",
      "****************************************\n",
      "Fold: 3\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 256, 256, 3)  0           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1_zeropadding (ZeroPadding2 (None, 262, 262, 3)  0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 128, 64) 9408        conv1_zeropadding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_conv1 (Scale)             (None, 128, 128, 64) 128         bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           scale_conv1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 128, 128, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 64, 64, 64)   0           dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4096        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2a (Scale)        (None, 64, 64, 64)   128         bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2b (Scale)        (None, 64, 64, 64)   128         bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16384       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2c (Scale)        (None, 64, 64, 256)  512         bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch1 (Scale)         (None, 64, 64, 256)  512         bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a (Merge)                   (None, 64, 64, 256)  0           scale2a_branch2c[0][0]           \n",
      "                                                                 scale2a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2a_relu (Activation)         (None, 64, 64, 256)  0           res2a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16384       res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2a (Scale)        (None, 64, 64, 64)   128         bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2b (Scale)        (None, 64, 64, 64)   128         bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2c (Scale)        (None, 64, 64, 256)  512         bn2b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b (Merge)                   (None, 64, 64, 256)  0           scale2b_branch2c[0][0]           \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2b_relu (Activation)         (None, 64, 64, 256)  0           res2b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16384       res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2a (Scale)        (None, 64, 64, 64)   128         bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2b (Scale)        (None, 64, 64, 64)   128         bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2c (Scale)        (None, 64, 64, 256)  512         bn2c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c (Merge)                   (None, 64, 64, 256)  0           scale2c_branch2c[0][0]           \n",
      "                                                                 res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2c_relu (Activation)         (None, 64, 64, 256)  0           res2c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 64, 64, 256)  0           res2c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32768       dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2a (Scale)        (None, 32, 32, 128)  256         bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a_relu (Activation (None, 32, 32, 128)  0           scale3a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_zeropadding (Zer (None, 34, 34, 128)  0           res3a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147456      res3a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2b (Scale)        (None, 32, 32, 128)  256         bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_relu (Activation (None, 32, 32, 128)  0           scale3a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 512)  65536       res3a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131072      dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2c (Scale)        (None, 32, 32, 512)  1024        bn3a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch1 (Scale)         (None, 32, 32, 512)  1024        bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a (Merge)                   (None, 32, 32, 512)  0           scale3a_branch2c[0][0]           \n",
      "                                                                 scale3a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3a_relu (Activation)         (None, 32, 32, 512)  0           res3a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a (Conv2D)        (None, 32, 32, 128)  65536       res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2a (BatchNormalizat (None, 32, 32, 128)  512         res3b7_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2a (Scale)       (None, 32, 32, 128)  256         bn3b7_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a_relu (Activatio (None, 32, 32, 128)  0           scale3b7_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_zeropadding (Ze (None, 34, 34, 128)  0           res3b7_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b (Conv2D)        (None, 32, 32, 128)  147456      res3b7_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2b (BatchNormalizat (None, 32, 32, 128)  512         res3b7_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2b (Scale)       (None, 32, 32, 128)  256         bn3b7_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_relu (Activatio (None, 32, 32, 128)  0           scale3b7_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2c (Conv2D)        (None, 32, 32, 512)  65536       res3b7_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2c (BatchNormalizat (None, 32, 32, 512)  2048        res3b7_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2c (Scale)       (None, 32, 32, 512)  1024        bn3b7_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7 (Merge)                  (None, 32, 32, 512)  0           scale3b7_branch2c[0][0]          \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_relu (Activation)        (None, 32, 32, 512)  0           res3b7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 32, 32, 512)  0           res3b7_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131072      dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2a (Scale)        (None, 16, 16, 256)  512         bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a_relu (Activation (None, 16, 16, 256)  0           scale4a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_zeropadding (Zer (None, 18, 18, 256)  0           res4a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 16, 16, 256)  589824      res4a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2b (Scale)        (None, 16, 16, 256)  512         bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_relu (Activation (None, 16, 16, 256)  0           scale4a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 262144      res4a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 524288      dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2c (Scale)        (None, 16, 16, 1024) 2048        bn4a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch1 (Scale)         (None, 16, 16, 1024) 2048        bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4a (Merge)                   (None, 16, 16, 1024) 0           scale4a_branch2c[0][0]           \n",
      "                                                                 scale4a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4a_relu (Activation)         (None, 16, 16, 1024) 0           res4a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a (Conv2D)       (None, 16, 16, 256)  262144      res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2a (BatchNormaliza (None, 16, 16, 256)  1024        res4b35_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2a (Scale)      (None, 16, 16, 256)  512         bn4b35_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a_relu (Activati (None, 16, 16, 256)  0           scale4b35_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_zeropadding (Z (None, 18, 18, 256)  0           res4b35_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b (Conv2D)       (None, 16, 16, 256)  589824      res4b35_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2b (BatchNormaliza (None, 16, 16, 256)  1024        res4b35_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2b (Scale)      (None, 16, 16, 256)  512         bn4b35_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_relu (Activati (None, 16, 16, 256)  0           scale4b35_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2c (Conv2D)       (None, 16, 16, 1024) 262144      res4b35_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2c (BatchNormaliza (None, 16, 16, 1024) 4096        res4b35_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2c (Scale)      (None, 16, 16, 1024) 2048        bn4b35_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35 (Merge)                 (None, 16, 16, 1024) 0           scale4b35_branch2c[0][0]         \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_relu (Activation)       (None, 16, 16, 1024) 0           res4b35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 16, 16, 1024) 0           res4b35_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524288      dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2097152     dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch1 (Scale)         (None, 8, 8, 2048)   4096        bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a (Merge)                   (None, 8, 8, 2048)   0           scale5a_branch2c[0][0]           \n",
      "                                                                 scale5a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res5a_relu (Activation)         (None, 8, 8, 2048)   0           res5a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1048576     res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b (Merge)                   (None, 8, 8, 2048)   0           scale5b_branch2c[0][0]           \n",
      "                                                                 res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5b_relu (Activation)         (None, 8, 8, 2048)   0           res5b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1048576     res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c (Merge)                   (None, 8, 8, 2048)   0           scale5c_branch2c[0][0]           \n",
      "                                                                 res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5c_relu (Activation)         (None, 8, 8, 2048)   0           res5c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 8, 8, 2048)   0           res5c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DTran (None, 16, 16, 256)  2097408     dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 1280) 0           conv2d_transpose_21[0][0]        \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 256)  2949376     concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 16, 16, 256)  0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 16, 256)  590080      dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 16, 16, 256)  0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 16, 16, 256)  590080      dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DTran (None, 32, 32, 128)  131200      conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 32, 32, 640)  0           conv2d_transpose_22[0][0]        \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 32, 32, 128)  737408      concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 32, 32, 128)  0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 128)  147584      dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 32, 32, 128)  0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 128)  147584      dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DTran (None, 64, 64, 64)   32832       conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 64, 64, 320)  0           conv2d_transpose_23[0][0]        \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 64, 64, 64)   184384      concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 64, 64, 64)   0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 64, 64, 64)   36928       dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 64, 64, 64)   0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 64, 64, 64)   36928       dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_24 (Conv2DTran (None, 128, 128, 32) 8224        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 128, 128, 96) 0           conv2d_transpose_24[0][0]        \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 128, 128, 32) 27680       concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 128, 128, 32) 0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 128, 128, 32) 9248        dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 128, 128, 32) 0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 128, 128, 32) 9248        dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_25 (Conv2DTran (None, 256, 256, 16) 2064        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 256, 256, 16) 64          lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 256, 256, 32) 0           conv2d_transpose_25[0][0]        \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 256, 256, 16) 0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 256, 256, 16) 2320        dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 256, 256, 3)  51          conv2d_78[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,300,003\n",
      "Trainable params: 26,262,243\n",
      "Non-trainable params: 37,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "738/737 [==============================] - 320s 434ms/step - loss: 0.4264 - val_loss: 0.3785\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37846, saving model to Resnet152_UNet.h5\n",
      "Epoch 2/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.3345 - val_loss: 0.5399\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.37846\n",
      "Epoch 3/30\n",
      "738/737 [==============================] - 288s 390ms/step - loss: 0.3081 - val_loss: 0.3726\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37846 to 0.37256, saving model to Resnet152_UNet.h5\n",
      "Epoch 4/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2908 - val_loss: 0.3584\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.37256 to 0.35836, saving model to Resnet152_UNet.h5\n",
      "Epoch 5/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2865 - val_loss: 0.4058\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35836\n",
      "Epoch 6/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2735 - val_loss: 1.0892\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35836\n",
      "Epoch 7/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2685 - val_loss: 0.3134\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.35836 to 0.31343, saving model to Resnet152_UNet.h5\n",
      "Epoch 8/30\n",
      "738/737 [==============================] - 288s 390ms/step - loss: 0.2591 - val_loss: 0.7275\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31343\n",
      "Epoch 9/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2601 - val_loss: 0.3522\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31343\n",
      "Epoch 10/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2565 - val_loss: 0.4254\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31343\n",
      "Epoch 11/30\n",
      "738/737 [==============================] - 288s 390ms/step - loss: 0.2592 - val_loss: 0.4354\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31343\n",
      "Epoch 12/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2507 - val_loss: 1.1672\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31343\n",
      "Epoch 13/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2532 - val_loss: 1.2909\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31343\n",
      "Epoch 14/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2483 - val_loss: 0.3079\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.31343 to 0.30795, saving model to Resnet152_UNet.h5\n",
      "Epoch 15/30\n",
      "738/737 [==============================] - 288s 390ms/step - loss: 0.2447 - val_loss: 0.5451\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.30795\n",
      "Epoch 16/30\n",
      "738/737 [==============================] - 288s 390ms/step - loss: 0.2455 - val_loss: 0.3221\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.30795\n",
      "Epoch 17/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2423 - val_loss: 0.2916\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.30795 to 0.29164, saving model to Resnet152_UNet.h5\n",
      "Epoch 18/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2439 - val_loss: 0.6291\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.29164\n",
      "Epoch 19/30\n",
      "738/737 [==============================] - 288s 390ms/step - loss: 0.2401 - val_loss: 0.4848\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.29164\n",
      "Epoch 20/30\n",
      "738/737 [==============================] - 287s 390ms/step - loss: 0.2384 - val_loss: 0.2875\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.29164 to 0.28752, saving model to Resnet152_UNet.h5\n",
      "Epoch 21/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2372 - val_loss: 1.2035\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.28752\n",
      "Epoch 22/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2352 - val_loss: 0.5901\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.28752\n",
      "Epoch 23/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2348 - val_loss: 0.5082\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.28752\n",
      "Epoch 24/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2357 - val_loss: 0.3198\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.28752\n",
      "Epoch 25/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2351 - val_loss: 0.3068\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.28752\n",
      "Epoch 26/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2324 - val_loss: 0.5642\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.28752\n",
      "Epoch 27/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2332 - val_loss: 0.7491\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.28752\n",
      "Epoch 28/30\n",
      "738/737 [==============================] - 287s 389ms/step - loss: 0.2329 - val_loss: 0.3285\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.28752\n",
      "Epoch 00028: early stopping\n",
      "****************************************\n",
      "Fold: 4\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 256, 256, 3)  0           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1_zeropadding (ZeroPadding2 (None, 262, 262, 3)  0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 128, 64) 9408        conv1_zeropadding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_conv1 (Scale)             (None, 128, 128, 64) 128         bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           scale_conv1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 128, 128, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 64, 64, 64)   0           dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4096        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2a (Scale)        (None, 64, 64, 64)   128         bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2b (Scale)        (None, 64, 64, 64)   128         bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16384       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2c (Scale)        (None, 64, 64, 256)  512         bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch1 (Scale)         (None, 64, 64, 256)  512         bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a (Merge)                   (None, 64, 64, 256)  0           scale2a_branch2c[0][0]           \n",
      "                                                                 scale2a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2a_relu (Activation)         (None, 64, 64, 256)  0           res2a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16384       res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2a (Scale)        (None, 64, 64, 64)   128         bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2b (Scale)        (None, 64, 64, 64)   128         bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2c (Scale)        (None, 64, 64, 256)  512         bn2b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b (Merge)                   (None, 64, 64, 256)  0           scale2b_branch2c[0][0]           \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2b_relu (Activation)         (None, 64, 64, 256)  0           res2b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16384       res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2a (Scale)        (None, 64, 64, 64)   128         bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2b (Scale)        (None, 64, 64, 64)   128         bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2c (Scale)        (None, 64, 64, 256)  512         bn2c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c (Merge)                   (None, 64, 64, 256)  0           scale2c_branch2c[0][0]           \n",
      "                                                                 res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2c_relu (Activation)         (None, 64, 64, 256)  0           res2c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 64, 64, 256)  0           res2c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32768       dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2a (Scale)        (None, 32, 32, 128)  256         bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a_relu (Activation (None, 32, 32, 128)  0           scale3a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_zeropadding (Zer (None, 34, 34, 128)  0           res3a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147456      res3a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2b (Scale)        (None, 32, 32, 128)  256         bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_relu (Activation (None, 32, 32, 128)  0           scale3a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 512)  65536       res3a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131072      dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2c (Scale)        (None, 32, 32, 512)  1024        bn3a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch1 (Scale)         (None, 32, 32, 512)  1024        bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a (Merge)                   (None, 32, 32, 512)  0           scale3a_branch2c[0][0]           \n",
      "                                                                 scale3a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3a_relu (Activation)         (None, 32, 32, 512)  0           res3a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a (Conv2D)        (None, 32, 32, 128)  65536       res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2a (BatchNormalizat (None, 32, 32, 128)  512         res3b7_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2a (Scale)       (None, 32, 32, 128)  256         bn3b7_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a_relu (Activatio (None, 32, 32, 128)  0           scale3b7_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_zeropadding (Ze (None, 34, 34, 128)  0           res3b7_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b (Conv2D)        (None, 32, 32, 128)  147456      res3b7_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2b (BatchNormalizat (None, 32, 32, 128)  512         res3b7_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2b (Scale)       (None, 32, 32, 128)  256         bn3b7_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_relu (Activatio (None, 32, 32, 128)  0           scale3b7_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2c (Conv2D)        (None, 32, 32, 512)  65536       res3b7_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2c (BatchNormalizat (None, 32, 32, 512)  2048        res3b7_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2c (Scale)       (None, 32, 32, 512)  1024        bn3b7_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7 (Merge)                  (None, 32, 32, 512)  0           scale3b7_branch2c[0][0]          \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_relu (Activation)        (None, 32, 32, 512)  0           res3b7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 32, 32, 512)  0           res3b7_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131072      dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2a (Scale)        (None, 16, 16, 256)  512         bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a_relu (Activation (None, 16, 16, 256)  0           scale4a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_zeropadding (Zer (None, 18, 18, 256)  0           res4a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 16, 16, 256)  589824      res4a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2b (Scale)        (None, 16, 16, 256)  512         bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_relu (Activation (None, 16, 16, 256)  0           scale4a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 262144      res4a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 524288      dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2c (Scale)        (None, 16, 16, 1024) 2048        bn4a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch1 (Scale)         (None, 16, 16, 1024) 2048        bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4a (Merge)                   (None, 16, 16, 1024) 0           scale4a_branch2c[0][0]           \n",
      "                                                                 scale4a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4a_relu (Activation)         (None, 16, 16, 1024) 0           res4a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a (Conv2D)       (None, 16, 16, 256)  262144      res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2a (BatchNormaliza (None, 16, 16, 256)  1024        res4b35_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2a (Scale)      (None, 16, 16, 256)  512         bn4b35_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a_relu (Activati (None, 16, 16, 256)  0           scale4b35_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_zeropadding (Z (None, 18, 18, 256)  0           res4b35_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b (Conv2D)       (None, 16, 16, 256)  589824      res4b35_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2b (BatchNormaliza (None, 16, 16, 256)  1024        res4b35_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2b (Scale)      (None, 16, 16, 256)  512         bn4b35_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_relu (Activati (None, 16, 16, 256)  0           scale4b35_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2c (Conv2D)       (None, 16, 16, 1024) 262144      res4b35_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2c (BatchNormaliza (None, 16, 16, 1024) 4096        res4b35_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2c (Scale)      (None, 16, 16, 1024) 2048        bn4b35_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35 (Merge)                 (None, 16, 16, 1024) 0           scale4b35_branch2c[0][0]         \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_relu (Activation)       (None, 16, 16, 1024) 0           res4b35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 16, 16, 1024) 0           res4b35_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524288      dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2097152     dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch1 (Scale)         (None, 8, 8, 2048)   4096        bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a (Merge)                   (None, 8, 8, 2048)   0           scale5a_branch2c[0][0]           \n",
      "                                                                 scale5a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res5a_relu (Activation)         (None, 8, 8, 2048)   0           res5a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1048576     res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b (Merge)                   (None, 8, 8, 2048)   0           scale5b_branch2c[0][0]           \n",
      "                                                                 res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5b_relu (Activation)         (None, 8, 8, 2048)   0           res5b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1048576     res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c (Merge)                   (None, 8, 8, 2048)   0           scale5c_branch2c[0][0]           \n",
      "                                                                 res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5c_relu (Activation)         (None, 8, 8, 2048)   0           res5c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 8, 8, 2048)   0           res5c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_26 (Conv2DTran (None, 16, 16, 256)  2097408     dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 16, 16, 1280) 0           conv2d_transpose_26[0][0]        \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 16, 16, 256)  2949376     concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 16, 16, 256)  0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 16, 16, 256)  590080      dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 16, 16, 256)  0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 256)  590080      dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_27 (Conv2DTran (None, 32, 32, 128)  131200      conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 32, 32, 640)  0           conv2d_transpose_27[0][0]        \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 32, 32, 128)  737408      concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 32, 32, 128)  0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 32, 32, 128)  147584      dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 32, 32, 128)  0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 32, 32, 128)  147584      dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_28 (Conv2DTran (None, 64, 64, 64)   32832       conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 64, 64, 320)  0           conv2d_transpose_28[0][0]        \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 64, 64, 64)   184384      concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 64, 64, 64)   0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 64, 64, 64)   36928       dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 64, 64, 64)   0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 64, 64, 64)   36928       dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_29 (Conv2DTran (None, 128, 128, 32) 8224        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 128, 128, 96) 0           conv2d_transpose_29[0][0]        \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 128, 128, 32) 27680       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 128, 128, 32) 0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 128, 128, 32) 9248        dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 128, 128, 32) 0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 128, 128, 32) 9248        dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_30 (Conv2DTran (None, 256, 256, 16) 2064        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 256, 256, 16) 64          lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 256, 256, 32) 0           conv2d_transpose_30[0][0]        \n",
      "                                                                 conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 256, 256, 16) 0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 256, 256, 16) 2320        dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 256, 256, 3)  51          conv2d_94[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,300,003\n",
      "Trainable params: 26,262,243\n",
      "Non-trainable params: 37,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "738/737 [==============================] - 329s 446ms/step - loss: 0.4085 - val_loss: 0.3494\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.34941, saving model to Resnet152_UNet.h5\n",
      "Epoch 2/30\n",
      "738/737 [==============================] - 289s 392ms/step - loss: 0.3276 - val_loss: 1.0450\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34941\n",
      "Epoch 3/30\n",
      "738/737 [==============================] - 289s 392ms/step - loss: 0.3044 - val_loss: 0.4120\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34941\n",
      "Epoch 4/30\n",
      "738/737 [==============================] - 289s 392ms/step - loss: 0.2901 - val_loss: 0.7238\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34941\n",
      "Epoch 5/30\n",
      "738/737 [==============================] - 289s 391ms/step - loss: 0.3235 - val_loss: 1.1894\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34941\n",
      "Epoch 6/30\n",
      "738/737 [==============================] - 289s 391ms/step - loss: 0.2882 - val_loss: 0.3910\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34941\n",
      "Epoch 7/30\n",
      "738/737 [==============================] - 288s 391ms/step - loss: 0.2770 - val_loss: 0.2835\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34941 to 0.28348, saving model to Resnet152_UNet.h5\n",
      "Epoch 8/30\n",
      "738/737 [==============================] - 289s 391ms/step - loss: 0.2703 - val_loss: 0.5963\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28348\n",
      "Epoch 9/30\n",
      "738/737 [==============================] - 289s 391ms/step - loss: 0.2649 - val_loss: 0.3409\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28348\n",
      "Epoch 10/30\n",
      "738/737 [==============================] - 289s 392ms/step - loss: 0.2641 - val_loss: 0.4235\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28348\n",
      "Epoch 11/30\n",
      "738/737 [==============================] - 289s 391ms/step - loss: 0.2574 - val_loss: 0.2853\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28348\n",
      "Epoch 12/30\n",
      "738/737 [==============================] - 289s 391ms/step - loss: 0.2594 - val_loss: 0.9567\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28348\n",
      "Epoch 13/30\n",
      "738/737 [==============================] - 289s 392ms/step - loss: 0.2579 - val_loss: 0.2937\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.28348\n",
      "Epoch 14/30\n",
      "738/737 [==============================] - 289s 391ms/step - loss: 0.2539 - val_loss: 0.3311\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.28348\n",
      "Epoch 15/30\n",
      "738/737 [==============================] - 289s 391ms/step - loss: 0.2516 - val_loss: 0.3633\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.28348\n",
      "Epoch 00015: early stopping\n",
      "****************************************\n",
      "Fold: 5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 256, 256, 3)  0           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1_zeropadding (ZeroPadding2 (None, 262, 262, 3)  0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 128, 64) 9408        conv1_zeropadding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_conv1 (Scale)             (None, 128, 128, 64) 128         bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           scale_conv1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 128, 128, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 64, 64, 64)   0           dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4096        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2a (Scale)        (None, 64, 64, 64)   128         bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2b (Scale)        (None, 64, 64, 64)   128         bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16384       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2c (Scale)        (None, 64, 64, 256)  512         bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch1 (Scale)         (None, 64, 64, 256)  512         bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a (Merge)                   (None, 64, 64, 256)  0           scale2a_branch2c[0][0]           \n",
      "                                                                 scale2a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2a_relu (Activation)         (None, 64, 64, 256)  0           res2a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16384       res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2a (Scale)        (None, 64, 64, 64)   128         bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2b (Scale)        (None, 64, 64, 64)   128         bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2c (Scale)        (None, 64, 64, 256)  512         bn2b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b (Merge)                   (None, 64, 64, 256)  0           scale2b_branch2c[0][0]           \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2b_relu (Activation)         (None, 64, 64, 256)  0           res2b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16384       res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2a (Scale)        (None, 64, 64, 64)   128         bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a_relu (Activation (None, 64, 64, 64)   0           scale2c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_zeropadding (Zer (None, 66, 66, 64)   0           res2c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36864       res2c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2b (Scale)        (None, 64, 64, 64)   128         bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_relu (Activation (None, 64, 64, 64)   0           scale2c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16384       res2c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2c (Scale)        (None, 64, 64, 256)  512         bn2c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c (Merge)                   (None, 64, 64, 256)  0           scale2c_branch2c[0][0]           \n",
      "                                                                 res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2c_relu (Activation)         (None, 64, 64, 256)  0           res2c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 64, 64, 256)  0           res2c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32768       dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2a (Scale)        (None, 32, 32, 128)  256         bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a_relu (Activation (None, 32, 32, 128)  0           scale3a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_zeropadding (Zer (None, 34, 34, 128)  0           res3a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147456      res3a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2b (Scale)        (None, 32, 32, 128)  256         bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_relu (Activation (None, 32, 32, 128)  0           scale3a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 512)  65536       res3a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131072      dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2c (Scale)        (None, 32, 32, 512)  1024        bn3a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch1 (Scale)         (None, 32, 32, 512)  1024        bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a (Merge)                   (None, 32, 32, 512)  0           scale3a_branch2c[0][0]           \n",
      "                                                                 scale3a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3a_relu (Activation)         (None, 32, 32, 512)  0           res3a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a (Conv2D)        (None, 32, 32, 128)  65536       res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2a (BatchNormalizat (None, 32, 32, 128)  512         res3b7_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2a (Scale)       (None, 32, 32, 128)  256         bn3b7_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a_relu (Activatio (None, 32, 32, 128)  0           scale3b7_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_zeropadding (Ze (None, 34, 34, 128)  0           res3b7_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b (Conv2D)        (None, 32, 32, 128)  147456      res3b7_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2b (BatchNormalizat (None, 32, 32, 128)  512         res3b7_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2b (Scale)       (None, 32, 32, 128)  256         bn3b7_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_relu (Activatio (None, 32, 32, 128)  0           scale3b7_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2c (Conv2D)        (None, 32, 32, 512)  65536       res3b7_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2c (BatchNormalizat (None, 32, 32, 512)  2048        res3b7_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2c (Scale)       (None, 32, 32, 512)  1024        bn3b7_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7 (Merge)                  (None, 32, 32, 512)  0           scale3b7_branch2c[0][0]          \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_relu (Activation)        (None, 32, 32, 512)  0           res3b7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 32, 32, 512)  0           res3b7_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131072      dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2a (Scale)        (None, 16, 16, 256)  512         bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a_relu (Activation (None, 16, 16, 256)  0           scale4a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_zeropadding (Zer (None, 18, 18, 256)  0           res4a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 16, 16, 256)  589824      res4a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2b (Scale)        (None, 16, 16, 256)  512         bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_relu (Activation (None, 16, 16, 256)  0           scale4a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 262144      res4a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 524288      dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2c (Scale)        (None, 16, 16, 1024) 2048        bn4a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch1 (Scale)         (None, 16, 16, 1024) 2048        bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4a (Merge)                   (None, 16, 16, 1024) 0           scale4a_branch2c[0][0]           \n",
      "                                                                 scale4a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4a_relu (Activation)         (None, 16, 16, 1024) 0           res4a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a (Conv2D)       (None, 16, 16, 256)  262144      res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2a (BatchNormaliza (None, 16, 16, 256)  1024        res4b35_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2a (Scale)      (None, 16, 16, 256)  512         bn4b35_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a_relu (Activati (None, 16, 16, 256)  0           scale4b35_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_zeropadding (Z (None, 18, 18, 256)  0           res4b35_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b (Conv2D)       (None, 16, 16, 256)  589824      res4b35_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2b (BatchNormaliza (None, 16, 16, 256)  1024        res4b35_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2b (Scale)      (None, 16, 16, 256)  512         bn4b35_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_relu (Activati (None, 16, 16, 256)  0           scale4b35_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2c (Conv2D)       (None, 16, 16, 1024) 262144      res4b35_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2c (BatchNormaliza (None, 16, 16, 1024) 4096        res4b35_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2c (Scale)      (None, 16, 16, 1024) 2048        bn4b35_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35 (Merge)                 (None, 16, 16, 1024) 0           scale4b35_branch2c[0][0]         \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_relu (Activation)       (None, 16, 16, 1024) 0           res4b35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 16, 16, 1024) 0           res4b35_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524288      dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2097152     dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch1 (Scale)         (None, 8, 8, 2048)   4096        bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a (Merge)                   (None, 8, 8, 2048)   0           scale5a_branch2c[0][0]           \n",
      "                                                                 scale5a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res5a_relu (Activation)         (None, 8, 8, 2048)   0           res5a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1048576     res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b (Merge)                   (None, 8, 8, 2048)   0           scale5b_branch2c[0][0]           \n",
      "                                                                 res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5b_relu (Activation)         (None, 8, 8, 2048)   0           res5b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1048576     res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2a (Scale)        (None, 8, 8, 512)    1024        bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a_relu (Activation (None, 8, 8, 512)    0           scale5c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_zeropadding (Zer (None, 10, 10, 512)  0           res5c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359296     res5c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2b (Scale)        (None, 8, 8, 512)    1024        bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_relu (Activation (None, 8, 8, 512)    0           scale5c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1048576     res5c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2c (Scale)        (None, 8, 8, 2048)   4096        bn5c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c (Merge)                   (None, 8, 8, 2048)   0           scale5c_branch2c[0][0]           \n",
      "                                                                 res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5c_relu (Activation)         (None, 8, 8, 2048)   0           res5c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 8, 8, 2048)   0           res5c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_31 (Conv2DTran (None, 16, 16, 256)  2097408     dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 16, 16, 1280) 0           conv2d_transpose_31[0][0]        \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 16, 16, 256)  2949376     concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 16, 16, 256)  0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 16, 16, 256)  590080      dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 16, 16, 256)  0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 256)  590080      dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_32 (Conv2DTran (None, 32, 32, 128)  131200      conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 32, 32, 640)  0           conv2d_transpose_32[0][0]        \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 32, 32, 128)  737408      concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 32, 32, 128)  0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 32, 32, 128)  147584      dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 32, 32, 128)  0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 32, 32, 128)  147584      dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_33 (Conv2DTran (None, 64, 64, 64)   32832       conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 64, 64, 320)  0           conv2d_transpose_33[0][0]        \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 64, 64, 64)   184384      concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 64, 64, 64)   0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 64, 64, 64)   36928       dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 64, 64, 64)   0           conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 64, 64, 64)   36928       dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_34 (Conv2DTran (None, 128, 128, 32) 8224        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 128, 128, 96) 0           conv2d_transpose_34[0][0]        \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 128, 128, 32) 27680       concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 128, 128, 32) 0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 128, 128, 32) 9248        dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 128, 128, 32) 0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 128, 128, 32) 9248        dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_35 (Conv2DTran (None, 256, 256, 16) 2064        conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 256, 256, 16) 64          lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 256, 256, 32) 0           conv2d_transpose_35[0][0]        \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 256, 256, 16) 4624        concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 256, 256, 16) 0           conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 256, 256, 16) 2320        dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 256, 256, 3)  51          conv2d_110[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 26,300,003\n",
      "Trainable params: 26,262,243\n",
      "Non-trainable params: 37,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "738/737 [==============================] - 340s 460ms/step - loss: 0.4189 - val_loss: 0.7178\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.71779, saving model to Resnet152_UNet.h5\n",
      "Epoch 2/30\n",
      "738/737 [==============================] - 290s 393ms/step - loss: 0.3418 - val_loss: 0.6029\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.71779 to 0.60293, saving model to Resnet152_UNet.h5\n",
      "Epoch 3/30\n",
      "738/737 [==============================] - 291s 394ms/step - loss: 0.4138 - val_loss: 0.4215\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.60293 to 0.42149, saving model to Resnet152_UNet.h5\n",
      "Epoch 4/30\n",
      "738/737 [==============================] - 290s 394ms/step - loss: 0.3356 - val_loss: 1.5790\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.42149\n",
      "Epoch 5/30\n",
      "738/737 [==============================] - 290s 393ms/step - loss: 0.3163 - val_loss: 0.8068\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.42149\n",
      "Epoch 6/30\n",
      "738/737 [==============================] - 290s 393ms/step - loss: 0.2984 - val_loss: 0.3669\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.42149 to 0.36686, saving model to Resnet152_UNet.h5\n",
      "Epoch 7/30\n",
      "738/737 [==============================] - 290s 392ms/step - loss: 0.2858 - val_loss: 0.3408\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.36686 to 0.34077, saving model to Resnet152_UNet.h5\n",
      "Epoch 8/30\n",
      "738/737 [==============================] - 290s 392ms/step - loss: 0.2840 - val_loss: 0.7818\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34077\n",
      "Epoch 9/30\n",
      "738/737 [==============================] - 290s 392ms/step - loss: 0.2798 - val_loss: 0.4780\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34077\n",
      "Epoch 10/30\n",
      "738/737 [==============================] - 290s 393ms/step - loss: 0.2693 - val_loss: 0.6109\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34077\n",
      "Epoch 11/30\n",
      "738/737 [==============================] - 290s 393ms/step - loss: 0.2646 - val_loss: 0.5308\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.34077\n",
      "Epoch 12/30\n",
      "738/737 [==============================] - 290s 392ms/step - loss: 0.2656 - val_loss: 0.7025\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.34077\n",
      "Epoch 13/30\n",
      "738/737 [==============================] - 289s 392ms/step - loss: 0.2723 - val_loss: 0.2919\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34077 to 0.29194, saving model to Resnet152_UNet.h5\n",
      "Epoch 14/30\n",
      "738/737 [==============================] - 291s 395ms/step - loss: 0.2619 - val_loss: 0.4223\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.29194\n",
      "Epoch 15/30\n",
      "738/737 [==============================] - 290s 393ms/step - loss: 0.2610 - val_loss: 0.4358\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.29194\n",
      "Epoch 16/30\n",
      "738/737 [==============================] - 290s 393ms/step - loss: 0.2582 - val_loss: 0.5015\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.29194\n",
      "Epoch 17/30\n",
      "738/737 [==============================] - 290s 393ms/step - loss: 0.2554 - val_loss: 0.3214\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.29194\n",
      "Epoch 18/30\n",
      "738/737 [==============================] - 290s 393ms/step - loss: 0.2509 - val_loss: 0.3176\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.29194\n",
      "Epoch 19/30\n",
      "738/737 [==============================] - 290s 393ms/step - loss: 0.2522 - val_loss: 2.4312\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.29194\n",
      "Epoch 20/30\n",
      "738/737 [==============================] - 290s 393ms/step - loss: 0.2509 - val_loss: 0.5781\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.29194\n",
      "Epoch 21/30\n",
      "738/737 [==============================] - 290s 393ms/step - loss: 0.2463 - val_loss: 0.8948\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.29194\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "sess = init_seeds(0)\n",
    "\n",
    "# even number of folds because we duplicate images\n",
    "kf = KFold(6, shuffle=False)\n",
    "\n",
    "models = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    print('*' * 40)\n",
    "    print('Fold:', fold)\n",
    "    X_train_kf = X_train[train_idx]\n",
    "    X_val_kf = X_train[val_idx]\n",
    "    Z_train_kf = Z_train[train_idx]\n",
    "    Z_val_kf = Z_train[val_idx]\n",
    "\n",
    "    model = resnet152_model(256, 256, 3, 2)\n",
    "    models.append(model)\n",
    "\n",
    "    data_gen_args = dict(horizontal_flip=False,\n",
    "                         vertical_flip=False,\n",
    "                         rotation_range=90.,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         zoom_range=0.1)\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    image_datagen.fit(X_train_kf, seed=7)\n",
    "    mask_datagen.fit(Z_train_kf, seed=7)\n",
    "    image_generator = image_datagen.flow(X_train_kf, batch_size=6, seed=7)\n",
    "    mask_generator = mask_datagen.flow(Z_train_kf, batch_size=6, seed=7)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "    val_gen_args = dict()\n",
    "    image_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "    mask_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "    image_datagen_val.fit(X_val_kf, seed=7)\n",
    "    mask_datagen_val.fit(Z_val_kf, seed=7)\n",
    "    image_generator_val = image_datagen_val.flow(X_val_kf, batch_size=6, seed=7)\n",
    "    mask_generator_val = mask_datagen_val.flow(Z_val_kf, batch_size=6, seed=7)\n",
    "    valid_generator=zip(image_generator_val, mask_generator_val)\n",
    "\n",
    "    earlystopper = EarlyStopping(patience=8, verbose=1)\n",
    "    checkpointer = ModelCheckpoint('Resnet152_UNet.h5', \n",
    "                                       verbose=1, save_best_only=True)\n",
    "    model.fit_generator(train_generator, steps_per_epoch=len(X_train_kf)/6, epochs=30,\n",
    "                        validation_data=valid_generator, validation_steps=len(X_val_kf)/6,\n",
    "                       callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata_gen_args = dict(horizontal_flip=False,\\n                         vertical_flip=False,\\n                         rotation_range=90.,\\n                         width_shift_range=0.1,\\n                         height_shift_range=0.1,\\n                         zoom_range=0.1)\\nimage_datagen = ImageDataGenerator(**data_gen_args)\\nmask_datagen = ImageDataGenerator(**data_gen_args)\\nimage_datagen.fit(x_train, seed=7)\\nmask_datagen.fit(z_train, seed=7)\\nimage_generator = image_datagen.flow(x_train, batch_size=16, seed=7)\\nmask_generator = mask_datagen.flow(z_train, batch_size=16, seed=7)\\ntrain_generator = zip(image_generator, mask_generator)\\n\\nval_gen_args = dict()\\nimage_datagen_val = ImageDataGenerator(**val_gen_args)\\nmask_datagen_val = ImageDataGenerator(**val_gen_args)\\nimage_datagen_val.fit(x_valid, seed=7)\\nmask_datagen_val.fit(z_valid, seed=7)\\nimage_generator_val = image_datagen_val.flow(x_valid, batch_size=16, seed=7)\\nmask_generator_val = mask_datagen_val.flow(z_valid, batch_size=16, seed=7)\\nvalid_generator=zip(image_generator_val, mask_generator_val)\\n\\nearlystopper = EarlyStopping(patience=8, verbose=1)\\ncheckpointer = ModelCheckpoint('Resnet152_UNet.h5', \\n                                   verbose=1, save_best_only=True)\\nmodel.fit_generator(train_generator, steps_per_epoch=len(x_train)/16, epochs=15,\\n                    validation_data=valid_generator, validation_steps=len(x_valid)/16,\\n                   callbacks=[earlystopper, checkpointer])\\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "data_gen_args = dict(horizontal_flip=False,\n",
    "                         vertical_flip=False,\n",
    "                         rotation_range=90.,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         zoom_range=0.1)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "image_datagen.fit(x_train, seed=7)\n",
    "mask_datagen.fit(z_train, seed=7)\n",
    "image_generator = image_datagen.flow(x_train, batch_size=16, seed=7)\n",
    "mask_generator = mask_datagen.flow(z_train, batch_size=16, seed=7)\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "val_gen_args = dict()\n",
    "image_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "mask_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "image_datagen_val.fit(x_valid, seed=7)\n",
    "mask_datagen_val.fit(z_valid, seed=7)\n",
    "image_generator_val = image_datagen_val.flow(x_valid, batch_size=16, seed=7)\n",
    "mask_generator_val = mask_datagen_val.flow(z_valid, batch_size=16, seed=7)\n",
    "valid_generator=zip(image_generator_val, mask_generator_val)\n",
    "\n",
    "earlystopper = EarlyStopping(patience=8, verbose=1)\n",
    "checkpointer = ModelCheckpoint('Resnet152_UNet.h5', \n",
    "                                   verbose=1, save_best_only=True)\n",
    "model.fit_generator(train_generator, steps_per_epoch=len(x_train)/16, epochs=15,\n",
    "                    validation_data=valid_generator, validation_steps=len(x_valid)/16,\n",
    "                   callbacks=[earlystopper, checkpointer])\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1f381f5b-1b71-4daa-a417-e02f4894540b",
    "_uuid": "bb15226ea617cf91ed8f43179fccb5a15809e5a0"
   },
   "source": [
    "All right, looks good! Loss seems to be a bit erratic, though. I'll leave it to you to improve the model architecture and parameters! \n",
    "\n",
    "# Make predictions\n",
    "\n",
    "Let's make predictions both on the test set, the val set and the train set (as a sanity check). Remember to load the best saved model if you've used early stopping and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "sess = init_seeds(0)\n",
    "kf = KFold(6, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/topology.py:1271: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24152/24152 [==============================] - 345s 14ms/step\n",
      "24152/24152 [==============================] - 344s 14ms/step\n",
      "24152/24152 [==============================] - 346s 14ms/step\n",
      "24152/24152 [==============================] - 349s 14ms/step\n",
      "24152/24152 [==============================] - 353s 15ms/step\n",
      "24152/24152 [==============================] - 355s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#preds_train = np.zeros(Z_train.shape)\n",
    "preds_test = 0\n",
    "# Predict on train, val and test\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    model = load_model('Resnet152_UNet.h5', \n",
    "                       custom_objects={'pixelwise_crossentropy':pixelwise_crossentropy,\n",
    "                                       'SpeckleNoise':SpeckleNoise, \n",
    "                                       'Scale':Scale\n",
    "                                      })\n",
    "    #X_val_kf = X_train[val_idx]\n",
    "    #preds_train[val_idx] = model.predict(X_val_kf, verbose=1)\n",
    "    preds_test += model.predict(X_test, verbose=1)\n",
    "preds_test /= 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = load_model('Resnet152_UNet.h5', \\n                       custom_objects={'pixelwise_crossentropy':pixelwise_crossentropy, 'Scale':Scale})\\n\\npreds_test = model.predict(X_test, verbose=1)\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = load_model('Resnet152_UNet.h5', \n",
    "                       custom_objects={'pixelwise_crossentropy':pixelwise_crossentropy, 'Scale':Scale})\n",
    "\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(img1, img2, shape):\n",
    "    ov2 = 5\n",
    "    height = shape[0]\n",
    "    width = shape[1]\n",
    "    img = np.zeros((height, width, 3), dtype=np.float32)\n",
    "    w = np.zeros((height, width, 1), dtype=np.float32)\n",
    "    height1 = img1.shape[0]\n",
    "    width1 = img1.shape[1]\n",
    "    height2 = img2.shape[0]\n",
    "    width2 = img2.shape[1]  \n",
    "    w1 = 10*ov2*np.ones((height1, width1, 1), dtype=np.float32)\n",
    "    w2 =  10*ov2*np.ones((height2, width2, 1), dtype=np.float32)\n",
    "    for i in range(ov2, 0, -1):\n",
    "        w1[i-1,:] = 10*i\n",
    "        w1[height1 - i, :] = 10*i\n",
    "        w1[:, i-1] = 10*i\n",
    "        w1[:, width1 - i] = 10*i\n",
    "        w2[i-1,:] = 10*i\n",
    "        w2[height2 - i, :] = 10*i\n",
    "        w2[:, i-1] = 10*i\n",
    "        w2[:, width2 - i] = 10*i\n",
    "\n",
    "    if height > 2*width:\n",
    "        half = int(height//2)\n",
    "        img[:half, :, :] += w1*img1\n",
    "        img[half:, :, :] += w2*img2\n",
    "        w[:half, :] += w1\n",
    "        w[half:, :] += w2\n",
    "        img /= w\n",
    "    elif height > width:\n",
    "        img[:width, :, :] += w1*img1\n",
    "        img[height-width:, :, :] += w2*img2\n",
    "        w[:width, :] += w1\n",
    "        w[height-width:, :] += w2\n",
    "        img /= w\n",
    "    elif width > 2*height:\n",
    "        half = int(width//2)\n",
    "        img[:, :half, :] += w1*img1\n",
    "        img[:, half:, :] += w2*img2\n",
    "        w[:, :half] += w1\n",
    "        w[:, half:] += w2\n",
    "        img /= w\n",
    "    else:\n",
    "        img[:, :height, :] += w1*img1 \n",
    "        img[:, width-height:, :] += w2*img2\n",
    "        w[:, :height] += w1 \n",
    "        w[:, width-height:] += w1\n",
    "        img /= w\n",
    "    return (255*img).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6038/6038 [06:41<00:00, 15.05it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_test_upsampled = []\n",
    "for i in tqdm(range(len(test_split))):\n",
    "    test_i = test_split[i]\n",
    "    pred = resize(np.squeeze(preds_test[4*i + 0]), \n",
    "                  (test_i.shape[0], test_i.shape[1]), \n",
    "                  mode='constant', preserve_range=True)\n",
    "    pred += np.fliplr(resize(np.squeeze(preds_test[4*i + 1]), \n",
    "                  (test_i.shape[0], test_i.shape[1]), \n",
    "                  mode='constant', preserve_range=True))\n",
    "    pred += np.flipud(resize(np.squeeze(preds_test[4*i + 2]), \n",
    "                  (test_i.shape[0], test_i.shape[1]), \n",
    "                  mode='constant', preserve_range=True))\n",
    "    pred += np.flipud(np.fliplr(resize(np.squeeze(preds_test[4*i + 3]), \n",
    "                  (test_i.shape[0], test_i.shape[1]), \n",
    "                  mode='constant', preserve_range=True)))\n",
    "    #pred = (pred > 4*threshold).astype(np.uint8)\n",
    "    pred /= 4\n",
    "    preds_test_upsampled.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3019/3019 [00:22<00:00, 132.32it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_test_merged = []\n",
    "for ix in tqdm(range(len(test))):    \n",
    "    merged = merge(preds_test_upsampled[2*ix+0], \n",
    "                 preds_test_upsampled[2*ix+1],\n",
    "                 test[ix].shape\n",
    "            )\n",
    "    preds_test_merged.append(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_labels(y):\n",
    "    labels = np.zeros((y.shape[1], y.shape[2]))\n",
    "    for i in range(y.shape[0]):\n",
    "        labels = np.where(y[i,:,:] > 0, i+1, labels)\n",
    "    return labels\n",
    "\n",
    "def iou_score_cuk(y_true, y_pred, verbose=True, thresholds=np.arange(0.5, 1.0, 0.05)):\n",
    "    y_true = get_labels(y_true)\n",
    "    y_pred = get_labels(y_pred)\n",
    "    # Compute number of objects\n",
    "    true_objects = len(np.unique(y_true))\n",
    "    pred_objects = len(np.unique(y_pred))\n",
    "    if verbose:\n",
    "        print(\"Number of true objects:\", true_objects - 1)\n",
    "        print(\"Number of predicted objects:\", pred_objects - 1)\n",
    "    \n",
    "    intersection = np.histogram2d(y_true.flatten(), y_pred.flatten(), \n",
    "                                  bins=(true_objects, pred_objects))[0].astype('int')\n",
    "\n",
    "    area_true = np.histogram(y_true, bins = true_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    union = area_true + area_pred - intersection\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "    \n",
    "    iou = intersection / union\n",
    "    \n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn    \n",
    "    \n",
    "    prec = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in thresholds:\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) == 0:\n",
    "            p = 1\n",
    "        else:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        if verbose:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    if verbose:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "from skimage.morphology import label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post-processing functions\n",
    "\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "\n",
    "def get_pred_watershed(upsampled, area_threshold, threshold, sep_threshold, \n",
    "             spread_threshold, alpha, connectivity=2):\n",
    "    img = ((upsampled[:,:,1] > 255 * threshold) &\n",
    "                    (upsampled[:,:,0] < 255 * sep_threshold))\n",
    "    img = binary_fill_holes(img)\n",
    "    img = remove_small_objects(img, area_threshold)\n",
    "    lab_img = label(img, connectivity=connectivity)\n",
    "    distance = upsampled[:,:,1] + alpha * upsampled[:,:,0]\n",
    "    img = 1 * ((distance > 255 * spread_threshold) )\n",
    "    \n",
    "    lab_img = img * watershed(- upsampled[:,:,1], lab_img)\n",
    "\n",
    "    y_pred = np.zeros((lab_img.max(), lab_img.shape[0], lab_img.shape[1]), np.uint16)\n",
    "    i = 0\n",
    "    for lab in range(lab_img.max()):\n",
    "        tmp = (lab_img == lab+1)\n",
    "        if np.sum(tmp.ravel()) > area_threshold:\n",
    "            y_pred[i,:,:] = tmp\n",
    "            i += 1\n",
    "    return y_pred[:i]\n",
    "\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "\n",
    "def get_pred_random_walker(upsampled, area_threshold, threshold, sep_threshold, \n",
    "             spread_threshold, alpha, connectivity=2):\n",
    "    img = ((upsampled[:,:,1] > 255 * threshold) &\n",
    "                    (upsampled[:,:,0] < 255 * sep_threshold))\n",
    "    \n",
    "    img = binary_fill_holes(img)\n",
    "    img = remove_small_objects(img, area_threshold)\n",
    "    markers = label(img, connectivity=connectivity)\n",
    "    distance = upsampled[:,:,1] + alpha * upsampled[:,:,0]\n",
    "    mask = ((distance > 255 * spread_threshold) )\n",
    "    markers[~mask] = -1\n",
    "    \n",
    "    lab_img = random_walker(mask, markers)\n",
    "\n",
    "    y_pred = np.zeros((lab_img.max(), lab_img.shape[0], lab_img.shape[1]), np.uint16)\n",
    "    i = 0\n",
    "    for lab in range(lab_img.max()):\n",
    "        tmp = (lab_img == lab+1)\n",
    "        if np.sum(tmp.ravel()) > area_threshold:\n",
    "            y_pred[i,:,:] = tmp\n",
    "            i += 1\n",
    "    return y_pred[:i]\n",
    "\n",
    "def get_pred(upsampled, area_threshold, threshold, sep_threshold, \n",
    "             spread_threshold, alpha, connectivity=2):\n",
    "    try:\n",
    "        return get_pred_random_walker(upsampled, area_threshold, threshold, \n",
    "                                          sep_threshold, spread_threshold, \n",
    "                                      alpha, connectivity)\n",
    "    except:\n",
    "        return get_pred_watershed(upsampled, area_threshold, threshold, \n",
    "                                          sep_threshold, spread_threshold, \n",
    "                                      alpha, connectivity)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:08,  4.00it/s]/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/skimage/segmentation/random_walker_segmentation.py:91: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  beta /= 10 * data.std()\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/skimage/segmentation/random_walker_segmentation.py:96: RuntimeWarning: invalid value encountered in multiply\n",
      "  gradients *= beta\n",
      "3019it [11:54,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75554\n"
     ]
    }
   ],
   "source": [
    "area_threshold = 20\n",
    "threshold = 0.75\n",
    "sep_threshold = 0.6\n",
    "spread_threshold = 0.4\n",
    "alpha=0.4\n",
    "\n",
    "def get_pred(upsampled, area_threshold=area_threshold, \n",
    "             threshold=threshold, sep_threshold=sep_threshold, \n",
    "             spread_threshold=spread_threshold, alpha=alpha, connectivity=2):\n",
    "    try:\n",
    "        return get_pred_random_walker(upsampled, area_threshold, threshold, \n",
    "                                          sep_threshold, spread_threshold, \n",
    "                                      alpha, connectivity=2)\n",
    "    except:\n",
    "        return get_pred_watershed(upsampled, area_threshold, threshold, \n",
    "                                          sep_threshold, spread_threshold, \n",
    "                                      alpha, connectivity=2)\n",
    "\n",
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "            \n",
    "def pred_to_rles(y_pred):\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        tmp = y_pred[i]\n",
    "        yield rle_encoding(tmp)\n",
    "\n",
    "\n",
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in tqdm(enumerate(test_ids)):\n",
    "    y_pred = get_pred(preds_test_merged[n])\n",
    "    rle = list(pred_to_rles(y_pred))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))\n",
    "\n",
    "print(len(rles))\n",
    "\n",
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.to_csv('keras_unet_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
