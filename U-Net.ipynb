{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stolen from https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, AlphaDropout, Activation\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adamax, Adam, SGD\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = 'train/'\n",
    "#TEST_PATH = 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/607 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 2/607 [00:00<00:40, 15.08it/s]\u001b[A\n",
      "  0%|          | 3/607 [00:00<02:44,  3.67it/s]\u001b[A\n",
      "  1%|          | 4/607 [00:00<02:29,  4.02it/s]\u001b[A\n",
      "  1%|          | 5/607 [00:01<02:24,  4.17it/s]\u001b[A\n",
      "  1%|          | 6/607 [00:01<02:31,  3.96it/s]\u001b[A\n",
      "  1%|          | 7/607 [00:01<02:33,  3.92it/s]\u001b[A\n",
      "  1%|▏         | 9/607 [00:01<02:05,  4.77it/s]\u001b[A\n",
      "  2%|▏         | 11/607 [00:02<01:50,  5.39it/s]\u001b[A\n",
      "  2%|▏         | 13/607 [00:02<01:41,  5.85it/s]\u001b[A\n",
      "  2%|▏         | 15/607 [00:02<01:39,  5.96it/s]\u001b[A\n",
      "  3%|▎         | 17/607 [00:03<01:53,  5.18it/s]\u001b[A\n",
      "  3%|▎         | 18/607 [00:03<01:52,  5.22it/s]\u001b[A\n",
      "  3%|▎         | 20/607 [00:03<01:46,  5.50it/s]\u001b[A\n",
      "  3%|▎         | 21/607 [00:04<02:17,  4.26it/s]\u001b[A\n",
      "  4%|▎         | 22/607 [00:05<02:27,  3.96it/s]\u001b[A\n",
      "  4%|▍         | 24/607 [00:05<02:17,  4.24it/s]\u001b[A\n",
      "  4%|▍         | 26/607 [00:05<02:09,  4.49it/s]\u001b[A\n",
      "  5%|▍         | 29/607 [00:06<02:00,  4.78it/s]\u001b[A\n",
      "  5%|▌         | 31/607 [00:07<02:13,  4.31it/s]\u001b[A\n",
      "  5%|▌         | 32/607 [00:07<02:20,  4.08it/s]\u001b[A\n",
      "  6%|▌         | 34/607 [00:08<02:14,  4.25it/s]\u001b[A\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      " 28%|██▊       | 168/607 [00:33<01:27,  5.04it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train/.ipynb_checkpoints/images/.ipynb_checkpoints.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4cd15bc68d6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTRAIN_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mid_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/images/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mid_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#X_train[n] = img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/scikit_image-0.13.1-py3.6-linux-x86_64.egg/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_grey, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/scikit_image-0.13.1-py3.6-linux-x86_64.egg/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                                (plugin, kind))\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/scikit_image-0.13.1-py3.6-linux-x86_64.egg/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train/.ipynb_checkpoints/images/.ipynb_checkpoints.png'"
     ]
    }
   ],
   "source": [
    "# initializes the training images and target images (masks) as arrays of zeros\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "#gets and resizes the images each containing several nuclei\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:3]\n",
    "    #img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    #X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    #gets and resizes the masks that contain the individual segmented nuclei\n",
    "    #the targets for the model\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (256, 256), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "    \n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603 603 67 67\n",
      "(603, 256, 256, 3) (603, 256, 256, 1) (67, 256, 256, 3) (67, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train, test_size=0.1, random_state=8011)\n",
    "\n",
    "print(len(x_train), len(y_train), len(x_valid), len(y_valid))\n",
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (3, 3), activation=\"elu\", padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (3, 3), activation=\"elu\", padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"elu\", padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\")`\n",
      "  del sys.path[0]\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"elu\", padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\")`\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"elu\", padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\")`\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"elu\", padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\")`\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"elu\", padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\")`\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (7, 1), activation=\"elu\", padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\")`\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 7), activation=\"elu\", padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\")`\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"elu\", padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\")`\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"elu\", padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 256, 256, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 256, 256, 4)  112         lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 256, 256, 4)  148         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 256, 256, 8)  296         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 256, 256, 8)  0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 256, 256, 12) 876         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 256, 256, 20) 0           max_pooling2d_13[0][0]           \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 256, 256, 8)  168         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 256, 256, 8)  456         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 256, 256, 8)  168         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 256, 256, 8)  456         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 256, 256, 12) 876         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 256, 256, 12) 876         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 256, 256, 24) 0           conv2d_66[0][0]                  \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 256, 256, 24) 5208        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 256, 256, 24) 0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 256, 256, 48) 0           conv2d_71[0][0]                  \n",
      "                                                                 max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 48) 0           concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 256, 256, 16) 6928        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 256, 256, 16) 0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 256, 256, 16) 2320        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 128, 128, 16) 0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 128, 128, 32) 4640        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 128, 128, 32) 0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 128, 128, 32) 9248        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 64, 64, 32)   0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 64, 64, 64)   18496       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 64, 64, 64)   0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 64, 64, 64)   36928       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 32, 128)  73856       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 32, 32, 128)  0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 128)  147584      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 16, 16, 128)  0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 256)  0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 16, 16, 256)  590080      dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 32, 32, 128)  131200      conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 32, 32, 256)  0           conv2d_transpose_9[0][0]         \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 32, 32, 128)  0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 32, 32, 128)  147584      dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 64, 64, 64)   32832       conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 64, 64, 128)  0           conv2d_transpose_10[0][0]        \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 64, 64, 64)   0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 64, 64, 64)   36928       dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 128, 128, 32) 8224        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 128, 128, 64) 0           conv2d_transpose_11[0][0]        \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 128, 128, 32) 0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 128, 128, 32) 9248        dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 256, 256, 16) 2064        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 256, 256, 32) 0           conv2d_transpose_12[0][0]        \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 256, 256, 16) 0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 256, 256, 16) 2320        dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 256, 256, 1)  17          conv2d_89[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,957,225\n",
      "Trainable params: 1,957,225\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\neps = 1.1e-5\\nbn_axis = 3\\nimg_input = Input(shape=(256, 256, 3), name='data')\\n\\nx = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)\\nx = Convolution2D(64, 7, 7, subsample=(2, 2), name='conv1', use_bias=False)(x)\\nx = BatchNormalization(epsilon=eps, axis=bn_axis, name='bn_conv1')(x)\\nx = Scale(axis=bn_axis, name='scale_conv1')(x)\\nx = Activation('relu', name='conv1_relu')(x)\\nx = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\\n\\nx = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\\nx = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\\nx = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\\n\\nx = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\\nfor i in range(1,4):\\n  x = identity_block(x, 3, [128, 128, 512], stage=3, block='b'+str(i))\\n\\nx = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\\nfor i in range(1,23):\\n  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b'+str(i))\\n\\n#x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\\n#x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\\n#x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\\n\\n#x_fc = AveragePooling2D((7, 7), name='avg_pool')(x)\\n#x_fc = Flatten()(x_fc)\\n#x_fc = Dense(1000, activation='softmax', name='fc1000')(x_fc)\\n\\nmodel = Model(img_input, x)\\n\\n# Use pre-trained weights for Tensorflow backend\\nweights_path = 'resnet101_weights_tf.h5'\\n\\nmodel.load_weights(weights_path, by_name=True)\\n\\n# Truncate and replace softmax layer for transfer learning\\n# Cannot use model.layers.pop() since model is not of Sequential() type\\n# The method below works since pre-trained weights are stored in layers but not in the model\\n#x_newfc = AveragePooling2D((7, 7), name='avg_pool')(x)\\n#x_newfc = Flatten()(x_newfc)\\nx_newfc = Conv2D(1, (1, 1), activation='sigmoid')(x)\\n\\nmodel = Model(img_input, x_newfc)\\n\\n# Learning rate is changed to 0.001\\nsgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\\nmodel.compile(optimizer=sgd, loss='binary_crossentropy', metrics=[mean_iou])\\nmodel.summary()\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nb_filters_reduction_factor = 8\n",
    "\n",
    "# Build InceptionResnetV2 stem block connected to U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "s = Lambda(lambda x: x/255) (inputs)\n",
    "\n",
    "x = Conv2D(32//nb_filters_reduction_factor, (3, 3), subsample=(1, 1), activation='elu',\n",
    "                      init='he_normal', padding='same')(s)\n",
    "x = Conv2D(32//nb_filters_reduction_factor, (3, 3), subsample=(1, 1), activation='elu',\n",
    "                      init='he_normal', padding='same')(x)\n",
    "x = Conv2D(64//nb_filters_reduction_factor, (3, 3), subsample=(1, 1), activation='elu',\n",
    "                      init='he_normal', padding='same')(x)\n",
    "\n",
    "a = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "\n",
    "b = Conv2D(96//nb_filters_reduction_factor, (3, 3), subsample=(1, 1), activation='elu',\n",
    "                      init='he_normal', padding='same')(x)\n",
    "x = concatenate([a, b], axis=3)\n",
    "\n",
    "a = Conv2D(64//nb_filters_reduction_factor, (1, 1), subsample=(1, 1), activation='elu',\n",
    "                      init='he_normal', padding='same')(x)\n",
    "a = Conv2D(96//nb_filters_reduction_factor, (3, 3), subsample=(1, 1), activation='elu',\n",
    "                      init='he_normal', padding='same')(a)\n",
    "b = Conv2D(64//nb_filters_reduction_factor, (1, 1), subsample=(1, 1), activation='elu',\n",
    "                      init='he_normal', padding='same')(x)\n",
    "b = Conv2D(64//nb_filters_reduction_factor, (7, 1), subsample=(1, 1), activation='elu',\n",
    "                      init='he_normal', padding='same')(b)\n",
    "b = Conv2D(64//nb_filters_reduction_factor, (1, 7), subsample=(1, 1), activation='elu',\n",
    "                      init='he_normal', padding='same')(b)\n",
    "b = Conv2D(96//nb_filters_reduction_factor, (3, 3), subsample=(1, 1), activation='elu',\n",
    "                      init='he_normal', padding='same')(b)\n",
    "\n",
    "x = concatenate([a, b], axis=3)\n",
    "\n",
    "a = Conv2D(192//nb_filters_reduction_factor, (3, 3), subsample=(1, 1), activation='elu',\n",
    "                      init='he_normal', padding='same')(x)\n",
    "\n",
    "b = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "x = concatenate([a, b], axis=3)\n",
    "\n",
    "x = Activation('elu')(x)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (x)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "model.compile(optimizer=Adamax(lr=0.002), loss='binary_crossentropy', metrics=[mean_iou])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\"\"\"\n",
    "#from https://github.com/flyyufelix/cnn_finetune/blob/master/resnet_101.py\n",
    "\n",
    "from keras.layers.core import Layer\n",
    "from keras.engine import InputSpec\n",
    "from keras import backend as K\n",
    "try:\n",
    "    from keras import initializations\n",
    "except ImportError:\n",
    "    from keras import initializers as initializations\n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(3000)\n",
    "\n",
    "class Scale(Layer):\n",
    "    '''Learns a set of weights and biases used for scaling the input data.\n",
    "    the output consists simply in an element-wise multiplication of the input\n",
    "    and a sum of a set of constants:\n",
    "        out = in * gamma + beta,\n",
    "    where 'gamma' and 'beta' are the weights and biases learned.\n",
    "    # Arguments\n",
    "        axis: integer, axis along which to normalize in mode 0. For instance,\n",
    "            if your input tensor has shape (samples, channels, rows, cols),\n",
    "            set axis to 1 to normalize per feature map (channels axis).\n",
    "        momentum: momentum in the computation of the\n",
    "            exponential average of the mean and standard deviation\n",
    "            of the data, for feature-wise normalization.\n",
    "        weights: Initialization weights.\n",
    "            List of 2 Numpy arrays, with shapes:\n",
    "            `[(input_shape,), (input_shape,)]`\n",
    "        beta_init: name of initialization function for shift parameter\n",
    "            (see [initializations](../initializations.md)), or alternatively,\n",
    "            Theano/TensorFlow function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "        gamma_init: name of initialization function for scale parameter (see\n",
    "            [initializations](../initializations.md)), or alternatively,\n",
    "            Theano/TensorFlow function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "    '''\n",
    "    def __init__(self, weights=None, axis=-1, momentum = 0.9, beta_init='zero', gamma_init='one', **kwargs):\n",
    "        self.momentum = momentum\n",
    "        self.axis = axis\n",
    "        self.beta_init = initializations.get(beta_init)\n",
    "        self.gamma_init = initializations.get(gamma_init)\n",
    "        self.initial_weights = weights\n",
    "        super(Scale, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        shape = (int(input_shape[self.axis]),)\n",
    "\n",
    "        # Compatibility with TensorFlow >= 1.0.0\n",
    "        self.gamma = K.variable(self.gamma_init(shape), name='{}_gamma'.format(self.name))\n",
    "        self.beta = K.variable(self.beta_init(shape), name='{}_beta'.format(self.name))\n",
    "        #self.gamma = self.gamma_init(shape, name='{}_gamma'.format(self.name))\n",
    "        #self.beta = self.beta_init(shape, name='{}_beta'.format(self.name))\n",
    "        self.trainable_weights = [self.gamma, self.beta]\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        input_shape = self.input_spec[0].shape\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "\n",
    "        out = K.reshape(self.gamma, broadcast_shape) * x + K.reshape(self.beta, broadcast_shape)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"momentum\": self.momentum, \"axis\": self.axis}\n",
    "        base_config = super(Scale, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    '''The identity_block is the block that has no conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Convolution2D(nb_filter1, 1, 1, name=conv_name_base + '2a', use_bias=False)(input_tensor)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
    "    x = Convolution2D(nb_filter2, kernel_size, kernel_size,\n",
    "                      name=conv_name_base + '2b', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
    "\n",
    "    x = merge([x, input_tensor], mode='sum', name='res' + str(stage) + block)\n",
    "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    '''conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Convolution2D(nb_filter1, 1, 1, subsample=strides,\n",
    "                      name=conv_name_base + '2a', use_bias=False)(input_tensor)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
    "    x = Convolution2D(nb_filter2, kernel_size, kernel_size,\n",
    "                      name=conv_name_base + '2b', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Convolution2D(nb_filter3, 1, 1, subsample=strides,\n",
    "                             name=conv_name_base + '1', bias=False)(input_tensor)\n",
    "    shortcut = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "    shortcut = Scale(axis=bn_axis, name=scale_name_base + '1')(shortcut)\n",
    "\n",
    "    x = merge([x, shortcut], mode='sum', name='res' + str(stage) + block)\n",
    "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
    "    return x\n",
    "\"\"\"\n",
    "    \n",
    "\"\"\"    \n",
    "  Resnet 101 Model for Keras\n",
    "    Model Schema and layer naming follow that of the original Caffe implementation\n",
    "    https://github.com/KaimingHe/deep-residual-networks\n",
    "    ImageNet Pretrained Weights \n",
    "    Theano: https://drive.google.com/file/d/0Byy2AcGyEVxfdUV1MHJhelpnSG8/view?usp=sharing\n",
    "    TensorFlow: https://drive.google.com/file/d/0Byy2AcGyEVxfTmRRVmpGWDczaXM/view?usp=sharing\n",
    "    Parameters:\n",
    "      img_rows, img_cols - resolution of inputs\n",
    "      channel - 1 for grayscale, 3 for color \n",
    "      num_classes - number of class labels for our classification task\n",
    "\"\"\"\n",
    "  \n",
    "\"\"\"\n",
    "eps = 1.1e-5\n",
    "bn_axis = 3\n",
    "img_input = Input(shape=(256, 256, 3), name='data')\n",
    "\n",
    "x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)\n",
    "x = Convolution2D(64, 7, 7, subsample=(2, 2), name='conv1', use_bias=False)(x)\n",
    "x = BatchNormalization(epsilon=eps, axis=bn_axis, name='bn_conv1')(x)\n",
    "x = Scale(axis=bn_axis, name='scale_conv1')(x)\n",
    "x = Activation('relu', name='conv1_relu')(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "for i in range(1,4):\n",
    "  x = identity_block(x, 3, [128, 128, 512], stage=3, block='b'+str(i))\n",
    "\n",
    "x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "for i in range(1,23):\n",
    "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b'+str(i))\n",
    "\n",
    "#x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "#x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "#x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "#x_fc = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "#x_fc = Flatten()(x_fc)\n",
    "#x_fc = Dense(1000, activation='softmax', name='fc1000')(x_fc)\n",
    "\n",
    "model = Model(img_input, x)\n",
    "\n",
    "# Use pre-trained weights for Tensorflow backend\n",
    "weights_path = 'resnet101_weights_tf.h5'\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# Truncate and replace softmax layer for transfer learning\n",
    "# Cannot use model.layers.pop() since model is not of Sequential() type\n",
    "# The method below works since pre-trained weights are stored in layers but not in the model\n",
    "#x_newfc = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "#x_newfc = Flatten()(x_newfc)\n",
    "x_newfc = Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
    "\n",
    "model = Model(img_input, x_newfc)\n",
    "\n",
    "# Learning rate is changed to 0.001\n",
    "sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "data_gen_args = dict(horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         rotation_range=90.,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         zoom_range=0.1)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "image_datagen.fit(x_train, seed=7)\n",
    "mask_datagen.fit(y_train, seed=7)\n",
    "image_generator = image_datagen.flow(x_train, batch_size=32, seed=7)\n",
    "mask_generator = mask_datagen.flow(y_train, batch_size=32, seed=7)\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "val_gen_args = dict()\n",
    "image_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "mask_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "image_datagen_val.fit(x_valid, seed=7)\n",
    "mask_datagen_val.fit(y_valid, seed=7)\n",
    "image_generator_val = image_datagen_val.flow(x_valid, batch_size=32, seed=7)\n",
    "mask_generator_val = mask_datagen_val.flow(y_valid, batch_size=32, seed=7)\n",
    "valid_generator=zip(image_generator_val, mask_generator_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.3721 - mean_iou: 0.4155\n",
      "Epoch 00001: val_loss improved from inf to 0.25759, saving model to best_model.h5\n",
      "603/603 [==============================] - 41s 68ms/step - loss: 0.3698 - mean_iou: 0.4160 - val_loss: 0.2576 - val_mean_iou: 0.4524\n",
      "Epoch 2/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1939 - mean_iou: 0.5135\n",
      "Epoch 00002: val_loss improved from 0.25759 to 0.17971, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.1933 - mean_iou: 0.5142 - val_loss: 0.1797 - val_mean_iou: 0.5593\n",
      "Epoch 3/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1551 - mean_iou: 0.5889\n",
      "Epoch 00003: val_loss improved from 0.17971 to 0.14575, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.1543 - mean_iou: 0.5893 - val_loss: 0.1457 - val_mean_iou: 0.6161\n",
      "Epoch 4/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1344 - mean_iou: 0.6354\n",
      "Epoch 00004: val_loss improved from 0.14575 to 0.13153, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.1346 - mean_iou: 0.6356 - val_loss: 0.1315 - val_mean_iou: 0.6518\n",
      "Epoch 5/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1232 - mean_iou: 0.6660\n",
      "Epoch 00005: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.1221 - mean_iou: 0.6662 - val_loss: 0.1483 - val_mean_iou: 0.6775\n",
      "Epoch 6/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1179 - mean_iou: 0.6879\n",
      "Epoch 00006: val_loss improved from 0.13153 to 0.11503, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.1169 - mean_iou: 0.6880 - val_loss: 0.1150 - val_mean_iou: 0.6959\n",
      "Epoch 7/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1122 - mean_iou: 0.7039\n",
      "Epoch 00007: val_loss improved from 0.11503 to 0.10974, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.1116 - mean_iou: 0.7040 - val_loss: 0.1097 - val_mean_iou: 0.7099\n",
      "Epoch 8/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1150 - mean_iou: 0.7158\n",
      "Epoch 00008: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.1143 - mean_iou: 0.7159 - val_loss: 0.1185 - val_mean_iou: 0.7202\n",
      "Epoch 9/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1093 - mean_iou: 0.7248\n",
      "Epoch 00009: val_loss improved from 0.10974 to 0.10562, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.1085 - mean_iou: 0.7249 - val_loss: 0.1056 - val_mean_iou: 0.7290\n",
      "Epoch 10/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1067 - mean_iou: 0.7332\n",
      "Epoch 00010: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.1066 - mean_iou: 0.7332 - val_loss: 0.1105 - val_mean_iou: 0.7360\n",
      "Epoch 11/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0937 - mean_iou: 0.7392\n",
      "Epoch 00011: val_loss improved from 0.10562 to 0.10548, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0943 - mean_iou: 0.7393 - val_loss: 0.1055 - val_mean_iou: 0.7426\n",
      "Epoch 12/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0919 - mean_iou: 0.7456\n",
      "Epoch 00012: val_loss improved from 0.10548 to 0.09917, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0911 - mean_iou: 0.7456 - val_loss: 0.0992 - val_mean_iou: 0.7489\n",
      "Epoch 13/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0873 - mean_iou: 0.7522\n",
      "Epoch 00013: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0865 - mean_iou: 0.7522 - val_loss: 0.1001 - val_mean_iou: 0.7550\n",
      "Epoch 14/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0897 - mean_iou: 0.7573\n",
      "Epoch 00014: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0910 - mean_iou: 0.7573 - val_loss: 0.1010 - val_mean_iou: 0.7598\n",
      "Epoch 15/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0875 - mean_iou: 0.7619\n",
      "Epoch 00015: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0877 - mean_iou: 0.7619 - val_loss: 0.1023 - val_mean_iou: 0.7642\n",
      "Epoch 16/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0860 - mean_iou: 0.7665\n",
      "Epoch 00016: val_loss improved from 0.09917 to 0.09899, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0855 - mean_iou: 0.7665 - val_loss: 0.0990 - val_mean_iou: 0.7684\n",
      "Epoch 17/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0857 - mean_iou: 0.7703\n",
      "Epoch 00017: val_loss improved from 0.09899 to 0.09754, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0852 - mean_iou: 0.7703 - val_loss: 0.0975 - val_mean_iou: 0.7721\n",
      "Epoch 18/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0856 - mean_iou: 0.7739\n",
      "Epoch 00018: val_loss improved from 0.09754 to 0.09232, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0860 - mean_iou: 0.7739 - val_loss: 0.0923 - val_mean_iou: 0.7754\n",
      "Epoch 19/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0847 - mean_iou: 0.7770\n",
      "Epoch 00019: val_loss improved from 0.09232 to 0.09129, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0854 - mean_iou: 0.7770 - val_loss: 0.0913 - val_mean_iou: 0.7783\n",
      "Epoch 20/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0814 - mean_iou: 0.7799\n",
      "Epoch 00020: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0808 - mean_iou: 0.7799 - val_loss: 0.0995 - val_mean_iou: 0.7814\n",
      "Epoch 21/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0804 - mean_iou: 0.7828\n",
      "Epoch 00021: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0807 - mean_iou: 0.7828 - val_loss: 0.0918 - val_mean_iou: 0.7842\n",
      "Epoch 22/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0784 - mean_iou: 0.7857\n",
      "Epoch 00022: val_loss improved from 0.09129 to 0.09048, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0786 - mean_iou: 0.7857 - val_loss: 0.0905 - val_mean_iou: 0.7869\n",
      "Epoch 23/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0791 - mean_iou: 0.7882\n",
      "Epoch 00023: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0790 - mean_iou: 0.7882 - val_loss: 0.0950 - val_mean_iou: 0.7892\n",
      "Epoch 24/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0797 - mean_iou: 0.7904\n",
      "Epoch 00024: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0793 - mean_iou: 0.7904 - val_loss: 0.0906 - val_mean_iou: 0.7914\n",
      "Epoch 25/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0753 - mean_iou: 0.7927\n",
      "Epoch 00025: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0753 - mean_iou: 0.7927 - val_loss: 0.0909 - val_mean_iou: 0.7939\n",
      "Epoch 26/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0761 - mean_iou: 0.7949\n",
      "Epoch 00026: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0771 - mean_iou: 0.7949 - val_loss: 0.0947 - val_mean_iou: 0.7959\n",
      "Epoch 27/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0816 - mean_iou: 0.7969\n",
      "Epoch 00027: val_loss improved from 0.09048 to 0.09044, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0811 - mean_iou: 0.7969 - val_loss: 0.0904 - val_mean_iou: 0.7976\n",
      "Epoch 28/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0761 - mean_iou: 0.7985\n",
      "Epoch 00028: val_loss improved from 0.09044 to 0.08592, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0758 - mean_iou: 0.7985 - val_loss: 0.0859 - val_mean_iou: 0.7994\n",
      "Epoch 29/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0724 - mean_iou: 0.8003\n",
      "Epoch 00029: val_loss improved from 0.08592 to 0.08471, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0725 - mean_iou: 0.8004 - val_loss: 0.0847 - val_mean_iou: 0.8013\n",
      "Epoch 30/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0740 - mean_iou: 0.8022\n",
      "Epoch 00030: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0741 - mean_iou: 0.8022 - val_loss: 0.0871 - val_mean_iou: 0.8030\n",
      "Epoch 31/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0721 - mean_iou: 0.8039\n",
      "Epoch 00031: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0720 - mean_iou: 0.8039 - val_loss: 0.0881 - val_mean_iou: 0.8048\n",
      "Epoch 32/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0690 - mean_iou: 0.8057\n",
      "Epoch 00032: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0694 - mean_iou: 0.8058 - val_loss: 0.0882 - val_mean_iou: 0.8066\n",
      "Epoch 33/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0762 - mean_iou: 0.8074\n",
      "Epoch 00033: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0787 - mean_iou: 0.8074 - val_loss: 0.1050 - val_mean_iou: 0.8080\n",
      "Epoch 34/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0781 - mean_iou: 0.8085\n",
      "Epoch 00034: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0778 - mean_iou: 0.8085 - val_loss: 0.0864 - val_mean_iou: 0.8091\n",
      "Epoch 35/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0698 - mean_iou: 0.8099\n",
      "Epoch 00035: val_loss improved from 0.08471 to 0.08307, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0694 - mean_iou: 0.8099 - val_loss: 0.0831 - val_mean_iou: 0.8106\n",
      "Epoch 36/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0678 - mean_iou: 0.8113\n",
      "Epoch 00036: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0675 - mean_iou: 0.8113 - val_loss: 0.0862 - val_mean_iou: 0.8121\n",
      "Epoch 37/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0673 - mean_iou: 0.8128\n",
      "Epoch 00037: val_loss improved from 0.08307 to 0.08211, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0671 - mean_iou: 0.8128 - val_loss: 0.0821 - val_mean_iou: 0.8135\n",
      "Epoch 38/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0669 - mean_iou: 0.8142\n",
      "Epoch 00038: val_loss improved from 0.08211 to 0.08132, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0663 - mean_iou: 0.8142 - val_loss: 0.0813 - val_mean_iou: 0.8149\n",
      "Epoch 39/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0655 - mean_iou: 0.8156\n",
      "Epoch 00039: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0657 - mean_iou: 0.8156 - val_loss: 0.0829 - val_mean_iou: 0.8162\n",
      "Epoch 40/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0665 - mean_iou: 0.8169\n",
      "Epoch 00040: val_loss improved from 0.08132 to 0.08026, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0666 - mean_iou: 0.8169 - val_loss: 0.0803 - val_mean_iou: 0.8175\n",
      "Epoch 41/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0659 - mean_iou: 0.8181\n",
      "Epoch 00041: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0657 - mean_iou: 0.8181 - val_loss: 0.0966 - val_mean_iou: 0.8187\n",
      "Epoch 42/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0690 - mean_iou: 0.8192\n",
      "Epoch 00042: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0688 - mean_iou: 0.8192 - val_loss: 0.0842 - val_mean_iou: 0.8197\n",
      "Epoch 43/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0635 - mean_iou: 0.8202\n",
      "Epoch 00043: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0640 - mean_iou: 0.8202 - val_loss: 0.0838 - val_mean_iou: 0.8208\n",
      "Epoch 44/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0639 - mean_iou: 0.8214\n",
      "Epoch 00044: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0636 - mean_iou: 0.8214 - val_loss: 0.0846 - val_mean_iou: 0.8220\n",
      "Epoch 45/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0619 - mean_iou: 0.8226\n",
      "Epoch 00045: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0619 - mean_iou: 0.8226 - val_loss: 0.0826 - val_mean_iou: 0.8231\n",
      "Epoch 46/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0599 - mean_iou: 0.8238\n",
      "Epoch 00046: val_loss improved from 0.08026 to 0.08000, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0600 - mean_iou: 0.8238 - val_loss: 0.0800 - val_mean_iou: 0.8243\n",
      "Epoch 47/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0614 - mean_iou: 0.8248\n",
      "Epoch 00047: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0612 - mean_iou: 0.8248 - val_loss: 0.0811 - val_mean_iou: 0.8254\n",
      "Epoch 48/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0602 - mean_iou: 0.8260\n",
      "Epoch 00048: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0604 - mean_iou: 0.8260 - val_loss: 0.0812 - val_mean_iou: 0.8265\n",
      "Epoch 49/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0602 - mean_iou: 0.8269\n",
      "Epoch 00049: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0599 - mean_iou: 0.8269 - val_loss: 0.0830 - val_mean_iou: 0.8275\n",
      "Epoch 50/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0579 - mean_iou: 0.8280\n",
      "Epoch 00050: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0577 - mean_iou: 0.8280 - val_loss: 0.0855 - val_mean_iou: 0.8286\n",
      "Epoch 51/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0574 - mean_iou: 0.8291\n",
      "Epoch 00051: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0576 - mean_iou: 0.8291 - val_loss: 0.0833 - val_mean_iou: 0.8296\n",
      "Epoch 52/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0591 - mean_iou: 0.8301\n",
      "Epoch 00052: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0591 - mean_iou: 0.8301 - val_loss: 0.0833 - val_mean_iou: 0.8305\n",
      "Epoch 53/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0562 - mean_iou: 0.8311\n",
      "Epoch 00053: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0559 - mean_iou: 0.8311 - val_loss: 0.0816 - val_mean_iou: 0.8316\n",
      "Epoch 54/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0549 - mean_iou: 0.8320\n",
      "Epoch 00054: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0549 - mean_iou: 0.8320 - val_loss: 0.0888 - val_mean_iou: 0.8326\n",
      "Epoch 55/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0567 - mean_iou: 0.8331\n",
      "Epoch 00055: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0567 - mean_iou: 0.8331 - val_loss: 0.0834 - val_mean_iou: 0.8335\n",
      "Epoch 56/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0576 - mean_iou: 0.8338\n",
      "Epoch 00056: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0573 - mean_iou: 0.8338 - val_loss: 0.0850 - val_mean_iou: 0.8343\n",
      "Epoch 57/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0542 - mean_iou: 0.8348\n",
      "Epoch 00057: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0545 - mean_iou: 0.8348 - val_loss: 0.0869 - val_mean_iou: 0.8352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0538 - mean_iou: 0.8357\n",
      "Epoch 00058: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0537 - mean_iou: 0.8357 - val_loss: 0.0900 - val_mean_iou: 0.8361\n",
      "Epoch 59/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0518 - mean_iou: 0.8366\n",
      "Epoch 00059: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0523 - mean_iou: 0.8366 - val_loss: 0.0836 - val_mean_iou: 0.8371\n",
      "Epoch 60/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0534 - mean_iou: 0.8375\n",
      "Epoch 00060: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0538 - mean_iou: 0.8375 - val_loss: 0.0823 - val_mean_iou: 0.8379\n",
      "Epoch 61/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0531 - mean_iou: 0.8383\n",
      "Epoch 00061: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0532 - mean_iou: 0.8383 - val_loss: 0.0884 - val_mean_iou: 0.8387\n",
      "Epoch 62/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0504 - mean_iou: 0.8391\n",
      "Epoch 00062: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0508 - mean_iou: 0.8392 - val_loss: 0.0841 - val_mean_iou: 0.8396\n",
      "Epoch 63/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0530 - mean_iou: 0.8400\n",
      "Epoch 00063: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0529 - mean_iou: 0.8400 - val_loss: 0.0863 - val_mean_iou: 0.8404\n",
      "Epoch 64/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0499 - mean_iou: 0.8408\n",
      "Epoch 00064: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0499 - mean_iou: 0.8408 - val_loss: 0.0843 - val_mean_iou: 0.8413\n",
      "Epoch 65/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0492 - mean_iou: 0.8417\n",
      "Epoch 00065: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0492 - mean_iou: 0.8417 - val_loss: 0.0853 - val_mean_iou: 0.8421\n",
      "Epoch 66/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0490 - mean_iou: 0.8425\n",
      "Epoch 00066: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0491 - mean_iou: 0.8425 - val_loss: 0.0912 - val_mean_iou: 0.8429\n",
      "Epoch 67/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0484 - mean_iou: 0.8433\n",
      "Epoch 00067: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0481 - mean_iou: 0.8433 - val_loss: 0.0847 - val_mean_iou: 0.8437\n",
      "Epoch 68/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0478 - mean_iou: 0.8441\n",
      "Epoch 00068: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0476 - mean_iou: 0.8441 - val_loss: 0.0887 - val_mean_iou: 0.8445\n",
      "Epoch 69/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0464 - mean_iou: 0.8449\n",
      "Epoch 00069: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0464 - mean_iou: 0.8450 - val_loss: 0.0866 - val_mean_iou: 0.8454\n",
      "Epoch 70/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0463 - mean_iou: 0.8457\n",
      "Epoch 00070: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0463 - mean_iou: 0.8457 - val_loss: 0.0866 - val_mean_iou: 0.8461\n",
      "Epoch 71/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0462 - mean_iou: 0.8465\n",
      "Epoch 00071: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0459 - mean_iou: 0.8465 - val_loss: 0.0902 - val_mean_iou: 0.8469\n",
      "Epoch 72/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0461 - mean_iou: 0.8473\n",
      "Epoch 00072: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0461 - mean_iou: 0.8473 - val_loss: 0.0917 - val_mean_iou: 0.8477\n",
      "Epoch 73/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0446 - mean_iou: 0.8480\n",
      "Epoch 00073: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0446 - mean_iou: 0.8480 - val_loss: 0.0921 - val_mean_iou: 0.8484\n",
      "Epoch 74/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0465 - mean_iou: 0.8488\n",
      "Epoch 00074: val_loss did not improve\n",
      "603/603 [==============================] - 33s 56ms/step - loss: 0.0467 - mean_iou: 0.8488 - val_loss: 0.0925 - val_mean_iou: 0.8491\n",
      "Epoch 75/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0466 - mean_iou: 0.8494\n",
      "Epoch 00075: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0466 - mean_iou: 0.8495 - val_loss: 0.0853 - val_mean_iou: 0.8498\n",
      "Epoch 76/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0443 - mean_iou: 0.8501\n",
      "Epoch 00076: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0443 - mean_iou: 0.8501 - val_loss: 0.0903 - val_mean_iou: 0.8505\n",
      "Epoch 77/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0437 - mean_iou: 0.8509\n",
      "Epoch 00077: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0434 - mean_iou: 0.8509 - val_loss: 0.0907 - val_mean_iou: 0.8512\n",
      "Epoch 78/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0438 - mean_iou: 0.8515\n",
      "Epoch 00078: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0437 - mean_iou: 0.8515 - val_loss: 0.0957 - val_mean_iou: 0.8519\n",
      "Epoch 79/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0455 - mean_iou: 0.8522\n",
      "Epoch 00079: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0452 - mean_iou: 0.8522 - val_loss: 0.0963 - val_mean_iou: 0.8525\n",
      "Epoch 80/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0488 - mean_iou: 0.8528\n",
      "Epoch 00080: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0486 - mean_iou: 0.8528 - val_loss: 0.0916 - val_mean_iou: 0.8531\n",
      "Epoch 81/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0448 - mean_iou: 0.8533\n",
      "Epoch 00081: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0446 - mean_iou: 0.8534 - val_loss: 0.0928 - val_mean_iou: 0.8537\n",
      "Epoch 82/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0410 - mean_iou: 0.8540\n",
      "Epoch 00082: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0410 - mean_iou: 0.8540 - val_loss: 0.0948 - val_mean_iou: 0.8544\n",
      "Epoch 83/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0408 - mean_iou: 0.8547\n",
      "Epoch 00083: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0408 - mean_iou: 0.8547 - val_loss: 0.0941 - val_mean_iou: 0.8551\n",
      "Epoch 84/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0412 - mean_iou: 0.8554\n",
      "Epoch 00084: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0411 - mean_iou: 0.8554 - val_loss: 0.1009 - val_mean_iou: 0.8557\n",
      "Epoch 85/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0411 - mean_iou: 0.8560\n",
      "Epoch 00085: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0415 - mean_iou: 0.8560 - val_loss: 0.0942 - val_mean_iou: 0.8563\n",
      "Epoch 86/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0403 - mean_iou: 0.8566\n",
      "Epoch 00086: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0403 - mean_iou: 0.8566 - val_loss: 0.0985 - val_mean_iou: 0.8570\n",
      "Epoch 87/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0380 - mean_iou: 0.8573\n",
      "Epoch 00087: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0383 - mean_iou: 0.8573 - val_loss: 0.0970 - val_mean_iou: 0.8576\n",
      "Epoch 88/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0380 - mean_iou: 0.8580\n",
      "Epoch 00088: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0381 - mean_iou: 0.8580 - val_loss: 0.0970 - val_mean_iou: 0.8583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0386 - mean_iou: 0.8586\n",
      "Epoch 00089: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0388 - mean_iou: 0.8586 - val_loss: 0.0970 - val_mean_iou: 0.8589\n",
      "Epoch 90/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0389 - mean_iou: 0.8592\n",
      "Epoch 00090: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0388 - mean_iou: 0.8592 - val_loss: 0.0974 - val_mean_iou: 0.8595\n",
      "Epoch 91/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0381 - mean_iou: 0.8598\n",
      "Epoch 00091: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0382 - mean_iou: 0.8598 - val_loss: 0.0983 - val_mean_iou: 0.8601\n",
      "Epoch 92/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0380 - mean_iou: 0.8604\n",
      "Epoch 00092: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0379 - mean_iou: 0.8604 - val_loss: 0.0964 - val_mean_iou: 0.8607\n",
      "Epoch 93/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0385 - mean_iou: 0.8610\n",
      "Epoch 00093: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0383 - mean_iou: 0.8610 - val_loss: 0.0946 - val_mean_iou: 0.8613\n",
      "Epoch 94/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0373 - mean_iou: 0.8616\n",
      "Epoch 00094: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0372 - mean_iou: 0.8616 - val_loss: 0.0978 - val_mean_iou: 0.8619\n",
      "Epoch 95/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0367 - mean_iou: 0.8622\n",
      "Epoch 00095: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0365 - mean_iou: 0.8622 - val_loss: 0.0997 - val_mean_iou: 0.8625\n",
      "Epoch 96/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0373 - mean_iou: 0.8628\n",
      "Epoch 00096: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0372 - mean_iou: 0.8628 - val_loss: 0.0974 - val_mean_iou: 0.8630\n",
      "Epoch 97/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0380 - mean_iou: 0.8633\n",
      "Epoch 00097: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0380 - mean_iou: 0.8633 - val_loss: 0.0966 - val_mean_iou: 0.8636\n",
      "Epoch 98/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0364 - mean_iou: 0.8639\n",
      "Epoch 00098: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0364 - mean_iou: 0.8639 - val_loss: 0.1064 - val_mean_iou: 0.8641\n",
      "Epoch 99/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0351 - mean_iou: 0.8644\n",
      "Epoch 00099: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0351 - mean_iou: 0.8644 - val_loss: 0.1075 - val_mean_iou: 0.8647\n",
      "Epoch 100/100\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0350 - mean_iou: 0.8650\n",
      "Epoch 00100: val_loss did not improve\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0352 - mean_iou: 0.8650 - val_loss: 0.1028 - val_mean_iou: 0.8653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe9c62eb080>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "#lr_reduce = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience=5, min_lr = 0.00001)\n",
    "#earlystop = EarlyStopping(patience=30, verbose=1)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "#model.fit_generator(train_generator, steps_per_epoch=len(x_train)/6, epochs=50,validation_data=valid_generator, validation_steps=len(xval)/batch_size)\n",
    "    \n",
    "model.fit(x_train, y_train, batch_size=16, epochs = 100, validation_data=(x_valid, y_valid), callbacks = [checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0586 - mean_iou: 0.8479\n",
      "Epoch 00001: val_loss improved from inf to 0.07997, saving model to best_model.h5\n",
      "603/603 [==============================] - 37s 61ms/step - loss: 0.0587 - mean_iou: 0.8483 - val_loss: 0.0800 - val_mean_iou: 0.8699\n",
      "Epoch 2/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0581 - mean_iou: 0.8721\n",
      "Epoch 00002: val_loss improved from 0.07997 to 0.07987, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 56ms/step - loss: 0.0582 - mean_iou: 0.8721 - val_loss: 0.0799 - val_mean_iou: 0.8724\n",
      "Epoch 3/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0579 - mean_iou: 0.8729\n",
      "Epoch 00003: val_loss improved from 0.07987 to 0.07983, saving model to best_model.h5\n",
      "603/603 [==============================] - 34s 56ms/step - loss: 0.0580 - mean_iou: 0.8729 - val_loss: 0.0798 - val_mean_iou: 0.8738\n",
      "Epoch 4/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0580 - mean_iou: 0.8744\n",
      "Epoch 00004: val_loss improved from 0.07983 to 0.07973, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 56ms/step - loss: 0.0578 - mean_iou: 0.8744 - val_loss: 0.0797 - val_mean_iou: 0.8748\n",
      "Epoch 5/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0581 - mean_iou: 0.8752\n",
      "Epoch 00005: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0576 - mean_iou: 0.8752 - val_loss: 0.0799 - val_mean_iou: 0.8756\n",
      "Epoch 6/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0569 - mean_iou: 0.8758\n",
      "Epoch 00006: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0576 - mean_iou: 0.8759 - val_loss: 0.0800 - val_mean_iou: 0.8762\n",
      "Epoch 7/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0580 - mean_iou: 0.8767\n",
      "Epoch 00007: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0575 - mean_iou: 0.8767 - val_loss: 0.0799 - val_mean_iou: 0.8768\n",
      "Epoch 8/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0575 - mean_iou: 0.8770\n",
      "Epoch 00008: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0574 - mean_iou: 0.8770 - val_loss: 0.0798 - val_mean_iou: 0.8772\n",
      "Epoch 9/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0577 - mean_iou: 0.8773\n",
      "Epoch 00009: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0575 - mean_iou: 0.8773 - val_loss: 0.0800 - val_mean_iou: 0.8775\n",
      "Epoch 10/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0571 - mean_iou: 0.8776\n",
      "Epoch 00010: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0574 - mean_iou: 0.8776 - val_loss: 0.0798 - val_mean_iou: 0.8778\n",
      "Epoch 11/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0576 - mean_iou: 0.8780\n",
      "Epoch 00011: val_loss improved from 0.07973 to 0.07960, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0573 - mean_iou: 0.8780 - val_loss: 0.0796 - val_mean_iou: 0.8781\n",
      "Epoch 12/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0574 - mean_iou: 0.8783\n",
      "Epoch 00012: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0573 - mean_iou: 0.8783 - val_loss: 0.0796 - val_mean_iou: 0.8783\n",
      "Epoch 13/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0576 - mean_iou: 0.8786\n",
      "Epoch 00013: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0573 - mean_iou: 0.8786 - val_loss: 0.0797 - val_mean_iou: 0.8786\n",
      "Epoch 14/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0578 - mean_iou: 0.8787\n",
      "Epoch 00014: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0572 - mean_iou: 0.8787 - val_loss: 0.0800 - val_mean_iou: 0.8787\n",
      "Epoch 15/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0575 - mean_iou: 0.8788\n",
      "Epoch 00015: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0572 - mean_iou: 0.8788 - val_loss: 0.0797 - val_mean_iou: 0.8789\n",
      "Epoch 16/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0572 - mean_iou: 0.8789\n",
      "Epoch 00016: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0572 - mean_iou: 0.8789 - val_loss: 0.0800 - val_mean_iou: 0.8790\n",
      "Epoch 17/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0572 - mean_iou: 0.8791\n",
      "Epoch 00017: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0571 - mean_iou: 0.8791 - val_loss: 0.0796 - val_mean_iou: 0.8792\n",
      "Epoch 18/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0572 - mean_iou: 0.8793\n",
      "Epoch 00018: val_loss improved from 0.07960 to 0.07957, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0571 - mean_iou: 0.8793 - val_loss: 0.0796 - val_mean_iou: 0.8793\n",
      "Epoch 19/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0572 - mean_iou: 0.8794\n",
      "Epoch 00019: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0572 - mean_iou: 0.8794 - val_loss: 0.0799 - val_mean_iou: 0.8795\n",
      "Epoch 20/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0570 - mean_iou: 0.8796\n",
      "Epoch 00020: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0571 - mean_iou: 0.8796 - val_loss: 0.0797 - val_mean_iou: 0.8796\n",
      "Epoch 21/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0567 - mean_iou: 0.8797\n",
      "Epoch 00021: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0570 - mean_iou: 0.8797 - val_loss: 0.0796 - val_mean_iou: 0.8797\n",
      "Epoch 22/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0569 - mean_iou: 0.8798\n",
      "Epoch 00022: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0571 - mean_iou: 0.8798 - val_loss: 0.0800 - val_mean_iou: 0.8798\n",
      "Epoch 23/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0568 - mean_iou: 0.8799\n",
      "Epoch 00023: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0570 - mean_iou: 0.8799 - val_loss: 0.0798 - val_mean_iou: 0.8799\n",
      "Epoch 24/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0575 - mean_iou: 0.8800\n",
      "Epoch 00024: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0571 - mean_iou: 0.8800 - val_loss: 0.0798 - val_mean_iou: 0.8800\n",
      "Epoch 25/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0570 - mean_iou: 0.8800\n",
      "Epoch 00025: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0569 - mean_iou: 0.8800 - val_loss: 0.0799 - val_mean_iou: 0.8801\n",
      "Epoch 26/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0571 - mean_iou: 0.8802\n",
      "Epoch 00026: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0569 - mean_iou: 0.8802 - val_loss: 0.0796 - val_mean_iou: 0.8802\n",
      "Epoch 27/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0573 - mean_iou: 0.8802\n",
      "Epoch 00027: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0570 - mean_iou: 0.8802 - val_loss: 0.0800 - val_mean_iou: 0.8803\n",
      "Epoch 28/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0571 - mean_iou: 0.8803\n",
      "Epoch 00028: val_loss improved from 0.07957 to 0.07955, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0570 - mean_iou: 0.8803 - val_loss: 0.0796 - val_mean_iou: 0.8804\n",
      "Epoch 29/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0575 - mean_iou: 0.8804\n",
      "Epoch 00029: val_loss improved from 0.07955 to 0.07955, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0569 - mean_iou: 0.8804 - val_loss: 0.0795 - val_mean_iou: 0.8804\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 0s - loss: 0.0566 - mean_iou: 0.8805\n",
      "Epoch 00030: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0569 - mean_iou: 0.8805 - val_loss: 0.0797 - val_mean_iou: 0.8805\n",
      "Epoch 31/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0564 - mean_iou: 0.8805\n",
      "Epoch 00031: val_loss improved from 0.07955 to 0.07948, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0569 - mean_iou: 0.8805 - val_loss: 0.0795 - val_mean_iou: 0.8806\n",
      "Epoch 32/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0564 - mean_iou: 0.8806\n",
      "Epoch 00032: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0569 - mean_iou: 0.8806 - val_loss: 0.0797 - val_mean_iou: 0.8806\n",
      "Epoch 33/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0569 - mean_iou: 0.8807\n",
      "Epoch 00033: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0569 - mean_iou: 0.8807 - val_loss: 0.0799 - val_mean_iou: 0.8807\n",
      "Epoch 34/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0572 - mean_iou: 0.8807\n",
      "Epoch 00034: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0569 - mean_iou: 0.8807 - val_loss: 0.0798 - val_mean_iou: 0.8807\n",
      "Epoch 35/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0556 - mean_iou: 0.8808\n",
      "Epoch 00035: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0568 - mean_iou: 0.8808 - val_loss: 0.0799 - val_mean_iou: 0.8808\n",
      "Epoch 36/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0568 - mean_iou: 0.8808\n",
      "Epoch 00036: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0569 - mean_iou: 0.8808 - val_loss: 0.0800 - val_mean_iou: 0.8808\n",
      "Epoch 37/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0569 - mean_iou: 0.8809\n",
      "Epoch 00037: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0568 - mean_iou: 0.8809 - val_loss: 0.0798 - val_mean_iou: 0.8809\n",
      "Epoch 38/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0567 - mean_iou: 0.8810\n",
      "Epoch 00038: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0568 - mean_iou: 0.8810 - val_loss: 0.0796 - val_mean_iou: 0.8809\n",
      "Epoch 39/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0569 - mean_iou: 0.8809\n",
      "Epoch 00039: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0568 - mean_iou: 0.8809 - val_loss: 0.0799 - val_mean_iou: 0.8810\n",
      "Epoch 40/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0569 - mean_iou: 0.8810\n",
      "Epoch 00040: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0569 - mean_iou: 0.8810 - val_loss: 0.0796 - val_mean_iou: 0.8810\n",
      "Epoch 41/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0571 - mean_iou: 0.8811\n",
      "Epoch 00041: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0568 - mean_iou: 0.8811 - val_loss: 0.0798 - val_mean_iou: 0.8811\n",
      "Epoch 42/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0568 - mean_iou: 0.8811\n",
      "Epoch 00042: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0567 - mean_iou: 0.8811 - val_loss: 0.0796 - val_mean_iou: 0.8811\n",
      "Epoch 43/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0560 - mean_iou: 0.8812\n",
      "Epoch 00043: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0568 - mean_iou: 0.8812 - val_loss: 0.0796 - val_mean_iou: 0.8812\n",
      "Epoch 44/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0564 - mean_iou: 0.8812\n",
      "Epoch 00044: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0567 - mean_iou: 0.8812 - val_loss: 0.0798 - val_mean_iou: 0.8812\n",
      "Epoch 45/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0572 - mean_iou: 0.8812\n",
      "Epoch 00045: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0566 - mean_iou: 0.8812 - val_loss: 0.0796 - val_mean_iou: 0.8812\n",
      "Epoch 46/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0570 - mean_iou: 0.8813\n",
      "Epoch 00046: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0566 - mean_iou: 0.8813 - val_loss: 0.0798 - val_mean_iou: 0.8813\n",
      "Epoch 47/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0568 - mean_iou: 0.8813\n",
      "Epoch 00047: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0566 - mean_iou: 0.8813 - val_loss: 0.0801 - val_mean_iou: 0.8813\n",
      "Epoch 48/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0568 - mean_iou: 0.8813\n",
      "Epoch 00048: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0568 - mean_iou: 0.8813 - val_loss: 0.0796 - val_mean_iou: 0.8814\n",
      "Epoch 49/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0568 - mean_iou: 0.8814\n",
      "Epoch 00049: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0566 - mean_iou: 0.8814 - val_loss: 0.0800 - val_mean_iou: 0.8814\n",
      "Epoch 50/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0564 - mean_iou: 0.8814\n",
      "Epoch 00050: val_loss did not improve\n",
      "603/603 [==============================] - 32s 54ms/step - loss: 0.0567 - mean_iou: 0.8814 - val_loss: 0.0798 - val_mean_iou: 0.8814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe9c62eb208>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_reduce = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience=5, min_lr = 0.0001)\n",
    "earlystop = EarlyStopping(patience=30, verbose=1)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "model.compile(optimizer=SGD(lr=0.002), loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.fit(x_train, y_train, batch_size=16, epochs = 50, validation_data=(x_valid, y_valid), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1704 - mean_iou: 0.7220\n",
      "Epoch 00001: val_loss improved from inf to 0.14717, saving model to best_model.h5\n",
      "603/603 [==============================] - 38s 63ms/step - loss: 0.1704 - mean_iou: 0.7219 - val_loss: 0.1472 - val_mean_iou: 0.7166\n",
      "Epoch 2/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1519 - mean_iou: 0.7175\n",
      "Epoch 00002: val_loss improved from 0.14717 to 0.13945, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 56ms/step - loss: 0.1518 - mean_iou: 0.7176 - val_loss: 0.1394 - val_mean_iou: 0.7197\n",
      "Epoch 3/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1214 - mean_iou: 0.7295\n",
      "Epoch 00003: val_loss improved from 0.13945 to 0.12283, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.1221 - mean_iou: 0.7297 - val_loss: 0.1228 - val_mean_iou: 0.7372\n",
      "Epoch 4/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1044 - mean_iou: 0.7460\n",
      "Epoch 00004: val_loss improved from 0.12283 to 0.10322, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.1037 - mean_iou: 0.7461 - val_loss: 0.1032 - val_mean_iou: 0.7555\n",
      "Epoch 5/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0922 - mean_iou: 0.7637\n",
      "Epoch 00005: val_loss improved from 0.10322 to 0.09705, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0924 - mean_iou: 0.7638 - val_loss: 0.0970 - val_mean_iou: 0.7702\n",
      "Epoch 6/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0837 - mean_iou: 0.7768\n",
      "Epoch 00006: val_loss improved from 0.09705 to 0.09283, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0843 - mean_iou: 0.7769 - val_loss: 0.0928 - val_mean_iou: 0.7824\n",
      "Epoch 7/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0840 - mean_iou: 0.7867\n",
      "Epoch 00007: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0832 - mean_iou: 0.7867 - val_loss: 0.0932 - val_mean_iou: 0.7909\n",
      "Epoch 8/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0816 - mean_iou: 0.7947\n",
      "Epoch 00008: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0817 - mean_iou: 0.7947 - val_loss: 0.1078 - val_mean_iou: 0.7971\n",
      "Epoch 9/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0814 - mean_iou: 0.7997\n",
      "Epoch 00009: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0807 - mean_iou: 0.7997 - val_loss: 0.0990 - val_mean_iou: 0.8025\n",
      "Epoch 10/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0823 - mean_iou: 0.8040\n",
      "Epoch 00010: val_loss improved from 0.09283 to 0.09125, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0817 - mean_iou: 0.8040 - val_loss: 0.0913 - val_mean_iou: 0.8062\n",
      "Epoch 11/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0807 - mean_iou: 0.8084\n",
      "Epoch 00011: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0798 - mean_iou: 0.8085 - val_loss: 0.1007 - val_mean_iou: 0.8099\n",
      "Epoch 12/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0808 - mean_iou: 0.8119\n",
      "Epoch 00012: val_loss improved from 0.09125 to 0.08939, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0809 - mean_iou: 0.8119 - val_loss: 0.0894 - val_mean_iou: 0.8133\n",
      "Epoch 13/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0870 - mean_iou: 0.8147\n",
      "Epoch 00013: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0865 - mean_iou: 0.8147 - val_loss: 0.2285 - val_mean_iou: 0.8152\n",
      "Epoch 14/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1078 - mean_iou: 0.8146\n",
      "Epoch 00014: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.1079 - mean_iou: 0.8146 - val_loss: 0.0978 - val_mean_iou: 0.8149\n",
      "Epoch 15/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0811 - mean_iou: 0.8156\n",
      "Epoch 00015: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0822 - mean_iou: 0.8156 - val_loss: 0.0925 - val_mean_iou: 0.8164\n",
      "Epoch 16/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0760 - mean_iou: 0.8176\n",
      "Epoch 00016: val_loss improved from 0.08939 to 0.08685, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0759 - mean_iou: 0.8176 - val_loss: 0.0868 - val_mean_iou: 0.8190\n",
      "Epoch 17/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0745 - mean_iou: 0.8201\n",
      "Epoch 00017: val_loss improved from 0.08685 to 0.08478, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0740 - mean_iou: 0.8201 - val_loss: 0.0848 - val_mean_iou: 0.8212\n",
      "Epoch 18/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0706 - mean_iou: 0.8221\n",
      "Epoch 00018: val_loss improved from 0.08478 to 0.08378, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0705 - mean_iou: 0.8222 - val_loss: 0.0838 - val_mean_iou: 0.8233\n",
      "Epoch 19/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0712 - mean_iou: 0.8244\n",
      "Epoch 00019: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0711 - mean_iou: 0.8244 - val_loss: 0.1075 - val_mean_iou: 0.8252\n",
      "Epoch 20/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1708 - mean_iou: 0.8233\n",
      "Epoch 00020: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.1715 - mean_iou: 0.8232 - val_loss: 0.1444 - val_mean_iou: 0.8197\n",
      "Epoch 21/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.1372 - mean_iou: 0.8174\n",
      "Epoch 00021: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.1365 - mean_iou: 0.8174 - val_loss: 0.1025 - val_mean_iou: 0.8170\n",
      "Epoch 22/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0895 - mean_iou: 0.8172\n",
      "Epoch 00022: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0888 - mean_iou: 0.8172 - val_loss: 0.0966 - val_mean_iou: 0.8176\n",
      "Epoch 23/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0815 - mean_iou: 0.8182\n",
      "Epoch 00023: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0818 - mean_iou: 0.8182 - val_loss: 0.0900 - val_mean_iou: 0.8186\n",
      "Epoch 24/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0793 - mean_iou: 0.8192\n",
      "Epoch 00024: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0801 - mean_iou: 0.8192 - val_loss: 0.0896 - val_mean_iou: 0.8197\n",
      "Epoch 25/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0753 - mean_iou: 0.8203\n",
      "Epoch 00025: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0759 - mean_iou: 0.8203 - val_loss: 0.0897 - val_mean_iou: 0.8209\n",
      "Epoch 26/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0740 - mean_iou: 0.8216\n",
      "Epoch 00026: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0743 - mean_iou: 0.8216 - val_loss: 0.0861 - val_mean_iou: 0.8222\n",
      "Epoch 27/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0750 - mean_iou: 0.8228\n",
      "Epoch 00027: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0750 - mean_iou: 0.8228 - val_loss: 0.0858 - val_mean_iou: 0.8234\n",
      "Epoch 28/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0730 - mean_iou: 0.8238\n",
      "Epoch 00028: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0726 - mean_iou: 0.8238 - val_loss: 0.0841 - val_mean_iou: 0.8245\n",
      "Epoch 29/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0705 - mean_iou: 0.8251\n",
      "Epoch 00029: val_loss improved from 0.08378 to 0.08273, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0703 - mean_iou: 0.8251 - val_loss: 0.0827 - val_mean_iou: 0.8257\n",
      "Epoch 30/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0700 - mean_iou: 0.8264\n",
      "Epoch 00030: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0707 - mean_iou: 0.8264 - val_loss: 0.0868 - val_mean_iou: 0.8269\n",
      "Epoch 31/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0706 - mean_iou: 0.8274\n",
      "Epoch 00031: val_loss improved from 0.08273 to 0.08089, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0706 - mean_iou: 0.8274 - val_loss: 0.0809 - val_mean_iou: 0.8279\n",
      "Epoch 32/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0677 - mean_iou: 0.8286\n",
      "Epoch 00032: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0676 - mean_iou: 0.8286 - val_loss: 0.0850 - val_mean_iou: 0.8291\n",
      "Epoch 33/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0670 - mean_iou: 0.8297\n",
      "Epoch 00033: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0680 - mean_iou: 0.8297 - val_loss: 0.0809 - val_mean_iou: 0.8302\n",
      "Epoch 34/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0675 - mean_iou: 0.8307\n",
      "Epoch 00034: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0671 - mean_iou: 0.8307 - val_loss: 0.0822 - val_mean_iou: 0.8313\n",
      "Epoch 35/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0658 - mean_iou: 0.8318\n",
      "Epoch 00035: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0652 - mean_iou: 0.8318 - val_loss: 0.0810 - val_mean_iou: 0.8323\n",
      "Epoch 36/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0666 - mean_iou: 0.8328\n",
      "Epoch 00036: val_loss improved from 0.08089 to 0.08065, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0663 - mean_iou: 0.8328 - val_loss: 0.0806 - val_mean_iou: 0.8333\n",
      "Epoch 37/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0692 - mean_iou: 0.8337\n",
      "Epoch 00037: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0685 - mean_iou: 0.8337 - val_loss: 0.0845 - val_mean_iou: 0.8341\n",
      "Epoch 38/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0673 - mean_iou: 0.8345\n",
      "Epoch 00038: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0672 - mean_iou: 0.8345 - val_loss: 0.0864 - val_mean_iou: 0.8349\n",
      "Epoch 39/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0710 - mean_iou: 0.8353\n",
      "Epoch 00039: val_loss improved from 0.08065 to 0.08041, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0704 - mean_iou: 0.8353 - val_loss: 0.0804 - val_mean_iou: 0.8356\n",
      "Epoch 40/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0686 - mean_iou: 0.8360\n",
      "Epoch 00040: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0680 - mean_iou: 0.8360 - val_loss: 0.0886 - val_mean_iou: 0.8363\n",
      "Epoch 41/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0670 - mean_iou: 0.8367\n",
      "Epoch 00041: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0664 - mean_iou: 0.8367 - val_loss: 0.0832 - val_mean_iou: 0.8371\n",
      "Epoch 42/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0649 - mean_iou: 0.8375\n",
      "Epoch 00042: val_loss improved from 0.08041 to 0.07794, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0646 - mean_iou: 0.8375 - val_loss: 0.0779 - val_mean_iou: 0.8379\n",
      "Epoch 43/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0645 - mean_iou: 0.8383\n",
      "Epoch 00043: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0644 - mean_iou: 0.8383 - val_loss: 0.0809 - val_mean_iou: 0.8386\n",
      "Epoch 44/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0644 - mean_iou: 0.8390\n",
      "Epoch 00044: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0643 - mean_iou: 0.8390 - val_loss: 0.0795 - val_mean_iou: 0.8394\n",
      "Epoch 45/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0627 - mean_iou: 0.8398\n",
      "Epoch 00045: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0622 - mean_iou: 0.8398 - val_loss: 0.0792 - val_mean_iou: 0.8401\n",
      "Epoch 46/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0641 - mean_iou: 0.8405\n",
      "Epoch 00046: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0637 - mean_iou: 0.8405 - val_loss: 0.0811 - val_mean_iou: 0.8408\n",
      "Epoch 47/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0701 - mean_iou: 0.8411\n",
      "Epoch 00047: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0699 - mean_iou: 0.8411 - val_loss: 0.0865 - val_mean_iou: 0.8413\n",
      "Epoch 48/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0663 - mean_iou: 0.8416\n",
      "Epoch 00048: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0662 - mean_iou: 0.8416 - val_loss: 0.0808 - val_mean_iou: 0.8419\n",
      "Epoch 49/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0625 - mean_iou: 0.8422\n",
      "Epoch 00049: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0628 - mean_iou: 0.8422 - val_loss: 0.0786 - val_mean_iou: 0.8425\n",
      "Epoch 50/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0617 - mean_iou: 0.8428\n",
      "Epoch 00050: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0617 - mean_iou: 0.8428 - val_loss: 0.0786 - val_mean_iou: 0.8432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea495573c8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "model.compile(optimizer=Adam(lr=0.002), loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.fit(x_train, y_train, batch_size=16, epochs = 50, validation_data=(x_valid, y_valid), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0620 - mean_iou: 0.8545\n",
      "Epoch 00001: val_loss improved from inf to 0.07860, saving model to best_model.h5\n",
      "603/603 [==============================] - 38s 63ms/step - loss: 0.0617 - mean_iou: 0.8549 - val_loss: 0.0786 - val_mean_iou: 0.8757\n",
      "Epoch 2/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0578 - mean_iou: 0.8772\n",
      "Epoch 00002: val_loss improved from 0.07860 to 0.07756, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0585 - mean_iou: 0.8773 - val_loss: 0.0776 - val_mean_iou: 0.8777\n",
      "Epoch 3/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0584 - mean_iou: 0.8792\n",
      "Epoch 00003: val_loss improved from 0.07756 to 0.07751, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0583 - mean_iou: 0.8792 - val_loss: 0.0775 - val_mean_iou: 0.8791\n",
      "Epoch 4/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0576 - mean_iou: 0.8797\n",
      "Epoch 00004: val_loss improved from 0.07751 to 0.07667, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0575 - mean_iou: 0.8797 - val_loss: 0.0767 - val_mean_iou: 0.8799\n",
      "Epoch 5/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0568 - mean_iou: 0.8809\n",
      "Epoch 00005: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0571 - mean_iou: 0.8809 - val_loss: 0.0770 - val_mean_iou: 0.8806\n",
      "Epoch 6/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0569 - mean_iou: 0.8811\n",
      "Epoch 00006: val_loss improved from 0.07667 to 0.07623, saving model to best_model.h5\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0567 - mean_iou: 0.8811 - val_loss: 0.0762 - val_mean_iou: 0.8811\n",
      "Epoch 7/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0565 - mean_iou: 0.8813\n",
      "Epoch 00007: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0564 - mean_iou: 0.8813 - val_loss: 0.0772 - val_mean_iou: 0.8816\n",
      "Epoch 8/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0562 - mean_iou: 0.8818\n",
      "Epoch 00008: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0560 - mean_iou: 0.8818 - val_loss: 0.0792 - val_mean_iou: 0.8822\n",
      "Epoch 9/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0564 - mean_iou: 0.8825\n",
      "Epoch 00009: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0562 - mean_iou: 0.8825 - val_loss: 0.0787 - val_mean_iou: 0.8825\n",
      "Epoch 10/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0560 - mean_iou: 0.8827\n",
      "Epoch 00010: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0560 - mean_iou: 0.8827 - val_loss: 0.0768 - val_mean_iou: 0.8828\n",
      "Epoch 11/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0546 - mean_iou: 0.8830\n",
      "Epoch 00011: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0556 - mean_iou: 0.8830 - val_loss: 0.0768 - val_mean_iou: 0.8832\n",
      "Epoch 12/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0554 - mean_iou: 0.8832\n",
      "Epoch 00012: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0552 - mean_iou: 0.8832 - val_loss: 0.0764 - val_mean_iou: 0.8834\n",
      "Epoch 13/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0548 - mean_iou: 0.8835\n",
      "Epoch 00013: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0547 - mean_iou: 0.8835 - val_loss: 0.0772 - val_mean_iou: 0.8837\n",
      "Epoch 14/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0543 - mean_iou: 0.8838\n",
      "Epoch 00014: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0546 - mean_iou: 0.8838 - val_loss: 0.0775 - val_mean_iou: 0.8840\n",
      "Epoch 15/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0547 - mean_iou: 0.8841\n",
      "Epoch 00015: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0545 - mean_iou: 0.8841 - val_loss: 0.0770 - val_mean_iou: 0.8843\n",
      "Epoch 16/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0544 - mean_iou: 0.8843\n",
      "Epoch 00016: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0541 - mean_iou: 0.8843 - val_loss: 0.0779 - val_mean_iou: 0.8845\n",
      "Epoch 17/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0537 - mean_iou: 0.8847\n",
      "Epoch 00017: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0539 - mean_iou: 0.8847 - val_loss: 0.0773 - val_mean_iou: 0.8849\n",
      "Epoch 18/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0533 - mean_iou: 0.8851\n",
      "Epoch 00018: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0534 - mean_iou: 0.8851 - val_loss: 0.0767 - val_mean_iou: 0.8852\n",
      "Epoch 19/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0532 - mean_iou: 0.8853\n",
      "Epoch 00019: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0532 - mean_iou: 0.8853 - val_loss: 0.0770 - val_mean_iou: 0.8854\n",
      "Epoch 20/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0535 - mean_iou: 0.8855\n",
      "Epoch 00020: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0534 - mean_iou: 0.8855 - val_loss: 0.0787 - val_mean_iou: 0.8856\n",
      "Epoch 21/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0527 - mean_iou: 0.8858\n",
      "Epoch 00021: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0528 - mean_iou: 0.8858 - val_loss: 0.0786 - val_mean_iou: 0.8859\n",
      "Epoch 22/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0530 - mean_iou: 0.8860\n",
      "Epoch 00022: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0527 - mean_iou: 0.8860 - val_loss: 0.0775 - val_mean_iou: 0.8862\n",
      "Epoch 23/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0530 - mean_iou: 0.8862\n",
      "Epoch 00023: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0525 - mean_iou: 0.8862 - val_loss: 0.0770 - val_mean_iou: 0.8864\n",
      "Epoch 24/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0524 - mean_iou: 0.8865\n",
      "Epoch 00024: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0523 - mean_iou: 0.8865 - val_loss: 0.0786 - val_mean_iou: 0.8866\n",
      "Epoch 25/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0524 - mean_iou: 0.8867\n",
      "Epoch 00025: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0528 - mean_iou: 0.8867 - val_loss: 0.0779 - val_mean_iou: 0.8868\n",
      "Epoch 26/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0529 - mean_iou: 0.8869\n",
      "Epoch 00026: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0528 - mean_iou: 0.8869 - val_loss: 0.0781 - val_mean_iou: 0.8870\n",
      "Epoch 27/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0521 - mean_iou: 0.8871\n",
      "Epoch 00027: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0522 - mean_iou: 0.8871 - val_loss: 0.0777 - val_mean_iou: 0.8872\n",
      "Epoch 28/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0526 - mean_iou: 0.8873\n",
      "Epoch 00028: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0521 - mean_iou: 0.8873 - val_loss: 0.0776 - val_mean_iou: 0.8874\n",
      "Epoch 29/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0516 - mean_iou: 0.8874\n",
      "Epoch 00029: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0513 - mean_iou: 0.8874 - val_loss: 0.0777 - val_mean_iou: 0.8876\n",
      "Epoch 30/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0508 - mean_iou: 0.8877\n",
      "Epoch 00030: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0511 - mean_iou: 0.8877 - val_loss: 0.0778 - val_mean_iou: 0.8878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0511 - mean_iou: 0.8879\n",
      "Epoch 00031: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0508 - mean_iou: 0.8879 - val_loss: 0.0775 - val_mean_iou: 0.8880\n",
      "Epoch 32/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0509 - mean_iou: 0.8881\n",
      "Epoch 00032: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0506 - mean_iou: 0.8881 - val_loss: 0.0790 - val_mean_iou: 0.8882\n",
      "Epoch 33/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0513 - mean_iou: 0.8883\n",
      "Epoch 00033: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0510 - mean_iou: 0.8883 - val_loss: 0.0776 - val_mean_iou: 0.8884\n",
      "Epoch 34/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0506 - mean_iou: 0.8885\n",
      "Epoch 00034: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0506 - mean_iou: 0.8885 - val_loss: 0.0781 - val_mean_iou: 0.8886\n",
      "Epoch 35/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0508 - mean_iou: 0.8887\n",
      "Epoch 00035: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0506 - mean_iou: 0.8887 - val_loss: 0.0779 - val_mean_iou: 0.8888\n",
      "Epoch 36/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0510 - mean_iou: 0.8888\n",
      "Epoch 00036: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0508 - mean_iou: 0.8888 - val_loss: 0.0776 - val_mean_iou: 0.8889\n",
      "Epoch 37/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0506 - mean_iou: 0.8890\n",
      "Epoch 00037: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0504 - mean_iou: 0.8890 - val_loss: 0.0787 - val_mean_iou: 0.8891\n",
      "Epoch 38/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0498 - mean_iou: 0.8892\n",
      "Epoch 00038: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0497 - mean_iou: 0.8892 - val_loss: 0.0792 - val_mean_iou: 0.8893\n",
      "Epoch 39/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0497 - mean_iou: 0.8894\n",
      "Epoch 00039: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0495 - mean_iou: 0.8894 - val_loss: 0.0784 - val_mean_iou: 0.8894\n",
      "Epoch 40/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0494 - mean_iou: 0.8895\n",
      "Epoch 00040: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0500 - mean_iou: 0.8895 - val_loss: 0.0789 - val_mean_iou: 0.8896\n",
      "Epoch 41/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0490 - mean_iou: 0.8897\n",
      "Epoch 00041: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0491 - mean_iou: 0.8897 - val_loss: 0.0778 - val_mean_iou: 0.8898\n",
      "Epoch 42/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0490 - mean_iou: 0.8899\n",
      "Epoch 00042: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0489 - mean_iou: 0.8899 - val_loss: 0.0789 - val_mean_iou: 0.8900\n",
      "Epoch 43/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0490 - mean_iou: 0.8901\n",
      "Epoch 00043: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0491 - mean_iou: 0.8901 - val_loss: 0.0798 - val_mean_iou: 0.8901\n",
      "Epoch 44/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0489 - mean_iou: 0.8902\n",
      "Epoch 00044: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0490 - mean_iou: 0.8902 - val_loss: 0.0795 - val_mean_iou: 0.8903\n",
      "Epoch 45/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0490 - mean_iou: 0.8904\n",
      "Epoch 00045: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0488 - mean_iou: 0.8904 - val_loss: 0.0803 - val_mean_iou: 0.8905\n",
      "Epoch 46/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0486 - mean_iou: 0.8906\n",
      "Epoch 00046: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0488 - mean_iou: 0.8906 - val_loss: 0.0808 - val_mean_iou: 0.8906\n",
      "Epoch 47/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0489 - mean_iou: 0.8907\n",
      "Epoch 00047: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0484 - mean_iou: 0.8907 - val_loss: 0.0793 - val_mean_iou: 0.8908\n",
      "Epoch 48/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0483 - mean_iou: 0.8909\n",
      "Epoch 00048: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0480 - mean_iou: 0.8909 - val_loss: 0.0809 - val_mean_iou: 0.8910\n",
      "Epoch 49/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0480 - mean_iou: 0.8911\n",
      "Epoch 00049: val_loss did not improve\n",
      "603/603 [==============================] - 33s 54ms/step - loss: 0.0479 - mean_iou: 0.8911 - val_loss: 0.0787 - val_mean_iou: 0.8912\n",
      "Epoch 50/50\n",
      "592/603 [============================>.] - ETA: 0s - loss: 0.0479 - mean_iou: 0.8912\n",
      "Epoch 00050: val_loss did not improve\n",
      "603/603 [==============================] - 33s 55ms/step - loss: 0.0478 - mean_iou: 0.8912 - val_loss: 0.0805 - val_mean_iou: 0.8913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea42473b00>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "model.compile(optimizer=Adamax(lr=0.001), loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.fit(x_train, y_train, batch_size=16, epochs = 50, validation_data=(x_valid, y_valid), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 10s 16ms/step\n",
      "67/67 [==============================] - 1s 14ms/step\n",
      "65/65 [==============================] - 1s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('best_model.h5', custom_objects={'mean_iou': mean_iou})\n",
    "preds_train = model.predict(x_train, verbose=1)\n",
    "preds_val = model.predict(x_valid, verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)\n",
    "        \n",
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2623\n"
     ]
    }
   ],
   "source": [
    "# Create submission DataFrame\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.groupby('ImageId').ngroup()\n",
    "print(len(sub))\n",
    "sub.to_csv('11th_kaggle_submission_ever.csv', index=False)#scored 0.341\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
