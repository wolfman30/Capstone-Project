{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#stolen from https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, AlphaDropout, Activation\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 672\n",
    "IMG_HEIGHT = 672\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = 'stage1_train/'\n",
    "TEST_PATH = 'stage2_test/'\n",
    "\n",
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 664/664 [09:04<00:00,  1.22it/s]\n",
      "100%|██████████| 3019/3019 [02:54<00:00, 17.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initializes the training images and target images (masks) as arrays of zeros\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "#gets and resizes the images each containing several nuclei\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = cv2.imread(path + '/images/' + id_ + '.png')[:,:,:3]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    #gets and resizes the masks that contain the individual segmented nuclei\n",
    "    #the targets for the model\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = cv2.imread(path + '/masks/' + mask_file,0)\n",
    "        mask_ = np.expand_dims(resize(mask_, (672, 672), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "# initializes, gets, and resizes test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = cv2.imread(path + '/images/' + id_ + '.png')[:,:,:3]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train, test_size=0.1, random_state=8011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "def get_crop_shape(target, refer):\n",
    "    # width, the 3rd dimension\n",
    "    cw = (target.get_shape()[2] - refer.get_shape()[2]).value\n",
    "    assert (cw >= 0)\n",
    "    if cw % 2 != 0:\n",
    "        cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "    else:\n",
    "        cw1, cw2 = int(cw/2), int(cw/2)\n",
    "    # height, the 2nd dimension\n",
    "    ch = (target.get_shape()[1] - refer.get_shape()[1]).value\n",
    "    assert (ch >= 0)\n",
    "    if ch % 2 != 0:\n",
    "        ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "    else:\n",
    "        ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "    return (ch1, ch2), (cw1, cw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 672, 672, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                (None, 672, 672, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 672, 672, 32) 9248        conv1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 336, 336, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 336, 336, 64) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 336, 336, 64) 36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 168, 168, 64) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 168, 168, 128 73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 168, 168, 128 147584      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 84, 84, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 84, 84, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 84, 84, 256)  590080      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84, 84, 256)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 42, 42, 256)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 42, 42, 512)  1180160     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 42, 42, 512)  2359808     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 42, 42, 512)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 84, 84, 512)  0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 84, 84, 256)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 84, 84, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 cropping2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 84, 84, 256)  1769728     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 84, 84, 256)  590080      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 168, 168, 256 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)       (None, 168, 168, 128 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 168, 168, 384 0           up_sampling2d_2[0][0]            \n",
      "                                                                 cropping2d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 168, 168, 128 442496      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 168, 168, 128 147584      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 336, 336, 128 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)       (None, 336, 336, 64) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 336, 336, 192 0           up_sampling2d_3[0][0]            \n",
      "                                                                 cropping2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 336, 336, 64) 110656      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 336, 336, 64) 36928       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 672, 672, 64) 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_4 (Cropping2D)       (None, 672, 672, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 672, 672, 96) 0           up_sampling2d_4[0][0]            \n",
      "                                                                 cropping2d_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 672, 672, 32) 27680       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 672, 672, 32) 9248        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 672, 672, 32) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 672, 672, 1)  33          zero_padding2d_1[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 7,846,657\n",
      "Trainable params: 7,846,657\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#from https://github.com/zizhaozhang/unet-tensorflow-keras/blob/master/model.py\n",
    "\n",
    "concat_axis = 3\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_1')(inputs)\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "conv4 = Dropout(0.5)(conv4)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "conv5 = Dropout(0.5)(conv5)\n",
    "\n",
    "up_conv5 = layers.UpSampling2D(size=(2, 2))(conv5)\n",
    "ch, cw = get_crop_shape(conv4, up_conv5)\n",
    "crop_conv4 = layers.Cropping2D(cropping=(ch,cw))(conv4)\n",
    "up6 = layers.concatenate([up_conv5, crop_conv4], axis=concat_axis)\n",
    "conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up_conv6 = layers.UpSampling2D(size=(2, 2))(conv6)\n",
    "ch, cw = get_crop_shape(conv3, up_conv6)\n",
    "crop_conv3 = layers.Cropping2D(cropping=(ch,cw))(conv3)\n",
    "up7 = layers.concatenate([up_conv6, crop_conv3], axis=concat_axis) \n",
    "conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "up_conv7 = layers.UpSampling2D(size=(2, 2))(conv7)\n",
    "ch, cw = get_crop_shape(conv2, up_conv7)\n",
    "crop_conv2 = layers.Cropping2D(cropping=(ch,cw))(conv2)\n",
    "up8 = layers.concatenate([up_conv7, crop_conv2], axis=concat_axis)\n",
    "conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "up_conv8 = layers.UpSampling2D(size=(2, 2))(conv8)\n",
    "ch, cw = get_crop_shape(conv1, up_conv8)\n",
    "crop_conv1 = layers.Cropping2D(cropping=(ch,cw))(conv1)\n",
    "up9 = layers.concatenate([up_conv8, crop_conv1], axis=concat_axis)\n",
    "conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "ch, cw = get_crop_shape(inputs, conv9)\n",
    "conv9 = layers.ZeroPadding2D(padding=((ch[0], ch[1]), (cw[0], cw[1])))(conv9)\n",
    "conv10 = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[conv10])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom imgaug import augmenters as iaa\\n\\naug = iaa.Sequential([iaa.Fliplr(0.5), iaa.Flipud(0.5),\\n                      iaa.Affine(rotate=(-45,45),translate_px={\"x\": (-40, 40)}),\\n                      iaa.PiecewiseAffine(scale=(0.01, 0.2)),\\n                      iaa.ElasticTransformation(alpha=(0, 5.0), sigma=0.25)])\\n\\naug_val = iaa.Sequential([])\\n\\nx_train_aug = aug.augment_images(x_train)\\ny_train_aug = aug.augment_images(y_train)\\nx_valid_aug = aug_val.augment_images(x_valid)\\nx_valid_aug = aug_val.augment_images(y_valid)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "aug = iaa.Sequential([iaa.Fliplr(0.5), iaa.Flipud(0.5),\n",
    "                      iaa.Affine(rotate=(-45,45),translate_px={\"x\": (-40, 40)}),\n",
    "                      iaa.PiecewiseAffine(scale=(0.01, 0.2)),\n",
    "                      iaa.ElasticTransformation(alpha=(0, 5.0), sigma=0.25)])\n",
    "\n",
    "aug_val = iaa.Sequential([])\n",
    "\n",
    "x_train_aug = aug.augment_images(x_train)\n",
    "y_train_aug = aug.augment_images(y_train)\n",
    "x_valid_aug = aug_val.augment_images(x_valid)\n",
    "x_valid_aug = aug_val.augment_images(y_valid)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "data_gen_args = dict(horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         rotation_range=90.,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         zoom_range=0.1)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "image_datagen.fit(x_train, seed=7)\n",
    "mask_datagen.fit(y_train, seed=7)\n",
    "image_generator = image_datagen.flow(x_train, batch_size=1, seed=7)\n",
    "mask_generator = mask_datagen.flow(y_train, batch_size=1, seed=7)\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "val_gen_args = dict()\n",
    "image_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "mask_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "image_datagen_val.fit(x_valid, seed=7)\n",
    "mask_datagen_val.fit(y_valid, seed=7)\n",
    "image_generator_val = image_datagen_val.flow(x_valid, batch_size=1, seed=7)\n",
    "mask_generator_val = mask_datagen_val.flow(y_valid, batch_size=1, seed=7)\n",
    "valid_generator=zip(image_generator_val, mask_generator_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "597/597 [==============================] - 281s 471ms/step - loss: 0.6710 - mean_iou: 0.4323 - val_loss: 0.4153 - val_mean_iou: 0.4447\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41531, saving model to unet.h5\n",
      "Epoch 2/2\n",
      "597/597 [==============================] - 272s 456ms/step - loss: 0.5776 - mean_iou: 0.4405 - val_loss: 0.4171 - val_mean_iou: 0.4377\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f69b7c44ba8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('unet.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "model.fit_generator(train_generator, steps_per_epoch=len(x_train), epochs=2,\n",
    "                    validation_data=valid_generator, validation_steps=len(x_valid), callbacks = [checkpoint])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3019/3019 [==============================] - 419s 139ms/step\n",
      "31802\n"
     ]
    }
   ],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('unet.h5', custom_objects={'mean_iou': mean_iou, 'get_crop_shape':get_crop_shape})\n",
    "preds_test = model.predict(X_test,  batch_size=1, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))\n",
    "    \n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)\n",
    "        \n",
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))\n",
    "    \n",
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.groupby('ImageId').ngroup()\n",
    "print(len(sub))\n",
    "sub.to_csv('UNet_crop_aug_larger-img_size_imgaug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
