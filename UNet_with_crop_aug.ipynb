{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#stolen from https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, AlphaDropout, Activation\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adamax, Adam, SGD\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = 'stage1_train/'\n",
    "TEST_PATH = 'stage2_test/'\n",
    "\n",
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 664/664 [02:38<00:00,  4.20it/s]\n",
      "100%|██████████| 3019/3019 [00:51<00:00, 58.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initializes the training images and target images (masks) as arrays of zeros\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "#gets and resizes the images each containing several nuclei\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = cv2.imread(path + '/images/' + id_ + '.png')[:,:,:3]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    #gets and resizes the masks that contain the individual segmented nuclei\n",
    "    #the targets for the model\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = cv2.imread(path + '/masks/' + mask_file,0)\n",
    "        mask_ = np.expand_dims(resize(mask_, (256, 256), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "# initializes, gets, and resizes test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = cv2.imread(path + '/images/' + id_ + '.png')[:,:,:3]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train, test_size=0.1, random_state=8011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "def get_crop_shape(target, refer):\n",
    "    # width, the 3rd dimension\n",
    "    cw = (target.get_shape()[2] - refer.get_shape()[2]).value\n",
    "    assert (cw >= 0)\n",
    "    if cw % 2 != 0:\n",
    "        cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "    else:\n",
    "        cw1, cw2 = int(cw/2), int(cw/2)\n",
    "    # height, the 2nd dimension\n",
    "    ch = (target.get_shape()[1] - refer.get_shape()[1]).value\n",
    "    assert (ch >= 0)\n",
    "    if ch % 2 != 0:\n",
    "        ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "    else:\n",
    "        ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "    return (ch1, ch2), (cw1, cw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                (None, 256, 256, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 9248        conv1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 64) 36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 128)  147584      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 256)  590080      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 256)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 512)  2359808     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 512)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 32, 32, 256)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 cropping2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 256)  1769728     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 256)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)       (None, 64, 64, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 cropping2d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 128)  442496      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 128 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)       (None, 128, 128, 64) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_3[0][0]            \n",
      "                                                                 cropping2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 64) 110656      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_4 (Cropping2D)       (None, 256, 256, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 96) 0           up_sampling2d_4[0][0]            \n",
      "                                                                 cropping2d_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 32) 27680       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 32) 9248        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 256, 256, 32) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 1)  33          zero_padding2d_1[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 7,846,657\n",
      "Trainable params: 7,846,657\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#from https://github.com/zizhaozhang/unet-tensorflow-keras/blob/master/model.py\n",
    "\n",
    "concat_axis = 3\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_1')(inputs)\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "up_conv5 = layers.UpSampling2D(size=(2, 2))(conv5)\n",
    "ch, cw = get_crop_shape(conv4, up_conv5)\n",
    "crop_conv4 = layers.Cropping2D(cropping=(ch,cw))(conv4)\n",
    "up6 = layers.concatenate([up_conv5, crop_conv4], axis=concat_axis)\n",
    "conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up_conv6 = layers.UpSampling2D(size=(2, 2))(conv6)\n",
    "ch, cw = get_crop_shape(conv3, up_conv6)\n",
    "crop_conv3 = layers.Cropping2D(cropping=(ch,cw))(conv3)\n",
    "up7 = layers.concatenate([up_conv6, crop_conv3], axis=concat_axis) \n",
    "conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "up_conv7 = layers.UpSampling2D(size=(2, 2))(conv7)\n",
    "ch, cw = get_crop_shape(conv2, up_conv7)\n",
    "crop_conv2 = layers.Cropping2D(cropping=(ch,cw))(conv2)\n",
    "up8 = layers.concatenate([up_conv7, crop_conv2], axis=concat_axis)\n",
    "conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "up_conv8 = layers.UpSampling2D(size=(2, 2))(conv8)\n",
    "ch, cw = get_crop_shape(conv1, up_conv8)\n",
    "crop_conv1 = layers.Cropping2D(cropping=(ch,cw))(conv1)\n",
    "up9 = layers.concatenate([up_conv8, crop_conv1], axis=concat_axis)\n",
    "conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "ch, cw = get_crop_shape(inputs, conv9)\n",
    "conv9 = layers.ZeroPadding2D(padding=((ch[0], ch[1]), (cw[0], cw[1])))(conv9)\n",
    "conv10 = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[conv10])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "data_gen_args = dict(horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         rotation_range=90.,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         zoom_range=0.1)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "image_datagen.fit(x_train, seed=7)\n",
    "mask_datagen.fit(y_train, seed=7)\n",
    "image_generator = image_datagen.flow(x_train, batch_size=8, seed=7)\n",
    "mask_generator = mask_datagen.flow(y_train, batch_size=8, seed=7)\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "val_gen_args = dict()\n",
    "image_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "mask_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "image_datagen_val.fit(x_valid, seed=7)\n",
    "mask_datagen_val.fit(y_valid, seed=7)\n",
    "image_generator_val = image_datagen_val.flow(x_valid, batch_size=32, seed=7)\n",
    "mask_generator_val = mask_datagen_val.flow(y_valid, batch_size=32, seed=7)\n",
    "valid_generator=zip(image_generator_val, mask_generator_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "75/74 [==============================] - 41s 541ms/step - loss: 0.1661 - mean_iou: 0.5901 - val_loss: 0.1243 - val_mean_iou: 0.6108\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12425, saving model to best_model.h5\n",
      "Epoch 2/30\n",
      "75/74 [==============================] - 40s 537ms/step - loss: 0.1151 - mean_iou: 0.6335 - val_loss: 0.0825 - val_mean_iou: 0.6526\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12425 to 0.08246, saving model to best_model.h5\n",
      "Epoch 3/30\n",
      "75/74 [==============================] - 40s 539ms/step - loss: 0.1396 - mean_iou: 0.6664 - val_loss: 0.1160 - val_mean_iou: 0.6703\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/30\n",
      "75/74 [==============================] - 40s 538ms/step - loss: 0.1034 - mean_iou: 0.6783 - val_loss: 0.0760 - val_mean_iou: 0.6893\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08246 to 0.07595, saving model to best_model.h5\n",
      "Epoch 5/30\n",
      "75/74 [==============================] - 40s 537ms/step - loss: 0.1074 - mean_iou: 0.7006 - val_loss: 0.1341 - val_mean_iou: 0.7077\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/30\n",
      "75/74 [==============================] - 40s 537ms/step - loss: 0.1167 - mean_iou: 0.7114 - val_loss: 0.0710 - val_mean_iou: 0.7173\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07595 to 0.07103, saving model to best_model.h5\n",
      "Epoch 7/30\n",
      "75/74 [==============================] - 40s 538ms/step - loss: 0.0941 - mean_iou: 0.7240 - val_loss: 0.0665 - val_mean_iou: 0.7307\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.07103 to 0.06646, saving model to best_model.h5\n",
      "Epoch 8/30\n",
      "75/74 [==============================] - 40s 540ms/step - loss: 0.0873 - mean_iou: 0.7366 - val_loss: 0.0665 - val_mean_iou: 0.7422\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/30\n",
      "75/74 [==============================] - 40s 539ms/step - loss: 0.0807 - mean_iou: 0.7474 - val_loss: 0.0630 - val_mean_iou: 0.7518\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.06646 to 0.06299, saving model to best_model.h5\n",
      "Epoch 10/30\n",
      "75/74 [==============================] - 40s 539ms/step - loss: 0.1318 - mean_iou: 0.7551 - val_loss: 0.1338 - val_mean_iou: 0.7552\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/30\n",
      "75/74 [==============================] - 40s 538ms/step - loss: 0.1624 - mean_iou: 0.7547 - val_loss: 0.1641 - val_mean_iou: 0.7522\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/30\n",
      "75/74 [==============================] - 40s 538ms/step - loss: 0.1700 - mean_iou: 0.7475 - val_loss: 0.1392 - val_mean_iou: 0.7446\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/30\n",
      "75/74 [==============================] - 40s 538ms/step - loss: 0.1258 - mean_iou: 0.7432 - val_loss: 0.0857 - val_mean_iou: 0.7448\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/30\n",
      "75/74 [==============================] - 40s 537ms/step - loss: 0.0942 - mean_iou: 0.7475 - val_loss: 0.0739 - val_mean_iou: 0.7499\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/30\n",
      "75/74 [==============================] - 40s 537ms/step - loss: 0.0885 - mean_iou: 0.7525 - val_loss: 0.0704 - val_mean_iou: 0.7553\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/30\n",
      "75/74 [==============================] - 40s 538ms/step - loss: 0.0987 - mean_iou: 0.7579 - val_loss: 0.0838 - val_mean_iou: 0.7591\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/30\n",
      "75/74 [==============================] - 40s 537ms/step - loss: 0.0919 - mean_iou: 0.7610 - val_loss: 0.0655 - val_mean_iou: 0.7633\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/30\n",
      "75/74 [==============================] - 40s 538ms/step - loss: 0.0891 - mean_iou: 0.7655 - val_loss: 0.0663 - val_mean_iou: 0.7677\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/30\n",
      "75/74 [==============================] - 40s 537ms/step - loss: 0.0758 - mean_iou: 0.7701 - val_loss: 0.0600 - val_mean_iou: 0.7722\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.06299 to 0.06004, saving model to best_model.h5\n",
      "Epoch 20/30\n",
      "75/74 [==============================] - 40s 538ms/step - loss: 0.0886 - mean_iou: 0.7741 - val_loss: 0.0616 - val_mean_iou: 0.7759\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/30\n",
      "75/74 [==============================] - 41s 541ms/step - loss: 0.0881 - mean_iou: 0.7776 - val_loss: 0.0701 - val_mean_iou: 0.7791\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/30\n",
      "75/74 [==============================] - 40s 538ms/step - loss: 0.0814 - mean_iou: 0.7806 - val_loss: 0.0660 - val_mean_iou: 0.7822\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/30\n",
      "75/74 [==============================] - 40s 538ms/step - loss: 0.0925 - mean_iou: 0.7834 - val_loss: 0.0646 - val_mean_iou: 0.7847\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/30\n",
      "75/74 [==============================] - 40s 539ms/step - loss: 0.0812 - mean_iou: 0.7864 - val_loss: 0.0612 - val_mean_iou: 0.7876\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/30\n",
      "75/74 [==============================] - 40s 538ms/step - loss: 0.0753 - mean_iou: 0.7890 - val_loss: 0.0596 - val_mean_iou: 0.7905\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.06004 to 0.05965, saving model to best_model.h5\n",
      "Epoch 26/30\n",
      "75/74 [==============================] - 40s 538ms/step - loss: 0.0818 - mean_iou: 0.7917 - val_loss: 0.0649 - val_mean_iou: 0.7928\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/30\n",
      "75/74 [==============================] - 40s 539ms/step - loss: 0.0843 - mean_iou: 0.7942 - val_loss: 0.0600 - val_mean_iou: 0.7952\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/30\n",
      "75/74 [==============================] - 40s 539ms/step - loss: 0.0728 - mean_iou: 0.7964 - val_loss: 0.0609 - val_mean_iou: 0.7975\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/30\n",
      "75/74 [==============================] - 40s 537ms/step - loss: 0.0821 - mean_iou: 0.7985 - val_loss: 0.0588 - val_mean_iou: 0.7993\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.05965 to 0.05881, saving model to best_model.h5\n",
      "Epoch 30/30\n",
      "75/74 [==============================] - 40s 539ms/step - loss: 0.0772 - mean_iou: 0.8003 - val_loss: 0.0588 - val_mean_iou: 0.8013\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f96bcaae668>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "model.fit_generator(train_generator, steps_per_epoch=len(x_train)/8, epochs=30,\n",
    "                    validation_data=valid_generator, validation_steps=len(x_valid)/8, callbacks = [checkpoint])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597/597 [==============================] - 11s 19ms/step\n",
      "67/67 [==============================] - 1s 15ms/step\n",
      "3019/3019 [==============================] - 46s 15ms/step\n",
      "286982\n"
     ]
    }
   ],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('best_model.h5', custom_objects={'mean_iou': mean_iou, 'get_crop_shape':get_crop_shape})\n",
    "preds_train = model.predict(x_train, verbose=1)\n",
    "preds_val = model.predict(x_valid, verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))\n",
    "    \n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)\n",
    "        \n",
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))\n",
    "    \n",
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.groupby('ImageId').ngroup()\n",
    "print(len(sub))\n",
    "sub.to_csv('UNet_with_crop_and_aug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
