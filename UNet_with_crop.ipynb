{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stolen from https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, AlphaDropout, Activation\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adamax, Adam, SGD\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = 'stage1_train/'\n",
    "TEST_PATH = 'stage2_test/'\n",
    "\n",
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 664/664 [02:37<00:00,  4.20it/s]\n",
      "100%|██████████| 3019/3019 [00:53<00:00, 55.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initializes the training images and target images (masks) as arrays of zeros\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "#gets and resizes the images each containing several nuclei\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = cv2.imread(path + '/images/' + id_ + '.png')[:,:,:3]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    #gets and resizes the masks that contain the individual segmented nuclei\n",
    "    #the targets for the model\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = cv2.imread(path + '/masks/' + mask_file,0)\n",
    "        mask_ = np.expand_dims(resize(mask_, (256, 256), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "# initializes, gets, and resizes test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = cv2.imread(path + '/images/' + id_ + '.png')[:,:,:3]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train, test_size=0.1, random_state=8011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "def get_crop_shape(target, refer):\n",
    "    # width, the 3rd dimension\n",
    "    cw = (target.get_shape()[2] - refer.get_shape()[2]).value\n",
    "    assert (cw >= 0)\n",
    "    if cw % 2 != 0:\n",
    "        cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "    else:\n",
    "        cw1, cw2 = int(cw/2), int(cw/2)\n",
    "    # height, the 2nd dimension\n",
    "    ch = (target.get_shape()[1] - refer.get_shape()[1]).value\n",
    "    assert (ch >= 0)\n",
    "    if ch % 2 != 0:\n",
    "        ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "    else:\n",
    "        ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "    return (ch1, ch2), (cw1, cw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                (None, 256, 256, 32) 896         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 256, 256, 32) 9248        conv1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 128, 128, 32) 0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 128, 128, 64) 18496       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 64, 64, 64)   0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 64, 64, 128)  73856       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 32, 32, 128)  0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 16, 16, 256)  0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 16, 16, 512)  1180160     max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling2D) (None, 32, 32, 512)  0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_13 (Cropping2D)      (None, 32, 32, 256)  0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 32, 32, 768)  0           up_sampling2d_14[0][0]           \n",
      "                                                                 cropping2d_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 32, 32, 256)  1769728     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling2D) (None, 64, 64, 256)  0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_14 (Cropping2D)      (None, 64, 64, 128)  0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 64, 64, 384)  0           up_sampling2d_15[0][0]           \n",
      "                                                                 cropping2d_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 64, 64, 128)  442496      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling2D) (None, 128, 128, 128 0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_15 (Cropping2D)      (None, 128, 128, 64) 0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 128, 128, 192 0           up_sampling2d_16[0][0]           \n",
      "                                                                 cropping2d_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 128, 128, 64) 110656      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling2D) (None, 256, 256, 64) 0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_16 (Cropping2D)      (None, 256, 256, 32) 0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 256, 256, 96) 0           up_sampling2d_17[0][0]           \n",
      "                                                                 cropping2d_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 256, 256, 32) 27680       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 256, 256, 32) 9248        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 256, 256, 32) 0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 256, 256, 1)  33          zero_padding2d_4[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 7,846,657\n",
      "Trainable params: 7,846,657\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#from https://github.com/zizhaozhang/unet-tensorflow-keras/blob/master/model.py\n",
    "\n",
    "concat_axis = 3\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_1')(inputs)\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "up_conv5 = layers.UpSampling2D(size=(2, 2))(conv5)\n",
    "ch, cw = get_crop_shape(conv4, up_conv5)\n",
    "crop_conv4 = layers.Cropping2D(cropping=(ch,cw))(conv4)\n",
    "up6 = layers.concatenate([up_conv5, crop_conv4], axis=concat_axis)\n",
    "conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up_conv6 = layers.UpSampling2D(size=(2, 2))(conv6)\n",
    "ch, cw = get_crop_shape(conv3, up_conv6)\n",
    "crop_conv3 = layers.Cropping2D(cropping=(ch,cw))(conv3)\n",
    "up7 = layers.concatenate([up_conv6, crop_conv3], axis=concat_axis) \n",
    "conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "up_conv7 = layers.UpSampling2D(size=(2, 2))(conv7)\n",
    "ch, cw = get_crop_shape(conv2, up_conv7)\n",
    "crop_conv2 = layers.Cropping2D(cropping=(ch,cw))(conv2)\n",
    "up8 = layers.concatenate([up_conv7, crop_conv2], axis=concat_axis)\n",
    "conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "up_conv8 = layers.UpSampling2D(size=(2, 2))(conv8)\n",
    "ch, cw = get_crop_shape(conv1, up_conv8)\n",
    "crop_conv1 = layers.Cropping2D(cropping=(ch,cw))(conv1)\n",
    "up9 = layers.concatenate([up_conv8, crop_conv1], axis=concat_axis)\n",
    "conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "ch, cw = get_crop_shape(inputs, conv9)\n",
    "conv9 = layers.ZeroPadding2D(padding=((ch[0], ch[1]), (cw[0], cw[1])))(conv9)\n",
    "conv10 = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[conv10])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 597 samples, validate on 67 samples\n",
      "Epoch 1/30\n",
      "597/597 [==============================] - 45s 75ms/step - loss: 0.3586 - mean_iou: 0.4763 - val_loss: 0.1262 - val_mean_iou: 0.5457\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12618, saving model to best_model.h5\n",
      "Epoch 2/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1608 - mean_iou: 0.5899 - val_loss: 0.2721 - val_mean_iou: 0.6064\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1497 - mean_iou: 0.6126 - val_loss: 0.2177 - val_mean_iou: 0.6295\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1771 - mean_iou: 0.6232 - val_loss: 0.1313 - val_mean_iou: 0.6294\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1602 - mean_iou: 0.6401 - val_loss: 0.1818 - val_mean_iou: 0.6456\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.2558 - mean_iou: 0.6430 - val_loss: 0.1744 - val_mean_iou: 0.6383\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1526 - mean_iou: 0.6414 - val_loss: 0.1522 - val_mean_iou: 0.6470\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1156 - mean_iou: 0.6499 - val_loss: 0.0899 - val_mean_iou: 0.6582\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12618 to 0.08988, saving model to best_model.h5\n",
      "Epoch 9/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.0881 - mean_iou: 0.6679 - val_loss: 0.0754 - val_mean_iou: 0.6775\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.08988 to 0.07538, saving model to best_model.h5\n",
      "Epoch 10/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.0863 - mean_iou: 0.6865 - val_loss: 0.0744 - val_mean_iou: 0.6939\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.07538 to 0.07442, saving model to best_model.h5\n",
      "Epoch 11/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.0818 - mean_iou: 0.7009 - val_loss: 0.0737 - val_mean_iou: 0.7077\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.07442 to 0.07368, saving model to best_model.h5\n",
      "Epoch 12/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.0763 - mean_iou: 0.7136 - val_loss: 0.0646 - val_mean_iou: 0.7198\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.07368 to 0.06457, saving model to best_model.h5\n",
      "Epoch 13/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.0743 - mean_iou: 0.7256 - val_loss: 0.0648 - val_mean_iou: 0.7305\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.0726 - mean_iou: 0.7353 - val_loss: 0.0616 - val_mean_iou: 0.7396\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.06457 to 0.06158, saving model to best_model.h5\n",
      "Epoch 15/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.0709 - mean_iou: 0.7437 - val_loss: 0.0593 - val_mean_iou: 0.7477\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.06158 to 0.05932, saving model to best_model.h5\n",
      "Epoch 16/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.0695 - mean_iou: 0.7515 - val_loss: 0.0591 - val_mean_iou: 0.7550\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.05932 to 0.05912, saving model to best_model.h5\n",
      "Epoch 17/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.0688 - mean_iou: 0.7583 - val_loss: 0.0599 - val_mean_iou: 0.7614\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.0986 - mean_iou: 0.7642 - val_loss: 0.1551 - val_mean_iou: 0.7653\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1173 - mean_iou: 0.7645 - val_loss: 0.0915 - val_mean_iou: 0.7646\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1329 - mean_iou: 0.7656 - val_loss: 0.1381 - val_mean_iou: 0.7647\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1787 - mean_iou: 0.7640 - val_loss: 0.1909 - val_mean_iou: 0.7623\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1386 - mean_iou: 0.7608 - val_loss: 0.1163 - val_mean_iou: 0.7604\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1945 - mean_iou: 0.7589 - val_loss: 0.1604 - val_mean_iou: 0.7549\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1246 - mean_iou: 0.7529 - val_loss: 0.0977 - val_mean_iou: 0.7527\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1623 - mean_iou: 0.7520 - val_loss: 0.0987 - val_mean_iou: 0.7517\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.2596 - mean_iou: 0.7491 - val_loss: 0.2093 - val_mean_iou: 0.7450\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1434 - mean_iou: 0.7431 - val_loss: 0.1610 - val_mean_iou: 0.7416\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.1161 - mean_iou: 0.7409 - val_loss: 0.0975 - val_mean_iou: 0.7407\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.0966 - mean_iou: 0.7411 - val_loss: 0.0971 - val_mean_iou: 0.7417\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/30\n",
      "597/597 [==============================] - 35s 59ms/step - loss: 0.0907 - mean_iou: 0.7428 - val_loss: 0.0792 - val_mean_iou: 0.7437\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1248879358>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "model.fit(x_train, y_train, batch_size=8, epochs = 30, validation_data=(x_valid, y_valid), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597/597 [==============================] - 14s 23ms/step\n",
      "67/67 [==============================] - 1s 15ms/step\n",
      "3019/3019 [==============================] - 45s 15ms/step\n",
      "172521\n"
     ]
    }
   ],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('best_model.h5', custom_objects={'mean_iou': mean_iou, 'get_crop_shape':get_crop_shape})\n",
    "preds_train = model.predict(x_train, verbose=1)\n",
    "preds_val = model.predict(x_valid, verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))\n",
    "    \n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)\n",
    "        \n",
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))\n",
    "    \n",
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.groupby('ImageId').ngroup()\n",
    "print(len(sub))\n",
    "sub.to_csv('UNet_with_crop_no_aug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
